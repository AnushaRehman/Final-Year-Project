{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone1_final_notebook ",
      "provenance": [],
      "collapsed_sections": [
        "jLjyPllOQUc7",
        "x0Ul8UKBQY17",
        "7EcXzZuszLvM"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "70ixJKgUM2QG"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from numpy import mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0mTup_wNAqm",
        "outputId": "fa96fe60-f447-44b6-8c68-999864a40133"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLjyPllOQUc7"
      },
      "source": [
        "#wsi training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "H6li1PvTNCW6",
        "outputId": "ea0d1dd9-0ac2-47f4-8217-3edb6e5499eb"
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/all_trans3.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># t_s</th>\n",
              "      <th>period</th>\n",
              "      <th>w_si</th>\n",
              "      <th>1400.0</th>\n",
              "      <th>1401.0</th>\n",
              "      <th>1402.0</th>\n",
              "      <th>1403.0</th>\n",
              "      <th>1404.0</th>\n",
              "      <th>1405.0</th>\n",
              "      <th>1406.0</th>\n",
              "      <th>1407.0</th>\n",
              "      <th>1408.0</th>\n",
              "      <th>1409.0</th>\n",
              "      <th>1410.0</th>\n",
              "      <th>1411.0</th>\n",
              "      <th>1412.0</th>\n",
              "      <th>1413.0</th>\n",
              "      <th>1414.0</th>\n",
              "      <th>1415.0</th>\n",
              "      <th>1416.0</th>\n",
              "      <th>1417.0</th>\n",
              "      <th>1418.0</th>\n",
              "      <th>1419.0</th>\n",
              "      <th>1420.0</th>\n",
              "      <th>1421.0</th>\n",
              "      <th>1422.0</th>\n",
              "      <th>1423.0</th>\n",
              "      <th>1424.0</th>\n",
              "      <th>1425.0</th>\n",
              "      <th>1426.0</th>\n",
              "      <th>1427.0</th>\n",
              "      <th>1428.0</th>\n",
              "      <th>1429.0</th>\n",
              "      <th>1430.0</th>\n",
              "      <th>1431.0</th>\n",
              "      <th>1432.0</th>\n",
              "      <th>1433.0</th>\n",
              "      <th>1434.0</th>\n",
              "      <th>1435.0</th>\n",
              "      <th>1436.0</th>\n",
              "      <th>...</th>\n",
              "      <th>1611.0</th>\n",
              "      <th>1612.0</th>\n",
              "      <th>1613.0</th>\n",
              "      <th>1614.0</th>\n",
              "      <th>1615.0</th>\n",
              "      <th>1616.0</th>\n",
              "      <th>1617.0</th>\n",
              "      <th>1618.0</th>\n",
              "      <th>1619.0</th>\n",
              "      <th>1620.0</th>\n",
              "      <th>1621.0</th>\n",
              "      <th>1622.0</th>\n",
              "      <th>1623.0</th>\n",
              "      <th>1624.0</th>\n",
              "      <th>1625.0</th>\n",
              "      <th>1626.0</th>\n",
              "      <th>1627.0</th>\n",
              "      <th>1628.0</th>\n",
              "      <th>1629.0</th>\n",
              "      <th>1630.0</th>\n",
              "      <th>1631.0</th>\n",
              "      <th>1632.0</th>\n",
              "      <th>1633.0</th>\n",
              "      <th>1634.0</th>\n",
              "      <th>1635.0</th>\n",
              "      <th>1636.0</th>\n",
              "      <th>1637.0</th>\n",
              "      <th>1638.0</th>\n",
              "      <th>1639.0</th>\n",
              "      <th>1640.0</th>\n",
              "      <th>1641.0</th>\n",
              "      <th>1642.0</th>\n",
              "      <th>1643.0</th>\n",
              "      <th>1644.0</th>\n",
              "      <th>1645.0</th>\n",
              "      <th>1646.0</th>\n",
              "      <th>1647.0</th>\n",
              "      <th>1648.0</th>\n",
              "      <th>1649.0</th>\n",
              "      <th>1650.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>382.50</td>\n",
              "      <td>0.951240</td>\n",
              "      <td>0.950670</td>\n",
              "      <td>0.95009</td>\n",
              "      <td>0.94949</td>\n",
              "      <td>0.94889</td>\n",
              "      <td>0.94828</td>\n",
              "      <td>0.94766</td>\n",
              "      <td>0.94702</td>\n",
              "      <td>0.94638</td>\n",
              "      <td>0.94573</td>\n",
              "      <td>0.94507</td>\n",
              "      <td>0.94440</td>\n",
              "      <td>0.94372</td>\n",
              "      <td>0.94303</td>\n",
              "      <td>0.94233</td>\n",
              "      <td>0.94163</td>\n",
              "      <td>0.94091</td>\n",
              "      <td>0.94019</td>\n",
              "      <td>0.93945</td>\n",
              "      <td>0.93871</td>\n",
              "      <td>0.93796</td>\n",
              "      <td>0.93720</td>\n",
              "      <td>0.93643</td>\n",
              "      <td>0.93566</td>\n",
              "      <td>0.93487</td>\n",
              "      <td>0.93408</td>\n",
              "      <td>0.93328</td>\n",
              "      <td>0.93247</td>\n",
              "      <td>0.93166</td>\n",
              "      <td>0.93083</td>\n",
              "      <td>0.93000</td>\n",
              "      <td>0.92916</td>\n",
              "      <td>0.92832</td>\n",
              "      <td>0.92747</td>\n",
              "      <td>0.92661</td>\n",
              "      <td>0.92574</td>\n",
              "      <td>0.92486</td>\n",
              "      <td>...</td>\n",
              "      <td>0.73293</td>\n",
              "      <td>0.73188</td>\n",
              "      <td>0.73083</td>\n",
              "      <td>0.72978</td>\n",
              "      <td>0.72874</td>\n",
              "      <td>0.72770</td>\n",
              "      <td>0.72666</td>\n",
              "      <td>0.72562</td>\n",
              "      <td>0.72458</td>\n",
              "      <td>0.72355</td>\n",
              "      <td>0.72252</td>\n",
              "      <td>0.72149</td>\n",
              "      <td>0.72047</td>\n",
              "      <td>0.71944</td>\n",
              "      <td>0.71842</td>\n",
              "      <td>0.71740</td>\n",
              "      <td>0.71639</td>\n",
              "      <td>0.71537</td>\n",
              "      <td>0.71436</td>\n",
              "      <td>0.71335</td>\n",
              "      <td>0.71234</td>\n",
              "      <td>0.71134</td>\n",
              "      <td>0.71034</td>\n",
              "      <td>0.70934</td>\n",
              "      <td>0.70834</td>\n",
              "      <td>0.70734</td>\n",
              "      <td>0.70635</td>\n",
              "      <td>0.70536</td>\n",
              "      <td>0.70437</td>\n",
              "      <td>0.70339</td>\n",
              "      <td>0.70240</td>\n",
              "      <td>0.70142</td>\n",
              "      <td>0.70045</td>\n",
              "      <td>0.69947</td>\n",
              "      <td>0.69850</td>\n",
              "      <td>0.69753</td>\n",
              "      <td>0.69656</td>\n",
              "      <td>0.69559</td>\n",
              "      <td>0.69463</td>\n",
              "      <td>0.69367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>405.00</td>\n",
              "      <td>0.963090</td>\n",
              "      <td>0.962850</td>\n",
              "      <td>0.96260</td>\n",
              "      <td>0.96234</td>\n",
              "      <td>0.96207</td>\n",
              "      <td>0.96179</td>\n",
              "      <td>0.96149</td>\n",
              "      <td>0.96118</td>\n",
              "      <td>0.96086</td>\n",
              "      <td>0.96053</td>\n",
              "      <td>0.96018</td>\n",
              "      <td>0.95983</td>\n",
              "      <td>0.95946</td>\n",
              "      <td>0.95908</td>\n",
              "      <td>0.95869</td>\n",
              "      <td>0.95828</td>\n",
              "      <td>0.95787</td>\n",
              "      <td>0.95744</td>\n",
              "      <td>0.95701</td>\n",
              "      <td>0.95656</td>\n",
              "      <td>0.95610</td>\n",
              "      <td>0.95563</td>\n",
              "      <td>0.95515</td>\n",
              "      <td>0.95466</td>\n",
              "      <td>0.95415</td>\n",
              "      <td>0.95364</td>\n",
              "      <td>0.95312</td>\n",
              "      <td>0.95258</td>\n",
              "      <td>0.95204</td>\n",
              "      <td>0.95148</td>\n",
              "      <td>0.95091</td>\n",
              "      <td>0.95034</td>\n",
              "      <td>0.94975</td>\n",
              "      <td>0.94915</td>\n",
              "      <td>0.94855</td>\n",
              "      <td>0.94793</td>\n",
              "      <td>0.94731</td>\n",
              "      <td>...</td>\n",
              "      <td>0.76473</td>\n",
              "      <td>0.76361</td>\n",
              "      <td>0.76250</td>\n",
              "      <td>0.76138</td>\n",
              "      <td>0.76027</td>\n",
              "      <td>0.75916</td>\n",
              "      <td>0.75805</td>\n",
              "      <td>0.75694</td>\n",
              "      <td>0.75584</td>\n",
              "      <td>0.75473</td>\n",
              "      <td>0.75363</td>\n",
              "      <td>0.75253</td>\n",
              "      <td>0.75143</td>\n",
              "      <td>0.75034</td>\n",
              "      <td>0.74924</td>\n",
              "      <td>0.74815</td>\n",
              "      <td>0.74706</td>\n",
              "      <td>0.74597</td>\n",
              "      <td>0.74488</td>\n",
              "      <td>0.74380</td>\n",
              "      <td>0.74271</td>\n",
              "      <td>0.74163</td>\n",
              "      <td>0.74055</td>\n",
              "      <td>0.73948</td>\n",
              "      <td>0.73840</td>\n",
              "      <td>0.73733</td>\n",
              "      <td>0.73626</td>\n",
              "      <td>0.73519</td>\n",
              "      <td>0.73412</td>\n",
              "      <td>0.73306</td>\n",
              "      <td>0.73199</td>\n",
              "      <td>0.73093</td>\n",
              "      <td>0.72988</td>\n",
              "      <td>0.72882</td>\n",
              "      <td>0.72777</td>\n",
              "      <td>0.72672</td>\n",
              "      <td>0.72567</td>\n",
              "      <td>0.72462</td>\n",
              "      <td>0.72357</td>\n",
              "      <td>0.72253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>270.00</td>\n",
              "      <td>0.787300</td>\n",
              "      <td>0.786100</td>\n",
              "      <td>0.78491</td>\n",
              "      <td>0.78372</td>\n",
              "      <td>0.78253</td>\n",
              "      <td>0.78135</td>\n",
              "      <td>0.78017</td>\n",
              "      <td>0.77899</td>\n",
              "      <td>0.77781</td>\n",
              "      <td>0.77663</td>\n",
              "      <td>0.77546</td>\n",
              "      <td>0.77429</td>\n",
              "      <td>0.77313</td>\n",
              "      <td>0.77196</td>\n",
              "      <td>0.77080</td>\n",
              "      <td>0.76964</td>\n",
              "      <td>0.76848</td>\n",
              "      <td>0.76733</td>\n",
              "      <td>0.76618</td>\n",
              "      <td>0.76503</td>\n",
              "      <td>0.76388</td>\n",
              "      <td>0.76274</td>\n",
              "      <td>0.76160</td>\n",
              "      <td>0.76046</td>\n",
              "      <td>0.75933</td>\n",
              "      <td>0.75820</td>\n",
              "      <td>0.75707</td>\n",
              "      <td>0.75594</td>\n",
              "      <td>0.75482</td>\n",
              "      <td>0.75370</td>\n",
              "      <td>0.75259</td>\n",
              "      <td>0.75147</td>\n",
              "      <td>0.75036</td>\n",
              "      <td>0.74925</td>\n",
              "      <td>0.74815</td>\n",
              "      <td>0.74705</td>\n",
              "      <td>0.74595</td>\n",
              "      <td>...</td>\n",
              "      <td>0.60222</td>\n",
              "      <td>0.60165</td>\n",
              "      <td>0.60108</td>\n",
              "      <td>0.60051</td>\n",
              "      <td>0.59995</td>\n",
              "      <td>0.59939</td>\n",
              "      <td>0.59883</td>\n",
              "      <td>0.59827</td>\n",
              "      <td>0.59772</td>\n",
              "      <td>0.59717</td>\n",
              "      <td>0.59662</td>\n",
              "      <td>0.59607</td>\n",
              "      <td>0.59552</td>\n",
              "      <td>0.59498</td>\n",
              "      <td>0.59444</td>\n",
              "      <td>0.59390</td>\n",
              "      <td>0.59337</td>\n",
              "      <td>0.59283</td>\n",
              "      <td>0.59230</td>\n",
              "      <td>0.59177</td>\n",
              "      <td>0.59125</td>\n",
              "      <td>0.59072</td>\n",
              "      <td>0.59020</td>\n",
              "      <td>0.58968</td>\n",
              "      <td>0.58916</td>\n",
              "      <td>0.58865</td>\n",
              "      <td>0.58813</td>\n",
              "      <td>0.58762</td>\n",
              "      <td>0.58711</td>\n",
              "      <td>0.58660</td>\n",
              "      <td>0.58610</td>\n",
              "      <td>0.58560</td>\n",
              "      <td>0.58510</td>\n",
              "      <td>0.58460</td>\n",
              "      <td>0.58410</td>\n",
              "      <td>0.58361</td>\n",
              "      <td>0.58311</td>\n",
              "      <td>0.58262</td>\n",
              "      <td>0.58214</td>\n",
              "      <td>0.58165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>225.00</td>\n",
              "      <td>0.701080</td>\n",
              "      <td>0.700130</td>\n",
              "      <td>0.69918</td>\n",
              "      <td>0.69823</td>\n",
              "      <td>0.69729</td>\n",
              "      <td>0.69635</td>\n",
              "      <td>0.69542</td>\n",
              "      <td>0.69449</td>\n",
              "      <td>0.69357</td>\n",
              "      <td>0.69264</td>\n",
              "      <td>0.69173</td>\n",
              "      <td>0.69081</td>\n",
              "      <td>0.68990</td>\n",
              "      <td>0.68900</td>\n",
              "      <td>0.68810</td>\n",
              "      <td>0.68720</td>\n",
              "      <td>0.68630</td>\n",
              "      <td>0.68541</td>\n",
              "      <td>0.68453</td>\n",
              "      <td>0.68365</td>\n",
              "      <td>0.68277</td>\n",
              "      <td>0.68189</td>\n",
              "      <td>0.68102</td>\n",
              "      <td>0.68016</td>\n",
              "      <td>0.67929</td>\n",
              "      <td>0.67843</td>\n",
              "      <td>0.67758</td>\n",
              "      <td>0.67673</td>\n",
              "      <td>0.67588</td>\n",
              "      <td>0.67503</td>\n",
              "      <td>0.67419</td>\n",
              "      <td>0.67336</td>\n",
              "      <td>0.67252</td>\n",
              "      <td>0.67170</td>\n",
              "      <td>0.67087</td>\n",
              "      <td>0.67005</td>\n",
              "      <td>0.66923</td>\n",
              "      <td>...</td>\n",
              "      <td>0.57256</td>\n",
              "      <td>0.57222</td>\n",
              "      <td>0.57187</td>\n",
              "      <td>0.57153</td>\n",
              "      <td>0.57120</td>\n",
              "      <td>0.57086</td>\n",
              "      <td>0.57053</td>\n",
              "      <td>0.57019</td>\n",
              "      <td>0.56986</td>\n",
              "      <td>0.56953</td>\n",
              "      <td>0.56920</td>\n",
              "      <td>0.56888</td>\n",
              "      <td>0.56855</td>\n",
              "      <td>0.56823</td>\n",
              "      <td>0.56791</td>\n",
              "      <td>0.56759</td>\n",
              "      <td>0.56727</td>\n",
              "      <td>0.56696</td>\n",
              "      <td>0.56664</td>\n",
              "      <td>0.56633</td>\n",
              "      <td>0.56602</td>\n",
              "      <td>0.56571</td>\n",
              "      <td>0.56541</td>\n",
              "      <td>0.56510</td>\n",
              "      <td>0.56480</td>\n",
              "      <td>0.56449</td>\n",
              "      <td>0.56419</td>\n",
              "      <td>0.56389</td>\n",
              "      <td>0.56360</td>\n",
              "      <td>0.56330</td>\n",
              "      <td>0.56301</td>\n",
              "      <td>0.56271</td>\n",
              "      <td>0.56242</td>\n",
              "      <td>0.56213</td>\n",
              "      <td>0.56184</td>\n",
              "      <td>0.56156</td>\n",
              "      <td>0.56127</td>\n",
              "      <td>0.56099</td>\n",
              "      <td>0.56071</td>\n",
              "      <td>0.56043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>292.50</td>\n",
              "      <td>0.829690</td>\n",
              "      <td>0.828470</td>\n",
              "      <td>0.82725</td>\n",
              "      <td>0.82604</td>\n",
              "      <td>0.82482</td>\n",
              "      <td>0.82361</td>\n",
              "      <td>0.82239</td>\n",
              "      <td>0.82118</td>\n",
              "      <td>0.81996</td>\n",
              "      <td>0.81875</td>\n",
              "      <td>0.81754</td>\n",
              "      <td>0.81633</td>\n",
              "      <td>0.81512</td>\n",
              "      <td>0.81391</td>\n",
              "      <td>0.81270</td>\n",
              "      <td>0.81149</td>\n",
              "      <td>0.81029</td>\n",
              "      <td>0.80908</td>\n",
              "      <td>0.80788</td>\n",
              "      <td>0.80668</td>\n",
              "      <td>0.80548</td>\n",
              "      <td>0.80428</td>\n",
              "      <td>0.80308</td>\n",
              "      <td>0.80189</td>\n",
              "      <td>0.80069</td>\n",
              "      <td>0.79950</td>\n",
              "      <td>0.79831</td>\n",
              "      <td>0.79712</td>\n",
              "      <td>0.79593</td>\n",
              "      <td>0.79474</td>\n",
              "      <td>0.79356</td>\n",
              "      <td>0.79238</td>\n",
              "      <td>0.79119</td>\n",
              "      <td>0.79001</td>\n",
              "      <td>0.78884</td>\n",
              "      <td>0.78766</td>\n",
              "      <td>0.78649</td>\n",
              "      <td>...</td>\n",
              "      <td>0.62351</td>\n",
              "      <td>0.62283</td>\n",
              "      <td>0.62215</td>\n",
              "      <td>0.62147</td>\n",
              "      <td>0.62080</td>\n",
              "      <td>0.62013</td>\n",
              "      <td>0.61947</td>\n",
              "      <td>0.61880</td>\n",
              "      <td>0.61814</td>\n",
              "      <td>0.61748</td>\n",
              "      <td>0.61682</td>\n",
              "      <td>0.61617</td>\n",
              "      <td>0.61552</td>\n",
              "      <td>0.61487</td>\n",
              "      <td>0.61422</td>\n",
              "      <td>0.61358</td>\n",
              "      <td>0.61293</td>\n",
              "      <td>0.61229</td>\n",
              "      <td>0.61166</td>\n",
              "      <td>0.61102</td>\n",
              "      <td>0.61039</td>\n",
              "      <td>0.60976</td>\n",
              "      <td>0.60913</td>\n",
              "      <td>0.60851</td>\n",
              "      <td>0.60789</td>\n",
              "      <td>0.60727</td>\n",
              "      <td>0.60665</td>\n",
              "      <td>0.60604</td>\n",
              "      <td>0.60542</td>\n",
              "      <td>0.60481</td>\n",
              "      <td>0.60420</td>\n",
              "      <td>0.60360</td>\n",
              "      <td>0.60300</td>\n",
              "      <td>0.60239</td>\n",
              "      <td>0.60180</td>\n",
              "      <td>0.60120</td>\n",
              "      <td>0.60061</td>\n",
              "      <td>0.60001</td>\n",
              "      <td>0.59943</td>\n",
              "      <td>0.59884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52306</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>435.50</td>\n",
              "      <td>0.989850</td>\n",
              "      <td>0.989550</td>\n",
              "      <td>0.98926</td>\n",
              "      <td>0.98898</td>\n",
              "      <td>0.98870</td>\n",
              "      <td>0.98844</td>\n",
              "      <td>0.98819</td>\n",
              "      <td>0.98794</td>\n",
              "      <td>0.98770</td>\n",
              "      <td>0.98747</td>\n",
              "      <td>0.98725</td>\n",
              "      <td>0.98704</td>\n",
              "      <td>0.98683</td>\n",
              "      <td>0.98664</td>\n",
              "      <td>0.98645</td>\n",
              "      <td>0.98626</td>\n",
              "      <td>0.98609</td>\n",
              "      <td>0.98592</td>\n",
              "      <td>0.98576</td>\n",
              "      <td>0.98560</td>\n",
              "      <td>0.98545</td>\n",
              "      <td>0.98531</td>\n",
              "      <td>0.98517</td>\n",
              "      <td>0.98503</td>\n",
              "      <td>0.98490</td>\n",
              "      <td>0.98478</td>\n",
              "      <td>0.98466</td>\n",
              "      <td>0.98454</td>\n",
              "      <td>0.98443</td>\n",
              "      <td>0.98432</td>\n",
              "      <td>0.98421</td>\n",
              "      <td>0.98411</td>\n",
              "      <td>0.98401</td>\n",
              "      <td>0.98391</td>\n",
              "      <td>0.98381</td>\n",
              "      <td>0.98371</td>\n",
              "      <td>0.98362</td>\n",
              "      <td>...</td>\n",
              "      <td>0.89112</td>\n",
              "      <td>0.89020</td>\n",
              "      <td>0.88928</td>\n",
              "      <td>0.88836</td>\n",
              "      <td>0.88744</td>\n",
              "      <td>0.88652</td>\n",
              "      <td>0.88560</td>\n",
              "      <td>0.88469</td>\n",
              "      <td>0.88377</td>\n",
              "      <td>0.88285</td>\n",
              "      <td>0.88194</td>\n",
              "      <td>0.88102</td>\n",
              "      <td>0.88011</td>\n",
              "      <td>0.87920</td>\n",
              "      <td>0.87828</td>\n",
              "      <td>0.87737</td>\n",
              "      <td>0.87647</td>\n",
              "      <td>0.87556</td>\n",
              "      <td>0.87466</td>\n",
              "      <td>0.87376</td>\n",
              "      <td>0.87286</td>\n",
              "      <td>0.87196</td>\n",
              "      <td>0.87106</td>\n",
              "      <td>0.87017</td>\n",
              "      <td>0.86928</td>\n",
              "      <td>0.86840</td>\n",
              "      <td>0.86751</td>\n",
              "      <td>0.86663</td>\n",
              "      <td>0.86576</td>\n",
              "      <td>0.86489</td>\n",
              "      <td>0.86402</td>\n",
              "      <td>0.86315</td>\n",
              "      <td>0.86230</td>\n",
              "      <td>0.86144</td>\n",
              "      <td>0.86059</td>\n",
              "      <td>0.85975</td>\n",
              "      <td>0.85891</td>\n",
              "      <td>0.85807</td>\n",
              "      <td>0.85724</td>\n",
              "      <td>0.85642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52307</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>318.25</td>\n",
              "      <td>0.973550</td>\n",
              "      <td>0.973080</td>\n",
              "      <td>0.97260</td>\n",
              "      <td>0.97211</td>\n",
              "      <td>0.97162</td>\n",
              "      <td>0.97111</td>\n",
              "      <td>0.97061</td>\n",
              "      <td>0.97009</td>\n",
              "      <td>0.96957</td>\n",
              "      <td>0.96905</td>\n",
              "      <td>0.96852</td>\n",
              "      <td>0.96799</td>\n",
              "      <td>0.96745</td>\n",
              "      <td>0.96692</td>\n",
              "      <td>0.96638</td>\n",
              "      <td>0.96584</td>\n",
              "      <td>0.96529</td>\n",
              "      <td>0.96475</td>\n",
              "      <td>0.96421</td>\n",
              "      <td>0.96366</td>\n",
              "      <td>0.96312</td>\n",
              "      <td>0.96258</td>\n",
              "      <td>0.96204</td>\n",
              "      <td>0.96151</td>\n",
              "      <td>0.96098</td>\n",
              "      <td>0.96046</td>\n",
              "      <td>0.95994</td>\n",
              "      <td>0.95942</td>\n",
              "      <td>0.95892</td>\n",
              "      <td>0.95842</td>\n",
              "      <td>0.95793</td>\n",
              "      <td>0.95745</td>\n",
              "      <td>0.95698</td>\n",
              "      <td>0.95653</td>\n",
              "      <td>0.95608</td>\n",
              "      <td>0.95565</td>\n",
              "      <td>0.95524</td>\n",
              "      <td>...</td>\n",
              "      <td>0.65345</td>\n",
              "      <td>0.65266</td>\n",
              "      <td>0.65187</td>\n",
              "      <td>0.65108</td>\n",
              "      <td>0.65029</td>\n",
              "      <td>0.64950</td>\n",
              "      <td>0.64871</td>\n",
              "      <td>0.64792</td>\n",
              "      <td>0.64714</td>\n",
              "      <td>0.64635</td>\n",
              "      <td>0.64557</td>\n",
              "      <td>0.64479</td>\n",
              "      <td>0.64400</td>\n",
              "      <td>0.64323</td>\n",
              "      <td>0.64245</td>\n",
              "      <td>0.64167</td>\n",
              "      <td>0.64089</td>\n",
              "      <td>0.64012</td>\n",
              "      <td>0.63935</td>\n",
              "      <td>0.63858</td>\n",
              "      <td>0.63781</td>\n",
              "      <td>0.63704</td>\n",
              "      <td>0.63628</td>\n",
              "      <td>0.63551</td>\n",
              "      <td>0.63475</td>\n",
              "      <td>0.63399</td>\n",
              "      <td>0.63324</td>\n",
              "      <td>0.63248</td>\n",
              "      <td>0.63173</td>\n",
              "      <td>0.63098</td>\n",
              "      <td>0.63023</td>\n",
              "      <td>0.62948</td>\n",
              "      <td>0.62873</td>\n",
              "      <td>0.62799</td>\n",
              "      <td>0.62725</td>\n",
              "      <td>0.62651</td>\n",
              "      <td>0.62578</td>\n",
              "      <td>0.62504</td>\n",
              "      <td>0.62431</td>\n",
              "      <td>0.62358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52308</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>284.75</td>\n",
              "      <td>0.025706</td>\n",
              "      <td>0.069033</td>\n",
              "      <td>0.12378</td>\n",
              "      <td>0.18295</td>\n",
              "      <td>0.24168</td>\n",
              "      <td>0.29707</td>\n",
              "      <td>0.34770</td>\n",
              "      <td>0.39309</td>\n",
              "      <td>0.43333</td>\n",
              "      <td>0.46877</td>\n",
              "      <td>0.49988</td>\n",
              "      <td>0.52718</td>\n",
              "      <td>0.55113</td>\n",
              "      <td>0.57219</td>\n",
              "      <td>0.59073</td>\n",
              "      <td>0.60709</td>\n",
              "      <td>0.62157</td>\n",
              "      <td>0.63441</td>\n",
              "      <td>0.64581</td>\n",
              "      <td>0.65597</td>\n",
              "      <td>0.66504</td>\n",
              "      <td>0.67314</td>\n",
              "      <td>0.68040</td>\n",
              "      <td>0.68691</td>\n",
              "      <td>0.69276</td>\n",
              "      <td>0.69801</td>\n",
              "      <td>0.70273</td>\n",
              "      <td>0.70698</td>\n",
              "      <td>0.71081</td>\n",
              "      <td>0.71425</td>\n",
              "      <td>0.71734</td>\n",
              "      <td>0.72012</td>\n",
              "      <td>0.72262</td>\n",
              "      <td>0.72485</td>\n",
              "      <td>0.72685</td>\n",
              "      <td>0.72864</td>\n",
              "      <td>0.73023</td>\n",
              "      <td>...</td>\n",
              "      <td>0.59986</td>\n",
              "      <td>0.59915</td>\n",
              "      <td>0.59843</td>\n",
              "      <td>0.59773</td>\n",
              "      <td>0.59702</td>\n",
              "      <td>0.59632</td>\n",
              "      <td>0.59562</td>\n",
              "      <td>0.59493</td>\n",
              "      <td>0.59424</td>\n",
              "      <td>0.59355</td>\n",
              "      <td>0.59287</td>\n",
              "      <td>0.59219</td>\n",
              "      <td>0.59151</td>\n",
              "      <td>0.59084</td>\n",
              "      <td>0.59017</td>\n",
              "      <td>0.58951</td>\n",
              "      <td>0.58884</td>\n",
              "      <td>0.58819</td>\n",
              "      <td>0.58753</td>\n",
              "      <td>0.58688</td>\n",
              "      <td>0.58623</td>\n",
              "      <td>0.58559</td>\n",
              "      <td>0.58495</td>\n",
              "      <td>0.58431</td>\n",
              "      <td>0.58368</td>\n",
              "      <td>0.58305</td>\n",
              "      <td>0.58242</td>\n",
              "      <td>0.58180</td>\n",
              "      <td>0.58118</td>\n",
              "      <td>0.58056</td>\n",
              "      <td>0.57995</td>\n",
              "      <td>0.57934</td>\n",
              "      <td>0.57873</td>\n",
              "      <td>0.57813</td>\n",
              "      <td>0.57753</td>\n",
              "      <td>0.57693</td>\n",
              "      <td>0.57634</td>\n",
              "      <td>0.57575</td>\n",
              "      <td>0.57516</td>\n",
              "      <td>0.57458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52309</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>217.75</td>\n",
              "      <td>0.649640</td>\n",
              "      <td>0.648220</td>\n",
              "      <td>0.64682</td>\n",
              "      <td>0.64542</td>\n",
              "      <td>0.64404</td>\n",
              "      <td>0.64267</td>\n",
              "      <td>0.64130</td>\n",
              "      <td>0.63995</td>\n",
              "      <td>0.63860</td>\n",
              "      <td>0.63727</td>\n",
              "      <td>0.63594</td>\n",
              "      <td>0.63462</td>\n",
              "      <td>0.63332</td>\n",
              "      <td>0.63202</td>\n",
              "      <td>0.63073</td>\n",
              "      <td>0.62946</td>\n",
              "      <td>0.62819</td>\n",
              "      <td>0.62693</td>\n",
              "      <td>0.62568</td>\n",
              "      <td>0.62444</td>\n",
              "      <td>0.62321</td>\n",
              "      <td>0.62199</td>\n",
              "      <td>0.62077</td>\n",
              "      <td>0.61957</td>\n",
              "      <td>0.61838</td>\n",
              "      <td>0.61719</td>\n",
              "      <td>0.61602</td>\n",
              "      <td>0.61485</td>\n",
              "      <td>0.61369</td>\n",
              "      <td>0.61255</td>\n",
              "      <td>0.61141</td>\n",
              "      <td>0.61027</td>\n",
              "      <td>0.60915</td>\n",
              "      <td>0.60804</td>\n",
              "      <td>0.60694</td>\n",
              "      <td>0.60584</td>\n",
              "      <td>0.60475</td>\n",
              "      <td>...</td>\n",
              "      <td>0.50886</td>\n",
              "      <td>0.50867</td>\n",
              "      <td>0.50848</td>\n",
              "      <td>0.50830</td>\n",
              "      <td>0.50811</td>\n",
              "      <td>0.50793</td>\n",
              "      <td>0.50775</td>\n",
              "      <td>0.50758</td>\n",
              "      <td>0.50740</td>\n",
              "      <td>0.50723</td>\n",
              "      <td>0.50706</td>\n",
              "      <td>0.50690</td>\n",
              "      <td>0.50673</td>\n",
              "      <td>0.50657</td>\n",
              "      <td>0.50641</td>\n",
              "      <td>0.50625</td>\n",
              "      <td>0.50610</td>\n",
              "      <td>0.50595</td>\n",
              "      <td>0.50580</td>\n",
              "      <td>0.50565</td>\n",
              "      <td>0.50550</td>\n",
              "      <td>0.50536</td>\n",
              "      <td>0.50522</td>\n",
              "      <td>0.50508</td>\n",
              "      <td>0.50494</td>\n",
              "      <td>0.50481</td>\n",
              "      <td>0.50467</td>\n",
              "      <td>0.50454</td>\n",
              "      <td>0.50442</td>\n",
              "      <td>0.50429</td>\n",
              "      <td>0.50416</td>\n",
              "      <td>0.50404</td>\n",
              "      <td>0.50392</td>\n",
              "      <td>0.50380</td>\n",
              "      <td>0.50369</td>\n",
              "      <td>0.50357</td>\n",
              "      <td>0.50346</td>\n",
              "      <td>0.50335</td>\n",
              "      <td>0.50324</td>\n",
              "      <td>0.50314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52310</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>268.00</td>\n",
              "      <td>0.770080</td>\n",
              "      <td>0.770050</td>\n",
              "      <td>0.76994</td>\n",
              "      <td>0.76977</td>\n",
              "      <td>0.76952</td>\n",
              "      <td>0.76922</td>\n",
              "      <td>0.76886</td>\n",
              "      <td>0.76844</td>\n",
              "      <td>0.76798</td>\n",
              "      <td>0.76746</td>\n",
              "      <td>0.76690</td>\n",
              "      <td>0.76630</td>\n",
              "      <td>0.76566</td>\n",
              "      <td>0.76498</td>\n",
              "      <td>0.76427</td>\n",
              "      <td>0.76352</td>\n",
              "      <td>0.76275</td>\n",
              "      <td>0.76194</td>\n",
              "      <td>0.76111</td>\n",
              "      <td>0.76025</td>\n",
              "      <td>0.75936</td>\n",
              "      <td>0.75845</td>\n",
              "      <td>0.75752</td>\n",
              "      <td>0.75657</td>\n",
              "      <td>0.75560</td>\n",
              "      <td>0.75462</td>\n",
              "      <td>0.75361</td>\n",
              "      <td>0.75259</td>\n",
              "      <td>0.75155</td>\n",
              "      <td>0.75050</td>\n",
              "      <td>0.74944</td>\n",
              "      <td>0.74836</td>\n",
              "      <td>0.74727</td>\n",
              "      <td>0.74617</td>\n",
              "      <td>0.74506</td>\n",
              "      <td>0.74394</td>\n",
              "      <td>0.74282</td>\n",
              "      <td>...</td>\n",
              "      <td>0.57273</td>\n",
              "      <td>0.57213</td>\n",
              "      <td>0.57152</td>\n",
              "      <td>0.57092</td>\n",
              "      <td>0.57033</td>\n",
              "      <td>0.56974</td>\n",
              "      <td>0.56915</td>\n",
              "      <td>0.56856</td>\n",
              "      <td>0.56798</td>\n",
              "      <td>0.56741</td>\n",
              "      <td>0.56683</td>\n",
              "      <td>0.56626</td>\n",
              "      <td>0.56570</td>\n",
              "      <td>0.56514</td>\n",
              "      <td>0.56458</td>\n",
              "      <td>0.56402</td>\n",
              "      <td>0.56347</td>\n",
              "      <td>0.56292</td>\n",
              "      <td>0.56238</td>\n",
              "      <td>0.56183</td>\n",
              "      <td>0.56130</td>\n",
              "      <td>0.56076</td>\n",
              "      <td>0.56023</td>\n",
              "      <td>0.55970</td>\n",
              "      <td>0.55918</td>\n",
              "      <td>0.55866</td>\n",
              "      <td>0.55814</td>\n",
              "      <td>0.55763</td>\n",
              "      <td>0.55712</td>\n",
              "      <td>0.55661</td>\n",
              "      <td>0.55610</td>\n",
              "      <td>0.55560</td>\n",
              "      <td>0.55511</td>\n",
              "      <td>0.55461</td>\n",
              "      <td>0.55412</td>\n",
              "      <td>0.55363</td>\n",
              "      <td>0.55315</td>\n",
              "      <td>0.55267</td>\n",
              "      <td>0.55219</td>\n",
              "      <td>0.55171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52311 rows × 254 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       # t_s  period    w_si    1400.0  ...   1647.0   1648.0   1649.0   1650.0\n",
              "0      208.0   450.0  382.50  0.951240  ...  0.69656  0.69559  0.69463  0.69367\n",
              "1      208.0   450.0  405.00  0.963090  ...  0.72567  0.72462  0.72357  0.72253\n",
              "2      208.0   450.0  270.00  0.787300  ...  0.58311  0.58262  0.58214  0.58165\n",
              "3      208.0   450.0  225.00  0.701080  ...  0.56127  0.56099  0.56071  0.56043\n",
              "4      208.0   450.0  292.50  0.829690  ...  0.60061  0.60001  0.59943  0.59884\n",
              "...      ...     ...     ...       ...  ...      ...      ...      ...      ...\n",
              "52306  248.0   670.0  435.50  0.989850  ...  0.85891  0.85807  0.85724  0.85642\n",
              "52307  248.0   670.0  318.25  0.973550  ...  0.62578  0.62504  0.62431  0.62358\n",
              "52308  248.0   670.0  284.75  0.025706  ...  0.57634  0.57575  0.57516  0.57458\n",
              "52309  248.0   670.0  217.75  0.649640  ...  0.50346  0.50335  0.50324  0.50314\n",
              "52310  248.0   670.0  268.00  0.770080  ...  0.55315  0.55267  0.55219  0.55171\n",
              "\n",
              "[52311 rows x 254 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZqiZaBvNIdT"
      },
      "source": [
        "X = df.drop(['w_si'], 1)\n",
        "Y = df.drop(X, 1)\n",
        "\n",
        "#X = df.values[:, :3]\n",
        "#Y = df.values[:, 3:]\n",
        "X = X.values\n",
        "Y = Y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_ZbghjNSTI"
      },
      "source": [
        "scaler_wsi = preprocessing.StandardScaler().fit(Y)\n",
        "Y = scaler_wsi.transform(Y)\n",
        "\n",
        "scaler_R = preprocessing.StandardScaler().fit(X[:, 2:])\n",
        "X[:, 2:] = scaler_R.transform(X[:, 2:])\n",
        "\n",
        "scaler_ts = preprocessing.StandardScaler().fit(X[:, 0:1])\n",
        "X[:, 0:1] = scaler_ts.transform(X[:, 0:1])\n",
        "\n",
        "scaler_period = preprocessing.StandardScaler().fit(X[:, 1:2])\n",
        "X[:, 1:2] = scaler_period.transform(X[:, 1:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EWAhw_KNUFy",
        "outputId": "f70059b4-e523-4acd-dae0-8eb1573fc387"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47079, 253) (5232, 253) (47079, 1) (5232, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DvisXOzNV79"
      },
      "source": [
        "model_wsi = Sequential([\n",
        "    Dense(100, activation='relu', input_shape=X_train[0].shape),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(1, activation= 'linear')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2OQW_JiNstv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "4f07631e-19a2-43d4-b468-fe02c0784ff6"
      },
      "source": [
        "#callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=8)\n",
        "\n",
        "model_wsi.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = tf.losses.MeanSquaredError(),\n",
        "              metrics=['acc'])\n",
        "\n",
        "hist = model_wsi.fit(X_train, Y_train,\n",
        "          batch_size=32, epochs=400, \n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "1472/1472 [==============================] - 4s 2ms/step - loss: 0.0837 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
            "Epoch 2/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 3/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0137 - val_acc: 0.0000e+00\n",
            "Epoch 4/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0201 - acc: 0.0000e+00 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
            "Epoch 5/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0143 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
            "Epoch 6/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0099 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0000e+00\n",
            "Epoch 7/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 8/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0098 - acc: 0.0000e+00 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 9/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
            "Epoch 10/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
            "Epoch 11/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0103 - acc: 0.0000e+00 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
            "Epoch 12/400\n",
            " 133/1472 [=>............................] - ETA: 3s - loss: 0.0083 - acc: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-189-7872d9989de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m hist = model_wsi.fit(X_train, Y_train,\n\u001b[1;32m      8\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m           validation_data=(X_test, Y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVB4uYG_NzQW"
      },
      "source": [
        "preds = model_wsi.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54iP7BAQ5AFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef537c4f-ed26-4780-b74f-45bb79ec077c"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.15844937],\n",
              "       [ 2.4637854 ],\n",
              "       [-0.5364138 ],\n",
              "       ...,\n",
              "       [ 0.7505237 ],\n",
              "       [ 0.3438227 ],\n",
              "       [-0.9022558 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya2xF4ia5W4j"
      },
      "source": [
        " import keras.backend as K \n",
        "\n",
        "def my_accuracy(y_pred, y_true):\n",
        "    diff = K.abs(y_true-y_pred)\n",
        "    correct = K.less(diff, 0.05)\n",
        "    return K.mean(correct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqezxpkX0rxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517a7b4b-3261-4b45-b936-75f8957e1b5a"
      },
      "source": [
        "my_accuracy(preds, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.98165137>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "02n3U3k96lXA",
        "outputId": "f0123fe9-e252-4817-95ec-c0650d238d86"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "#plt.ylim([0, 0.002])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa0f2209240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjMnvho6005T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdac90a-9c3c-421f-d000-f180cea71625"
      },
      "source": [
        "rmse = np.sqrt(mean_squared_error(Y_test, preds))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.024842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMrlzGhxeGZr"
      },
      "source": [
        "model_wsi.save('/content/gdrive/MyDrive/model_nn_wsi.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Ul8UKBQY17"
      },
      "source": [
        "#period training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enrdimKPh9Yw"
      },
      "source": [
        "model_wsi = tf.keras.models.load_model('/content/gdrive/MyDrive/model_nn_wsi.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pji8HnYSiTsi"
      },
      "source": [
        "preds = model_wsi.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJnx5X7ziZKq"
      },
      "source": [
        "my_accuracy(preds, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWo5dGiQa_i"
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/all_trans3.csv')\n",
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "4TLSZP0zLjjU",
        "outputId": "aa8e896d-8a96-4e95-fac9-423cfcf32500"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># t_s</th>\n",
              "      <th>period</th>\n",
              "      <th>w_si</th>\n",
              "      <th>1400.0</th>\n",
              "      <th>1401.0</th>\n",
              "      <th>1402.0</th>\n",
              "      <th>1403.0</th>\n",
              "      <th>1404.0</th>\n",
              "      <th>1405.0</th>\n",
              "      <th>1406.0</th>\n",
              "      <th>1407.0</th>\n",
              "      <th>1408.0</th>\n",
              "      <th>1409.0</th>\n",
              "      <th>1410.0</th>\n",
              "      <th>1411.0</th>\n",
              "      <th>1412.0</th>\n",
              "      <th>1413.0</th>\n",
              "      <th>1414.0</th>\n",
              "      <th>1415.0</th>\n",
              "      <th>1416.0</th>\n",
              "      <th>1417.0</th>\n",
              "      <th>1418.0</th>\n",
              "      <th>1419.0</th>\n",
              "      <th>1420.0</th>\n",
              "      <th>1421.0</th>\n",
              "      <th>1422.0</th>\n",
              "      <th>1423.0</th>\n",
              "      <th>1424.0</th>\n",
              "      <th>1425.0</th>\n",
              "      <th>1426.0</th>\n",
              "      <th>1427.0</th>\n",
              "      <th>1428.0</th>\n",
              "      <th>1429.0</th>\n",
              "      <th>1430.0</th>\n",
              "      <th>1431.0</th>\n",
              "      <th>1432.0</th>\n",
              "      <th>1433.0</th>\n",
              "      <th>1434.0</th>\n",
              "      <th>1435.0</th>\n",
              "      <th>1436.0</th>\n",
              "      <th>...</th>\n",
              "      <th>1611.0</th>\n",
              "      <th>1612.0</th>\n",
              "      <th>1613.0</th>\n",
              "      <th>1614.0</th>\n",
              "      <th>1615.0</th>\n",
              "      <th>1616.0</th>\n",
              "      <th>1617.0</th>\n",
              "      <th>1618.0</th>\n",
              "      <th>1619.0</th>\n",
              "      <th>1620.0</th>\n",
              "      <th>1621.0</th>\n",
              "      <th>1622.0</th>\n",
              "      <th>1623.0</th>\n",
              "      <th>1624.0</th>\n",
              "      <th>1625.0</th>\n",
              "      <th>1626.0</th>\n",
              "      <th>1627.0</th>\n",
              "      <th>1628.0</th>\n",
              "      <th>1629.0</th>\n",
              "      <th>1630.0</th>\n",
              "      <th>1631.0</th>\n",
              "      <th>1632.0</th>\n",
              "      <th>1633.0</th>\n",
              "      <th>1634.0</th>\n",
              "      <th>1635.0</th>\n",
              "      <th>1636.0</th>\n",
              "      <th>1637.0</th>\n",
              "      <th>1638.0</th>\n",
              "      <th>1639.0</th>\n",
              "      <th>1640.0</th>\n",
              "      <th>1641.0</th>\n",
              "      <th>1642.0</th>\n",
              "      <th>1643.0</th>\n",
              "      <th>1644.0</th>\n",
              "      <th>1645.0</th>\n",
              "      <th>1646.0</th>\n",
              "      <th>1647.0</th>\n",
              "      <th>1648.0</th>\n",
              "      <th>1649.0</th>\n",
              "      <th>1650.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40603</th>\n",
              "      <td>210.0</td>\n",
              "      <td>910.0</td>\n",
              "      <td>796.25</td>\n",
              "      <td>0.96503</td>\n",
              "      <td>0.96517</td>\n",
              "      <td>0.96529</td>\n",
              "      <td>0.96538</td>\n",
              "      <td>0.96544</td>\n",
              "      <td>0.965450</td>\n",
              "      <td>0.965370</td>\n",
              "      <td>0.965110</td>\n",
              "      <td>0.964400</td>\n",
              "      <td>0.962090</td>\n",
              "      <td>0.950160</td>\n",
              "      <td>0.553490</td>\n",
              "      <td>0.912140</td>\n",
              "      <td>0.95198</td>\n",
              "      <td>0.95862</td>\n",
              "      <td>0.96090</td>\n",
              "      <td>0.96194</td>\n",
              "      <td>0.96246</td>\n",
              "      <td>0.96273</td>\n",
              "      <td>0.96285</td>\n",
              "      <td>0.96288</td>\n",
              "      <td>0.96284</td>\n",
              "      <td>0.96275</td>\n",
              "      <td>0.96262</td>\n",
              "      <td>0.962460</td>\n",
              "      <td>0.962270</td>\n",
              "      <td>0.962050</td>\n",
              "      <td>0.96182</td>\n",
              "      <td>0.96156</td>\n",
              "      <td>0.96128</td>\n",
              "      <td>0.96099</td>\n",
              "      <td>0.96068</td>\n",
              "      <td>0.96035</td>\n",
              "      <td>0.96000</td>\n",
              "      <td>0.95964</td>\n",
              "      <td>0.95926</td>\n",
              "      <td>0.95887</td>\n",
              "      <td>...</td>\n",
              "      <td>0.789890</td>\n",
              "      <td>0.788790</td>\n",
              "      <td>0.78769</td>\n",
              "      <td>0.786600</td>\n",
              "      <td>0.785500</td>\n",
              "      <td>0.784410</td>\n",
              "      <td>0.783320</td>\n",
              "      <td>0.782240</td>\n",
              "      <td>0.781150</td>\n",
              "      <td>0.780070</td>\n",
              "      <td>0.778980</td>\n",
              "      <td>0.777900</td>\n",
              "      <td>0.776830</td>\n",
              "      <td>0.775750</td>\n",
              "      <td>0.774680</td>\n",
              "      <td>0.773600</td>\n",
              "      <td>0.772540</td>\n",
              "      <td>0.771470</td>\n",
              "      <td>0.77040</td>\n",
              "      <td>0.76934</td>\n",
              "      <td>0.768280</td>\n",
              "      <td>0.767220</td>\n",
              "      <td>0.766160</td>\n",
              "      <td>0.765110</td>\n",
              "      <td>0.764060</td>\n",
              "      <td>0.763010</td>\n",
              "      <td>0.761960</td>\n",
              "      <td>0.760910</td>\n",
              "      <td>0.759870</td>\n",
              "      <td>0.758830</td>\n",
              "      <td>0.757790</td>\n",
              "      <td>0.756760</td>\n",
              "      <td>0.755720</td>\n",
              "      <td>0.754690</td>\n",
              "      <td>0.753660</td>\n",
              "      <td>0.752640</td>\n",
              "      <td>0.75162</td>\n",
              "      <td>0.75060</td>\n",
              "      <td>0.74958</td>\n",
              "      <td>0.74856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29903</th>\n",
              "      <td>246.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>266.50</td>\n",
              "      <td>0.94036</td>\n",
              "      <td>0.94116</td>\n",
              "      <td>0.94194</td>\n",
              "      <td>0.94272</td>\n",
              "      <td>0.94348</td>\n",
              "      <td>0.944220</td>\n",
              "      <td>0.944960</td>\n",
              "      <td>0.945680</td>\n",
              "      <td>0.946380</td>\n",
              "      <td>0.947080</td>\n",
              "      <td>0.947760</td>\n",
              "      <td>0.948430</td>\n",
              "      <td>0.949080</td>\n",
              "      <td>0.94972</td>\n",
              "      <td>0.95035</td>\n",
              "      <td>0.95097</td>\n",
              "      <td>0.95157</td>\n",
              "      <td>0.95216</td>\n",
              "      <td>0.95274</td>\n",
              "      <td>0.95330</td>\n",
              "      <td>0.95385</td>\n",
              "      <td>0.95439</td>\n",
              "      <td>0.95492</td>\n",
              "      <td>0.95543</td>\n",
              "      <td>0.955930</td>\n",
              "      <td>0.956410</td>\n",
              "      <td>0.956890</td>\n",
              "      <td>0.95734</td>\n",
              "      <td>0.95779</td>\n",
              "      <td>0.95822</td>\n",
              "      <td>0.95864</td>\n",
              "      <td>0.95905</td>\n",
              "      <td>0.95945</td>\n",
              "      <td>0.95983</td>\n",
              "      <td>0.96020</td>\n",
              "      <td>0.96055</td>\n",
              "      <td>0.96090</td>\n",
              "      <td>...</td>\n",
              "      <td>0.876870</td>\n",
              "      <td>0.875930</td>\n",
              "      <td>0.87499</td>\n",
              "      <td>0.874040</td>\n",
              "      <td>0.873100</td>\n",
              "      <td>0.872160</td>\n",
              "      <td>0.871210</td>\n",
              "      <td>0.870260</td>\n",
              "      <td>0.869310</td>\n",
              "      <td>0.868360</td>\n",
              "      <td>0.867410</td>\n",
              "      <td>0.866460</td>\n",
              "      <td>0.865510</td>\n",
              "      <td>0.864560</td>\n",
              "      <td>0.863600</td>\n",
              "      <td>0.862650</td>\n",
              "      <td>0.861690</td>\n",
              "      <td>0.860730</td>\n",
              "      <td>0.85977</td>\n",
              "      <td>0.85882</td>\n",
              "      <td>0.857860</td>\n",
              "      <td>0.856900</td>\n",
              "      <td>0.855940</td>\n",
              "      <td>0.854980</td>\n",
              "      <td>0.854020</td>\n",
              "      <td>0.853050</td>\n",
              "      <td>0.852090</td>\n",
              "      <td>0.851130</td>\n",
              "      <td>0.850170</td>\n",
              "      <td>0.849200</td>\n",
              "      <td>0.848240</td>\n",
              "      <td>0.847280</td>\n",
              "      <td>0.846310</td>\n",
              "      <td>0.845350</td>\n",
              "      <td>0.844390</td>\n",
              "      <td>0.843420</td>\n",
              "      <td>0.84246</td>\n",
              "      <td>0.84149</td>\n",
              "      <td>0.84053</td>\n",
              "      <td>0.83957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46371</th>\n",
              "      <td>241.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>488.00</td>\n",
              "      <td>0.24575</td>\n",
              "      <td>0.21812</td>\n",
              "      <td>0.18871</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.12590</td>\n",
              "      <td>0.093892</td>\n",
              "      <td>0.063133</td>\n",
              "      <td>0.035588</td>\n",
              "      <td>0.013934</td>\n",
              "      <td>0.001542</td>\n",
              "      <td>0.002236</td>\n",
              "      <td>0.019722</td>\n",
              "      <td>0.056693</td>\n",
              "      <td>0.11380</td>\n",
              "      <td>0.18896</td>\n",
              "      <td>0.27740</td>\n",
              "      <td>0.37268</td>\n",
              "      <td>0.46815</td>\n",
              "      <td>0.55829</td>\n",
              "      <td>0.63939</td>\n",
              "      <td>0.70967</td>\n",
              "      <td>0.76883</td>\n",
              "      <td>0.81753</td>\n",
              "      <td>0.85697</td>\n",
              "      <td>0.888490</td>\n",
              "      <td>0.913450</td>\n",
              "      <td>0.933030</td>\n",
              "      <td>0.94828</td>\n",
              "      <td>0.96006</td>\n",
              "      <td>0.96908</td>\n",
              "      <td>0.97591</td>\n",
              "      <td>0.98100</td>\n",
              "      <td>0.98472</td>\n",
              "      <td>0.98736</td>\n",
              "      <td>0.98915</td>\n",
              "      <td>0.99027</td>\n",
              "      <td>0.99087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.940760</td>\n",
              "      <td>0.940160</td>\n",
              "      <td>0.93955</td>\n",
              "      <td>0.938940</td>\n",
              "      <td>0.938330</td>\n",
              "      <td>0.937710</td>\n",
              "      <td>0.937090</td>\n",
              "      <td>0.936460</td>\n",
              "      <td>0.935830</td>\n",
              "      <td>0.935200</td>\n",
              "      <td>0.934560</td>\n",
              "      <td>0.933920</td>\n",
              "      <td>0.933270</td>\n",
              "      <td>0.932620</td>\n",
              "      <td>0.931970</td>\n",
              "      <td>0.931310</td>\n",
              "      <td>0.930650</td>\n",
              "      <td>0.929990</td>\n",
              "      <td>0.92932</td>\n",
              "      <td>0.92865</td>\n",
              "      <td>0.927980</td>\n",
              "      <td>0.927300</td>\n",
              "      <td>0.926630</td>\n",
              "      <td>0.925950</td>\n",
              "      <td>0.925270</td>\n",
              "      <td>0.924590</td>\n",
              "      <td>0.923900</td>\n",
              "      <td>0.923210</td>\n",
              "      <td>0.922530</td>\n",
              "      <td>0.921840</td>\n",
              "      <td>0.921150</td>\n",
              "      <td>0.920460</td>\n",
              "      <td>0.919770</td>\n",
              "      <td>0.919080</td>\n",
              "      <td>0.918380</td>\n",
              "      <td>0.917690</td>\n",
              "      <td>0.91700</td>\n",
              "      <td>0.91631</td>\n",
              "      <td>0.91562</td>\n",
              "      <td>0.91493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5392</th>\n",
              "      <td>247.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>464.00</td>\n",
              "      <td>0.91552</td>\n",
              "      <td>0.91334</td>\n",
              "      <td>0.91131</td>\n",
              "      <td>0.90942</td>\n",
              "      <td>0.90766</td>\n",
              "      <td>0.906020</td>\n",
              "      <td>0.904510</td>\n",
              "      <td>0.903110</td>\n",
              "      <td>0.901810</td>\n",
              "      <td>0.900620</td>\n",
              "      <td>0.899530</td>\n",
              "      <td>0.898540</td>\n",
              "      <td>0.897630</td>\n",
              "      <td>0.89680</td>\n",
              "      <td>0.89606</td>\n",
              "      <td>0.89539</td>\n",
              "      <td>0.89480</td>\n",
              "      <td>0.89427</td>\n",
              "      <td>0.89382</td>\n",
              "      <td>0.89342</td>\n",
              "      <td>0.89309</td>\n",
              "      <td>0.89281</td>\n",
              "      <td>0.89259</td>\n",
              "      <td>0.89241</td>\n",
              "      <td>0.892290</td>\n",
              "      <td>0.892220</td>\n",
              "      <td>0.892190</td>\n",
              "      <td>0.89220</td>\n",
              "      <td>0.89226</td>\n",
              "      <td>0.89235</td>\n",
              "      <td>0.89248</td>\n",
              "      <td>0.89265</td>\n",
              "      <td>0.89285</td>\n",
              "      <td>0.89308</td>\n",
              "      <td>0.89334</td>\n",
              "      <td>0.89363</td>\n",
              "      <td>0.89395</td>\n",
              "      <td>...</td>\n",
              "      <td>0.962280</td>\n",
              "      <td>0.962090</td>\n",
              "      <td>0.96190</td>\n",
              "      <td>0.961710</td>\n",
              "      <td>0.961520</td>\n",
              "      <td>0.961330</td>\n",
              "      <td>0.961130</td>\n",
              "      <td>0.960940</td>\n",
              "      <td>0.960750</td>\n",
              "      <td>0.960560</td>\n",
              "      <td>0.960380</td>\n",
              "      <td>0.960200</td>\n",
              "      <td>0.960020</td>\n",
              "      <td>0.959850</td>\n",
              "      <td>0.959690</td>\n",
              "      <td>0.959540</td>\n",
              "      <td>0.959400</td>\n",
              "      <td>0.959270</td>\n",
              "      <td>0.95915</td>\n",
              "      <td>0.95906</td>\n",
              "      <td>0.958980</td>\n",
              "      <td>0.958930</td>\n",
              "      <td>0.958900</td>\n",
              "      <td>0.958900</td>\n",
              "      <td>0.958940</td>\n",
              "      <td>0.959020</td>\n",
              "      <td>0.959140</td>\n",
              "      <td>0.959310</td>\n",
              "      <td>0.959530</td>\n",
              "      <td>0.959820</td>\n",
              "      <td>0.960180</td>\n",
              "      <td>0.960610</td>\n",
              "      <td>0.961120</td>\n",
              "      <td>0.961690</td>\n",
              "      <td>0.962290</td>\n",
              "      <td>0.962850</td>\n",
              "      <td>0.96320</td>\n",
              "      <td>0.96291</td>\n",
              "      <td>0.96095</td>\n",
              "      <td>0.95454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46762</th>\n",
              "      <td>241.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>350.00</td>\n",
              "      <td>0.78254</td>\n",
              "      <td>0.78422</td>\n",
              "      <td>0.78590</td>\n",
              "      <td>0.78758</td>\n",
              "      <td>0.78925</td>\n",
              "      <td>0.790920</td>\n",
              "      <td>0.792590</td>\n",
              "      <td>0.794250</td>\n",
              "      <td>0.795910</td>\n",
              "      <td>0.797570</td>\n",
              "      <td>0.799220</td>\n",
              "      <td>0.800870</td>\n",
              "      <td>0.802520</td>\n",
              "      <td>0.80416</td>\n",
              "      <td>0.80580</td>\n",
              "      <td>0.80744</td>\n",
              "      <td>0.80907</td>\n",
              "      <td>0.81070</td>\n",
              "      <td>0.81232</td>\n",
              "      <td>0.81394</td>\n",
              "      <td>0.81555</td>\n",
              "      <td>0.81716</td>\n",
              "      <td>0.81877</td>\n",
              "      <td>0.82037</td>\n",
              "      <td>0.821970</td>\n",
              "      <td>0.823560</td>\n",
              "      <td>0.825140</td>\n",
              "      <td>0.82672</td>\n",
              "      <td>0.82830</td>\n",
              "      <td>0.82987</td>\n",
              "      <td>0.83144</td>\n",
              "      <td>0.83300</td>\n",
              "      <td>0.83455</td>\n",
              "      <td>0.83610</td>\n",
              "      <td>0.83764</td>\n",
              "      <td>0.83918</td>\n",
              "      <td>0.84071</td>\n",
              "      <td>...</td>\n",
              "      <td>0.961780</td>\n",
              "      <td>0.961530</td>\n",
              "      <td>0.96127</td>\n",
              "      <td>0.961000</td>\n",
              "      <td>0.960720</td>\n",
              "      <td>0.960430</td>\n",
              "      <td>0.960130</td>\n",
              "      <td>0.959820</td>\n",
              "      <td>0.959510</td>\n",
              "      <td>0.959180</td>\n",
              "      <td>0.958850</td>\n",
              "      <td>0.958510</td>\n",
              "      <td>0.958160</td>\n",
              "      <td>0.957790</td>\n",
              "      <td>0.957430</td>\n",
              "      <td>0.957050</td>\n",
              "      <td>0.956660</td>\n",
              "      <td>0.956270</td>\n",
              "      <td>0.95586</td>\n",
              "      <td>0.95545</td>\n",
              "      <td>0.955030</td>\n",
              "      <td>0.954600</td>\n",
              "      <td>0.954170</td>\n",
              "      <td>0.953720</td>\n",
              "      <td>0.953270</td>\n",
              "      <td>0.952810</td>\n",
              "      <td>0.952340</td>\n",
              "      <td>0.951860</td>\n",
              "      <td>0.951380</td>\n",
              "      <td>0.950890</td>\n",
              "      <td>0.950390</td>\n",
              "      <td>0.949880</td>\n",
              "      <td>0.949360</td>\n",
              "      <td>0.948840</td>\n",
              "      <td>0.948310</td>\n",
              "      <td>0.947770</td>\n",
              "      <td>0.94723</td>\n",
              "      <td>0.94668</td>\n",
              "      <td>0.94612</td>\n",
              "      <td>0.94555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3427</th>\n",
              "      <td>245.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>387.75</td>\n",
              "      <td>0.53011</td>\n",
              "      <td>0.35218</td>\n",
              "      <td>0.00065</td>\n",
              "      <td>0.87334</td>\n",
              "      <td>0.99334</td>\n",
              "      <td>0.955500</td>\n",
              "      <td>0.924960</td>\n",
              "      <td>0.904260</td>\n",
              "      <td>0.889990</td>\n",
              "      <td>0.879830</td>\n",
              "      <td>0.872400</td>\n",
              "      <td>0.866870</td>\n",
              "      <td>0.862700</td>\n",
              "      <td>0.85954</td>\n",
              "      <td>0.85715</td>\n",
              "      <td>0.85534</td>\n",
              "      <td>0.85401</td>\n",
              "      <td>0.85305</td>\n",
              "      <td>0.85240</td>\n",
              "      <td>0.85201</td>\n",
              "      <td>0.85182</td>\n",
              "      <td>0.85181</td>\n",
              "      <td>0.85195</td>\n",
              "      <td>0.85222</td>\n",
              "      <td>0.852600</td>\n",
              "      <td>0.853080</td>\n",
              "      <td>0.853640</td>\n",
              "      <td>0.85427</td>\n",
              "      <td>0.85497</td>\n",
              "      <td>0.85572</td>\n",
              "      <td>0.85652</td>\n",
              "      <td>0.85736</td>\n",
              "      <td>0.85824</td>\n",
              "      <td>0.85916</td>\n",
              "      <td>0.86011</td>\n",
              "      <td>0.86108</td>\n",
              "      <td>0.86208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.960340</td>\n",
              "      <td>0.960030</td>\n",
              "      <td>0.95972</td>\n",
              "      <td>0.959390</td>\n",
              "      <td>0.959060</td>\n",
              "      <td>0.958720</td>\n",
              "      <td>0.958370</td>\n",
              "      <td>0.958010</td>\n",
              "      <td>0.957640</td>\n",
              "      <td>0.957260</td>\n",
              "      <td>0.956880</td>\n",
              "      <td>0.956490</td>\n",
              "      <td>0.956090</td>\n",
              "      <td>0.955680</td>\n",
              "      <td>0.955260</td>\n",
              "      <td>0.954830</td>\n",
              "      <td>0.954400</td>\n",
              "      <td>0.953960</td>\n",
              "      <td>0.95351</td>\n",
              "      <td>0.95305</td>\n",
              "      <td>0.952580</td>\n",
              "      <td>0.952110</td>\n",
              "      <td>0.951630</td>\n",
              "      <td>0.951140</td>\n",
              "      <td>0.950640</td>\n",
              "      <td>0.950140</td>\n",
              "      <td>0.949630</td>\n",
              "      <td>0.949110</td>\n",
              "      <td>0.948580</td>\n",
              "      <td>0.948050</td>\n",
              "      <td>0.947510</td>\n",
              "      <td>0.946960</td>\n",
              "      <td>0.946400</td>\n",
              "      <td>0.945840</td>\n",
              "      <td>0.945270</td>\n",
              "      <td>0.944700</td>\n",
              "      <td>0.94411</td>\n",
              "      <td>0.94353</td>\n",
              "      <td>0.94293</td>\n",
              "      <td>0.94233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36256</th>\n",
              "      <td>249.0</td>\n",
              "      <td>920.0</td>\n",
              "      <td>391.00</td>\n",
              "      <td>0.66613</td>\n",
              "      <td>0.66762</td>\n",
              "      <td>0.66883</td>\n",
              "      <td>0.66975</td>\n",
              "      <td>0.67033</td>\n",
              "      <td>0.670540</td>\n",
              "      <td>0.670310</td>\n",
              "      <td>0.669570</td>\n",
              "      <td>0.668220</td>\n",
              "      <td>0.666130</td>\n",
              "      <td>0.663120</td>\n",
              "      <td>0.658950</td>\n",
              "      <td>0.653290</td>\n",
              "      <td>0.64567</td>\n",
              "      <td>0.63545</td>\n",
              "      <td>0.62172</td>\n",
              "      <td>0.60317</td>\n",
              "      <td>0.57792</td>\n",
              "      <td>0.54333</td>\n",
              "      <td>0.49583</td>\n",
              "      <td>0.43104</td>\n",
              "      <td>0.34515</td>\n",
              "      <td>0.23893</td>\n",
              "      <td>0.12535</td>\n",
              "      <td>0.034514</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.029944</td>\n",
              "      <td>0.10153</td>\n",
              "      <td>0.18538</td>\n",
              "      <td>0.26337</td>\n",
              "      <td>0.32899</td>\n",
              "      <td>0.38186</td>\n",
              "      <td>0.42381</td>\n",
              "      <td>0.45704</td>\n",
              "      <td>0.48347</td>\n",
              "      <td>0.50465</td>\n",
              "      <td>0.52176</td>\n",
              "      <td>...</td>\n",
              "      <td>0.426650</td>\n",
              "      <td>0.426300</td>\n",
              "      <td>0.42596</td>\n",
              "      <td>0.425630</td>\n",
              "      <td>0.425310</td>\n",
              "      <td>0.425010</td>\n",
              "      <td>0.424710</td>\n",
              "      <td>0.424430</td>\n",
              "      <td>0.424150</td>\n",
              "      <td>0.423890</td>\n",
              "      <td>0.423640</td>\n",
              "      <td>0.423390</td>\n",
              "      <td>0.423160</td>\n",
              "      <td>0.422940</td>\n",
              "      <td>0.422740</td>\n",
              "      <td>0.422540</td>\n",
              "      <td>0.422350</td>\n",
              "      <td>0.422170</td>\n",
              "      <td>0.42201</td>\n",
              "      <td>0.42185</td>\n",
              "      <td>0.421710</td>\n",
              "      <td>0.421580</td>\n",
              "      <td>0.421460</td>\n",
              "      <td>0.421350</td>\n",
              "      <td>0.421250</td>\n",
              "      <td>0.421160</td>\n",
              "      <td>0.421080</td>\n",
              "      <td>0.421020</td>\n",
              "      <td>0.420960</td>\n",
              "      <td>0.420920</td>\n",
              "      <td>0.420890</td>\n",
              "      <td>0.420860</td>\n",
              "      <td>0.420850</td>\n",
              "      <td>0.420860</td>\n",
              "      <td>0.420870</td>\n",
              "      <td>0.420890</td>\n",
              "      <td>0.42093</td>\n",
              "      <td>0.42098</td>\n",
              "      <td>0.42104</td>\n",
              "      <td>0.42111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1190</th>\n",
              "      <td>205.0</td>\n",
              "      <td>950.0</td>\n",
              "      <td>498.75</td>\n",
              "      <td>0.73500</td>\n",
              "      <td>0.73609</td>\n",
              "      <td>0.73653</td>\n",
              "      <td>0.73638</td>\n",
              "      <td>0.73571</td>\n",
              "      <td>0.734550</td>\n",
              "      <td>0.732950</td>\n",
              "      <td>0.730930</td>\n",
              "      <td>0.728530</td>\n",
              "      <td>0.725750</td>\n",
              "      <td>0.722620</td>\n",
              "      <td>0.719150</td>\n",
              "      <td>0.715340</td>\n",
              "      <td>0.71121</td>\n",
              "      <td>0.70676</td>\n",
              "      <td>0.70200</td>\n",
              "      <td>0.69692</td>\n",
              "      <td>0.69153</td>\n",
              "      <td>0.68583</td>\n",
              "      <td>0.67982</td>\n",
              "      <td>0.67349</td>\n",
              "      <td>0.66685</td>\n",
              "      <td>0.65989</td>\n",
              "      <td>0.65260</td>\n",
              "      <td>0.644990</td>\n",
              "      <td>0.637040</td>\n",
              "      <td>0.628750</td>\n",
              "      <td>0.62011</td>\n",
              "      <td>0.61111</td>\n",
              "      <td>0.60175</td>\n",
              "      <td>0.59201</td>\n",
              "      <td>0.58189</td>\n",
              "      <td>0.57136</td>\n",
              "      <td>0.56043</td>\n",
              "      <td>0.54906</td>\n",
              "      <td>0.53724</td>\n",
              "      <td>0.52496</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054564</td>\n",
              "      <td>0.055872</td>\n",
              "      <td>0.05718</td>\n",
              "      <td>0.058488</td>\n",
              "      <td>0.059796</td>\n",
              "      <td>0.061103</td>\n",
              "      <td>0.062409</td>\n",
              "      <td>0.063714</td>\n",
              "      <td>0.065018</td>\n",
              "      <td>0.066321</td>\n",
              "      <td>0.067622</td>\n",
              "      <td>0.068921</td>\n",
              "      <td>0.070218</td>\n",
              "      <td>0.071513</td>\n",
              "      <td>0.072806</td>\n",
              "      <td>0.074096</td>\n",
              "      <td>0.075384</td>\n",
              "      <td>0.076668</td>\n",
              "      <td>0.07795</td>\n",
              "      <td>0.07923</td>\n",
              "      <td>0.080506</td>\n",
              "      <td>0.081778</td>\n",
              "      <td>0.083048</td>\n",
              "      <td>0.084314</td>\n",
              "      <td>0.085577</td>\n",
              "      <td>0.086836</td>\n",
              "      <td>0.088092</td>\n",
              "      <td>0.089344</td>\n",
              "      <td>0.090592</td>\n",
              "      <td>0.091836</td>\n",
              "      <td>0.093077</td>\n",
              "      <td>0.094313</td>\n",
              "      <td>0.095546</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>0.097999</td>\n",
              "      <td>0.099219</td>\n",
              "      <td>0.10044</td>\n",
              "      <td>0.10165</td>\n",
              "      <td>0.10285</td>\n",
              "      <td>0.10406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37551</th>\n",
              "      <td>233.0</td>\n",
              "      <td>640.0</td>\n",
              "      <td>320.00</td>\n",
              "      <td>0.91882</td>\n",
              "      <td>0.91825</td>\n",
              "      <td>0.91771</td>\n",
              "      <td>0.91719</td>\n",
              "      <td>0.91671</td>\n",
              "      <td>0.916250</td>\n",
              "      <td>0.915830</td>\n",
              "      <td>0.915440</td>\n",
              "      <td>0.915090</td>\n",
              "      <td>0.914780</td>\n",
              "      <td>0.914510</td>\n",
              "      <td>0.914280</td>\n",
              "      <td>0.914100</td>\n",
              "      <td>0.91397</td>\n",
              "      <td>0.91389</td>\n",
              "      <td>0.91387</td>\n",
              "      <td>0.91390</td>\n",
              "      <td>0.91400</td>\n",
              "      <td>0.91417</td>\n",
              "      <td>0.91441</td>\n",
              "      <td>0.91472</td>\n",
              "      <td>0.91512</td>\n",
              "      <td>0.91560</td>\n",
              "      <td>0.91617</td>\n",
              "      <td>0.916840</td>\n",
              "      <td>0.917610</td>\n",
              "      <td>0.918500</td>\n",
              "      <td>0.91950</td>\n",
              "      <td>0.92062</td>\n",
              "      <td>0.92188</td>\n",
              "      <td>0.92328</td>\n",
              "      <td>0.92483</td>\n",
              "      <td>0.92654</td>\n",
              "      <td>0.92841</td>\n",
              "      <td>0.93045</td>\n",
              "      <td>0.93267</td>\n",
              "      <td>0.93506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.593260</td>\n",
              "      <td>0.592640</td>\n",
              "      <td>0.59202</td>\n",
              "      <td>0.591410</td>\n",
              "      <td>0.590790</td>\n",
              "      <td>0.590180</td>\n",
              "      <td>0.589570</td>\n",
              "      <td>0.588960</td>\n",
              "      <td>0.588350</td>\n",
              "      <td>0.587740</td>\n",
              "      <td>0.587140</td>\n",
              "      <td>0.586540</td>\n",
              "      <td>0.585940</td>\n",
              "      <td>0.585340</td>\n",
              "      <td>0.584740</td>\n",
              "      <td>0.584150</td>\n",
              "      <td>0.583560</td>\n",
              "      <td>0.582970</td>\n",
              "      <td>0.58238</td>\n",
              "      <td>0.58180</td>\n",
              "      <td>0.581220</td>\n",
              "      <td>0.580640</td>\n",
              "      <td>0.580060</td>\n",
              "      <td>0.579480</td>\n",
              "      <td>0.578910</td>\n",
              "      <td>0.578340</td>\n",
              "      <td>0.577770</td>\n",
              "      <td>0.577200</td>\n",
              "      <td>0.576640</td>\n",
              "      <td>0.576070</td>\n",
              "      <td>0.575510</td>\n",
              "      <td>0.574950</td>\n",
              "      <td>0.574400</td>\n",
              "      <td>0.573850</td>\n",
              "      <td>0.573290</td>\n",
              "      <td>0.572740</td>\n",
              "      <td>0.57220</td>\n",
              "      <td>0.57165</td>\n",
              "      <td>0.57111</td>\n",
              "      <td>0.57057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40097</th>\n",
              "      <td>207.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>246.50</td>\n",
              "      <td>0.53694</td>\n",
              "      <td>0.53640</td>\n",
              "      <td>0.53586</td>\n",
              "      <td>0.53533</td>\n",
              "      <td>0.53480</td>\n",
              "      <td>0.534270</td>\n",
              "      <td>0.533750</td>\n",
              "      <td>0.533230</td>\n",
              "      <td>0.532720</td>\n",
              "      <td>0.532210</td>\n",
              "      <td>0.531700</td>\n",
              "      <td>0.531200</td>\n",
              "      <td>0.530690</td>\n",
              "      <td>0.53020</td>\n",
              "      <td>0.52970</td>\n",
              "      <td>0.52921</td>\n",
              "      <td>0.52873</td>\n",
              "      <td>0.52825</td>\n",
              "      <td>0.52777</td>\n",
              "      <td>0.52729</td>\n",
              "      <td>0.52682</td>\n",
              "      <td>0.52635</td>\n",
              "      <td>0.52588</td>\n",
              "      <td>0.52542</td>\n",
              "      <td>0.524960</td>\n",
              "      <td>0.524510</td>\n",
              "      <td>0.524060</td>\n",
              "      <td>0.52361</td>\n",
              "      <td>0.52316</td>\n",
              "      <td>0.52272</td>\n",
              "      <td>0.52228</td>\n",
              "      <td>0.52185</td>\n",
              "      <td>0.52142</td>\n",
              "      <td>0.52099</td>\n",
              "      <td>0.52056</td>\n",
              "      <td>0.52014</td>\n",
              "      <td>0.51972</td>\n",
              "      <td>...</td>\n",
              "      <td>0.482780</td>\n",
              "      <td>0.482720</td>\n",
              "      <td>0.48266</td>\n",
              "      <td>0.482590</td>\n",
              "      <td>0.482540</td>\n",
              "      <td>0.482480</td>\n",
              "      <td>0.482420</td>\n",
              "      <td>0.482360</td>\n",
              "      <td>0.482310</td>\n",
              "      <td>0.482260</td>\n",
              "      <td>0.482200</td>\n",
              "      <td>0.482150</td>\n",
              "      <td>0.482100</td>\n",
              "      <td>0.482050</td>\n",
              "      <td>0.482000</td>\n",
              "      <td>0.481960</td>\n",
              "      <td>0.481910</td>\n",
              "      <td>0.481860</td>\n",
              "      <td>0.48182</td>\n",
              "      <td>0.48178</td>\n",
              "      <td>0.481740</td>\n",
              "      <td>0.481700</td>\n",
              "      <td>0.481660</td>\n",
              "      <td>0.481620</td>\n",
              "      <td>0.481580</td>\n",
              "      <td>0.481540</td>\n",
              "      <td>0.481510</td>\n",
              "      <td>0.481470</td>\n",
              "      <td>0.481440</td>\n",
              "      <td>0.481410</td>\n",
              "      <td>0.481370</td>\n",
              "      <td>0.481340</td>\n",
              "      <td>0.481310</td>\n",
              "      <td>0.481290</td>\n",
              "      <td>0.481260</td>\n",
              "      <td>0.481230</td>\n",
              "      <td>0.48121</td>\n",
              "      <td>0.48118</td>\n",
              "      <td>0.48116</td>\n",
              "      <td>0.48113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52311 rows × 254 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       # t_s  period    w_si   1400.0  ...   1647.0   1648.0   1649.0   1650.0\n",
              "40603  210.0   910.0  796.25  0.96503  ...  0.75162  0.75060  0.74958  0.74856\n",
              "29903  246.0   410.0  266.50  0.94036  ...  0.84246  0.84149  0.84053  0.83957\n",
              "46371  241.0   610.0  488.00  0.24575  ...  0.91700  0.91631  0.91562  0.91493\n",
              "5392   247.0   580.0  464.00  0.91552  ...  0.96320  0.96291  0.96095  0.95454\n",
              "46762  241.0   400.0  350.00  0.78254  ...  0.94723  0.94668  0.94612  0.94555\n",
              "...      ...     ...     ...      ...  ...      ...      ...      ...      ...\n",
              "3427   245.0   470.0  387.75  0.53011  ...  0.94411  0.94353  0.94293  0.94233\n",
              "36256  249.0   920.0  391.00  0.66613  ...  0.42093  0.42098  0.42104  0.42111\n",
              "1190   205.0   950.0  498.75  0.73500  ...  0.10044  0.10165  0.10285  0.10406\n",
              "37551  233.0   640.0  320.00  0.91882  ...  0.57220  0.57165  0.57111  0.57057\n",
              "40097  207.0   580.0  246.50  0.53694  ...  0.48121  0.48118  0.48116  0.48113\n",
              "\n",
              "[52311 rows x 254 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAIEKXYEcgT3"
      },
      "source": [
        "X = df.drop(['period'], 1)\n",
        "Y = df.drop(X, 1)\n",
        "\n",
        "#X = df.values[:, :3]\n",
        "#Y = df.values[:, 3:]\n",
        "X = X.values\n",
        "Y = Y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QfMIZNAcklH"
      },
      "source": [
        "Y = scaler_period.transform(Y)\n",
        "\n",
        "X[:, 0:1] = scaler_ts.transform(X[:, 0:1])\n",
        "X[:, 1:2] = scaler_wsi.transform(X[:, 1:2])\n",
        "X[:, 2:] = scaler_R.transform(X[:, 2:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SizbZ8KLco54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031eab2e-6775-460b-e0b3-a311a0deb5fe"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47079, 253) (5232, 253) (47079, 1) (5232, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwYd3TXecrJg"
      },
      "source": [
        "model_period = Sequential([\n",
        "    Dense(40, activation='relu', input_shape=X_train[0].shape),\n",
        "    Dense(40, activation='relu'),\n",
        "    Dense(40, activation='relu'),\n",
        "    Dense(40, activation='relu'),\n",
        "    Dense(40, activation='relu'),\n",
        "    Dense(40, activation='relu'),\n",
        "    Dense(1, activation= 'linear')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxeKz0jNcuhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b712016-7c37-467f-ba78-a61d70fae16b"
      },
      "source": [
        "model_period.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = tf.losses.MeanSquaredError(),\n",
        "              metrics=['acc'])\n",
        "\n",
        "hist = model_period.fit(X_train, Y_train,\n",
        "          batch_size=100, epochs=400, \n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.1437 - acc: 0.0000e+00 - val_loss: 0.0509 - val_acc: 0.0000e+00\n",
            "Epoch 2/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
            "Epoch 3/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
            "Epoch 4/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
            "Epoch 5/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
            "Epoch 6/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
            "Epoch 7/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
            "Epoch 8/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
            "Epoch 9/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
            "Epoch 10/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.0000e+00 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
            "Epoch 11/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0065 - acc: 0.0000e+00 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
            "Epoch 12/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0065 - acc: 0.0000e+00 - val_loss: 0.0175 - val_acc: 0.0000e+00\n",
            "Epoch 13/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0067 - acc: 0.0000e+00 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
            "Epoch 14/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0064 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
            "Epoch 15/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
            "Epoch 16/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 17/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 18/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
            "Epoch 19/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 20/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
            "Epoch 21/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 22/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 23/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
            "Epoch 24/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 25/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 26/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 27/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 28/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 29/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 30/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 31/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 32/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
            "Epoch 33/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 34/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 35/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 36/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 37/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 38/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 39/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 40/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 41/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 42/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 43/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 44/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 45/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 46/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 47/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 48/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 49/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 50/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 51/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 52/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 53/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 54/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 55/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 56/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 57/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 58/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 59/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 60/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
            "Epoch 61/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 62/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 63/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 64/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 65/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 66/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 67/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 68/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 69/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 70/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 71/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 72/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 73/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 74/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 75/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 76/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 77/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 78/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 79/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 7.3976e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 81/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 9.6948e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 83/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 84/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 85/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 86/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 9.4215e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 88/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 9.8239e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 7.0873e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 91/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 92/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 93/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 94/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 8.9106e-04 - val_acc: 0.0000e+00\n",
            "Epoch 95/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 96/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 7.2486e-04 - val_acc: 0.0000e+00\n",
            "Epoch 97/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 6.1829e-04 - val_acc: 0.0000e+00\n",
            "Epoch 98/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 9.5121e-04 - val_acc: 0.0000e+00\n",
            "Epoch 99/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 100/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 101/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 102/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 7.5478e-04 - val_acc: 0.0000e+00\n",
            "Epoch 103/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.9856e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 104/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 9.7576e-04 - val_acc: 0.0000e+00\n",
            "Epoch 105/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 6.8400e-04 - val_acc: 0.0000e+00\n",
            "Epoch 106/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.5967e-04 - acc: 0.0000e+00 - val_loss: 6.4264e-04 - val_acc: 0.0000e+00\n",
            "Epoch 107/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 108/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 8.9268e-04 - val_acc: 0.0000e+00\n",
            "Epoch 109/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 110/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.6593e-04 - acc: 0.0000e+00 - val_loss: 7.5022e-04 - val_acc: 0.0000e+00\n",
            "Epoch 111/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 112/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 113/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.4906e-04 - acc: 0.0000e+00 - val_loss: 6.4455e-04 - val_acc: 0.0000e+00\n",
            "Epoch 114/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 9.9394e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 115/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 116/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 6.3990e-04 - val_acc: 0.0000e+00\n",
            "Epoch 117/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.2869e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 118/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 6.7439e-04 - val_acc: 0.0000e+00\n",
            "Epoch 119/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.2093e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 120/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 6.0079e-04 - val_acc: 0.0000e+00\n",
            "Epoch 121/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 122/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 5.7837e-04 - val_acc: 0.0000e+00\n",
            "Epoch 123/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 124/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.3502e-04 - acc: 0.0000e+00 - val_loss: 6.4893e-04 - val_acc: 0.0000e+00\n",
            "Epoch 125/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.4908e-04 - acc: 0.0000e+00 - val_loss: 7.9894e-04 - val_acc: 0.0000e+00\n",
            "Epoch 126/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.9458e-04 - acc: 0.0000e+00 - val_loss: 5.8690e-04 - val_acc: 0.0000e+00\n",
            "Epoch 127/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.1840e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 128/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 6.3764e-04 - val_acc: 0.0000e+00\n",
            "Epoch 129/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 5.9415e-04 - val_acc: 0.0000e+00\n",
            "Epoch 130/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 7.7632e-04 - val_acc: 0.0000e+00\n",
            "Epoch 131/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.3791e-04 - acc: 0.0000e+00 - val_loss: 4.9602e-04 - val_acc: 0.0000e+00\n",
            "Epoch 132/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 5.2076e-04 - val_acc: 0.0000e+00\n",
            "Epoch 133/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.7276e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 134/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.8498e-04 - acc: 0.0000e+00 - val_loss: 7.2492e-04 - val_acc: 0.0000e+00\n",
            "Epoch 135/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.7808e-04 - acc: 0.0000e+00 - val_loss: 7.9326e-04 - val_acc: 0.0000e+00\n",
            "Epoch 136/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 8.9184e-04 - val_acc: 0.0000e+00\n",
            "Epoch 137/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 9.3871e-04 - val_acc: 0.0000e+00\n",
            "Epoch 138/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.2163e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 139/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.8394e-04 - acc: 0.0000e+00 - val_loss: 7.4778e-04 - val_acc: 0.0000e+00\n",
            "Epoch 140/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 141/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.7735e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 142/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 8.1363e-04 - val_acc: 0.0000e+00\n",
            "Epoch 143/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.7083e-04 - acc: 0.0000e+00 - val_loss: 6.4205e-04 - val_acc: 0.0000e+00\n",
            "Epoch 144/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 145/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 146/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.9390e-04 - acc: 0.0000e+00 - val_loss: 5.2875e-04 - val_acc: 0.0000e+00\n",
            "Epoch 147/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.3992e-04 - acc: 0.0000e+00 - val_loss: 7.2853e-04 - val_acc: 0.0000e+00\n",
            "Epoch 148/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.5881e-04 - acc: 0.0000e+00 - val_loss: 5.3799e-04 - val_acc: 0.0000e+00\n",
            "Epoch 149/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 150/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.9020e-04 - acc: 0.0000e+00 - val_loss: 8.5409e-04 - val_acc: 0.0000e+00\n",
            "Epoch 151/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.5018e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 152/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 153/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.4192e-04 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 154/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 7.8354e-04 - val_acc: 0.0000e+00\n",
            "Epoch 155/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 5.5829e-04 - val_acc: 0.0000e+00\n",
            "Epoch 156/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.1537e-04 - acc: 0.0000e+00 - val_loss: 6.1868e-04 - val_acc: 0.0000e+00\n",
            "Epoch 157/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.5608e-04 - acc: 0.0000e+00 - val_loss: 9.1197e-04 - val_acc: 0.0000e+00\n",
            "Epoch 158/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.6963e-04 - acc: 0.0000e+00 - val_loss: 4.6935e-04 - val_acc: 0.0000e+00\n",
            "Epoch 159/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.2526e-04 - acc: 0.0000e+00 - val_loss: 7.0011e-04 - val_acc: 0.0000e+00\n",
            "Epoch 160/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 6.7093e-04 - val_acc: 0.0000e+00\n",
            "Epoch 161/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 162/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 5.1592e-04 - val_acc: 0.0000e+00\n",
            "Epoch 163/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.2652e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 164/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.3612e-04 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
            "Epoch 165/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 5.1538e-04 - val_acc: 0.0000e+00\n",
            "Epoch 166/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 8.0184e-04 - val_acc: 0.0000e+00\n",
            "Epoch 167/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.6353e-04 - acc: 0.0000e+00 - val_loss: 9.9555e-04 - val_acc: 0.0000e+00\n",
            "Epoch 168/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.3888e-04 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 169/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.7086e-04 - acc: 0.0000e+00 - val_loss: 4.2778e-04 - val_acc: 0.0000e+00\n",
            "Epoch 170/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.0441e-04 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 171/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 8.6137e-04 - val_acc: 0.0000e+00\n",
            "Epoch 172/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.5772e-04 - acc: 0.0000e+00 - val_loss: 6.3457e-04 - val_acc: 0.0000e+00\n",
            "Epoch 173/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 6.5688e-04 - val_acc: 0.0000e+00\n",
            "Epoch 174/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.7702e-04 - acc: 0.0000e+00 - val_loss: 4.9431e-04 - val_acc: 0.0000e+00\n",
            "Epoch 175/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.7161e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 176/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 6.4209e-04 - acc: 0.0000e+00 - val_loss: 7.6931e-04 - val_acc: 0.0000e+00\n",
            "Epoch 177/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 178/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 9.2796e-04 - acc: 0.0000e+00 - val_loss: 6.1204e-04 - val_acc: 0.0000e+00\n",
            "Epoch 179/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 8.7258e-04 - acc: 0.0000e+00 - val_loss: 8.2926e-04 - val_acc: 0.0000e+00\n",
            "Epoch 180/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.8270e-04 - acc: 0.0000e+00 - val_loss: 3.9029e-04 - val_acc: 0.0000e+00\n",
            "Epoch 181/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.8812e-04 - acc: 0.0000e+00 - val_loss: 5.6061e-04 - val_acc: 0.0000e+00\n",
            "Epoch 182/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.9452e-04 - acc: 0.0000e+00 - val_loss: 6.1593e-04 - val_acc: 0.0000e+00\n",
            "Epoch 183/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.6206e-04 - acc: 0.0000e+00 - val_loss: 7.5112e-04 - val_acc: 0.0000e+00\n",
            "Epoch 184/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.5570e-04 - acc: 0.0000e+00 - val_loss: 7.5099e-04 - val_acc: 0.0000e+00\n",
            "Epoch 185/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 6.1506e-04 - val_acc: 0.0000e+00\n",
            "Epoch 186/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.6844e-04 - acc: 0.0000e+00 - val_loss: 5.1779e-04 - val_acc: 0.0000e+00\n",
            "Epoch 187/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.1672e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 188/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 7.3296e-04 - acc: 0.0000e+00 - val_loss: 5.4261e-04 - val_acc: 0.0000e+00\n",
            "Epoch 189/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.5404e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 190/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.0136e-04 - acc: 0.0000e+00 - val_loss: 7.1405e-04 - val_acc: 0.0000e+00\n",
            "Epoch 191/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.9053e-04 - acc: 0.0000e+00 - val_loss: 5.0013e-04 - val_acc: 0.0000e+00\n",
            "Epoch 192/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.5803e-04 - acc: 0.0000e+00 - val_loss: 5.3420e-04 - val_acc: 0.0000e+00\n",
            "Epoch 193/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 3.5896e-04 - val_acc: 0.0000e+00\n",
            "Epoch 194/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.4332e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 195/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.7766e-04 - acc: 0.0000e+00 - val_loss: 4.1060e-04 - val_acc: 0.0000e+00\n",
            "Epoch 196/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 5.6667e-04 - val_acc: 0.0000e+00\n",
            "Epoch 197/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.5347e-04 - acc: 0.0000e+00 - val_loss: 5.4078e-04 - val_acc: 0.0000e+00\n",
            "Epoch 198/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.1680e-04 - acc: 0.0000e+00 - val_loss: 8.1071e-04 - val_acc: 0.0000e+00\n",
            "Epoch 199/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.3117e-04 - acc: 0.0000e+00 - val_loss: 4.5470e-04 - val_acc: 0.0000e+00\n",
            "Epoch 200/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.9235e-04 - acc: 0.0000e+00 - val_loss: 6.7390e-04 - val_acc: 0.0000e+00\n",
            "Epoch 201/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.3845e-04 - acc: 0.0000e+00 - val_loss: 8.5689e-04 - val_acc: 0.0000e+00\n",
            "Epoch 202/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.5510e-04 - acc: 0.0000e+00 - val_loss: 9.0613e-04 - val_acc: 0.0000e+00\n",
            "Epoch 203/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.5454e-04 - acc: 0.0000e+00 - val_loss: 6.2544e-04 - val_acc: 0.0000e+00\n",
            "Epoch 204/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.2810e-04 - acc: 0.0000e+00 - val_loss: 8.8179e-04 - val_acc: 0.0000e+00\n",
            "Epoch 205/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 6.7932e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 206/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.3590e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 207/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 5.5797e-04 - val_acc: 0.0000e+00\n",
            "Epoch 208/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.8613e-04 - acc: 0.0000e+00 - val_loss: 5.3150e-04 - val_acc: 0.0000e+00\n",
            "Epoch 209/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.6804e-04 - acc: 0.0000e+00 - val_loss: 4.6467e-04 - val_acc: 0.0000e+00\n",
            "Epoch 210/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.1722e-04 - acc: 0.0000e+00 - val_loss: 5.3997e-04 - val_acc: 0.0000e+00\n",
            "Epoch 211/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 6.0562e-04 - val_acc: 0.0000e+00\n",
            "Epoch 212/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.9557e-04 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 213/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.4146e-04 - acc: 0.0000e+00 - val_loss: 5.0474e-04 - val_acc: 0.0000e+00\n",
            "Epoch 214/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.5958e-04 - acc: 0.0000e+00 - val_loss: 3.9831e-04 - val_acc: 0.0000e+00\n",
            "Epoch 215/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.4945e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 216/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 6.0253e-04 - val_acc: 0.0000e+00\n",
            "Epoch 217/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.2666e-04 - acc: 0.0000e+00 - val_loss: 6.0700e-04 - val_acc: 0.0000e+00\n",
            "Epoch 218/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.2349e-04 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 219/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.4918e-04 - acc: 0.0000e+00 - val_loss: 7.7457e-04 - val_acc: 0.0000e+00\n",
            "Epoch 220/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.7452e-04 - acc: 0.0000e+00 - val_loss: 5.4564e-04 - val_acc: 0.0000e+00\n",
            "Epoch 221/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.1792e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 222/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 7.8872e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 223/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.9924e-04 - acc: 0.0000e+00 - val_loss: 8.8544e-04 - val_acc: 0.0000e+00\n",
            "Epoch 224/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
            "Epoch 225/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 6.9920e-04 - val_acc: 0.0000e+00\n",
            "Epoch 226/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.2680e-04 - acc: 0.0000e+00 - val_loss: 5.8361e-04 - val_acc: 0.0000e+00\n",
            "Epoch 227/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.6688e-04 - acc: 0.0000e+00 - val_loss: 5.8415e-04 - val_acc: 0.0000e+00\n",
            "Epoch 228/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 4.9495e-04 - val_acc: 0.0000e+00\n",
            "Epoch 229/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.0817e-04 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 230/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.3302e-04 - acc: 0.0000e+00 - val_loss: 4.7989e-04 - val_acc: 0.0000e+00\n",
            "Epoch 231/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.1402e-04 - acc: 0.0000e+00 - val_loss: 4.8419e-04 - val_acc: 0.0000e+00\n",
            "Epoch 232/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.1093e-04 - acc: 0.0000e+00 - val_loss: 7.3650e-04 - val_acc: 0.0000e+00\n",
            "Epoch 233/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.6776e-04 - acc: 0.0000e+00 - val_loss: 3.9973e-04 - val_acc: 0.0000e+00\n",
            "Epoch 234/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.7723e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 235/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.1862e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 236/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.5375e-04 - acc: 0.0000e+00 - val_loss: 3.6931e-04 - val_acc: 0.0000e+00\n",
            "Epoch 237/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.8439e-04 - acc: 0.0000e+00 - val_loss: 8.6860e-04 - val_acc: 0.0000e+00\n",
            "Epoch 238/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.4943e-04 - acc: 0.0000e+00 - val_loss: 7.1239e-04 - val_acc: 0.0000e+00\n",
            "Epoch 239/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
            "Epoch 240/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 3.5928e-04 - val_acc: 0.0000e+00\n",
            "Epoch 241/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.2153e-04 - acc: 0.0000e+00 - val_loss: 7.7923e-04 - val_acc: 0.0000e+00\n",
            "Epoch 242/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.5233e-04 - acc: 0.0000e+00 - val_loss: 4.3501e-04 - val_acc: 0.0000e+00\n",
            "Epoch 243/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.3515e-04 - acc: 0.0000e+00 - val_loss: 8.6895e-04 - val_acc: 0.0000e+00\n",
            "Epoch 244/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.7059e-04 - acc: 0.0000e+00 - val_loss: 6.9136e-04 - val_acc: 0.0000e+00\n",
            "Epoch 245/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.3642e-04 - acc: 0.0000e+00 - val_loss: 4.8912e-04 - val_acc: 0.0000e+00\n",
            "Epoch 246/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.9199e-04 - acc: 0.0000e+00 - val_loss: 3.4157e-04 - val_acc: 0.0000e+00\n",
            "Epoch 247/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.2874e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 248/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.7616e-04 - acc: 0.0000e+00 - val_loss: 9.8449e-04 - val_acc: 0.0000e+00\n",
            "Epoch 249/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.1219e-04 - acc: 0.0000e+00 - val_loss: 7.1400e-04 - val_acc: 0.0000e+00\n",
            "Epoch 250/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.2719e-04 - acc: 0.0000e+00 - val_loss: 6.1561e-04 - val_acc: 0.0000e+00\n",
            "Epoch 251/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.5654e-04 - acc: 0.0000e+00 - val_loss: 6.2488e-04 - val_acc: 0.0000e+00\n",
            "Epoch 252/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.1128e-04 - acc: 0.0000e+00 - val_loss: 8.6348e-04 - val_acc: 0.0000e+00\n",
            "Epoch 253/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.1373e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 254/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.2667e-04 - acc: 0.0000e+00 - val_loss: 6.7243e-04 - val_acc: 0.0000e+00\n",
            "Epoch 255/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.6192e-04 - acc: 0.0000e+00 - val_loss: 4.3986e-04 - val_acc: 0.0000e+00\n",
            "Epoch 256/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.7532e-04 - acc: 0.0000e+00 - val_loss: 5.0547e-04 - val_acc: 0.0000e+00\n",
            "Epoch 257/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.9445e-04 - acc: 0.0000e+00 - val_loss: 9.6623e-04 - val_acc: 0.0000e+00\n",
            "Epoch 258/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.4525e-04 - acc: 0.0000e+00 - val_loss: 4.5494e-04 - val_acc: 0.0000e+00\n",
            "Epoch 259/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.0069e-04 - acc: 0.0000e+00 - val_loss: 7.9920e-04 - val_acc: 0.0000e+00\n",
            "Epoch 260/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.9822e-04 - acc: 0.0000e+00 - val_loss: 6.5922e-04 - val_acc: 0.0000e+00\n",
            "Epoch 261/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.2569e-04 - acc: 0.0000e+00 - val_loss: 9.6038e-04 - val_acc: 0.0000e+00\n",
            "Epoch 262/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.4755e-04 - acc: 0.0000e+00 - val_loss: 3.6677e-04 - val_acc: 0.0000e+00\n",
            "Epoch 263/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.7876e-04 - acc: 0.0000e+00 - val_loss: 4.0050e-04 - val_acc: 0.0000e+00\n",
            "Epoch 264/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.2066e-04 - acc: 0.0000e+00 - val_loss: 4.4489e-04 - val_acc: 0.0000e+00\n",
            "Epoch 265/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.7238e-04 - acc: 0.0000e+00 - val_loss: 3.7610e-04 - val_acc: 0.0000e+00\n",
            "Epoch 266/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.5926e-04 - acc: 0.0000e+00 - val_loss: 5.0401e-04 - val_acc: 0.0000e+00\n",
            "Epoch 267/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.5196e-04 - acc: 0.0000e+00 - val_loss: 4.4403e-04 - val_acc: 0.0000e+00\n",
            "Epoch 268/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.8752e-04 - acc: 0.0000e+00 - val_loss: 5.6114e-04 - val_acc: 0.0000e+00\n",
            "Epoch 269/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.8154e-04 - acc: 0.0000e+00 - val_loss: 4.4837e-04 - val_acc: 0.0000e+00\n",
            "Epoch 270/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.1026e-04 - acc: 0.0000e+00 - val_loss: 4.6279e-04 - val_acc: 0.0000e+00\n",
            "Epoch 271/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.9530e-04 - acc: 0.0000e+00 - val_loss: 5.6796e-04 - val_acc: 0.0000e+00\n",
            "Epoch 272/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.1064e-04 - acc: 0.0000e+00 - val_loss: 3.4263e-04 - val_acc: 0.0000e+00\n",
            "Epoch 273/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.6655e-04 - acc: 0.0000e+00 - val_loss: 4.8489e-04 - val_acc: 0.0000e+00\n",
            "Epoch 274/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.5532e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 275/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.3444e-04 - acc: 0.0000e+00 - val_loss: 6.4114e-04 - val_acc: 0.0000e+00\n",
            "Epoch 276/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.7320e-04 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 277/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.8637e-04 - acc: 0.0000e+00 - val_loss: 9.7862e-04 - val_acc: 0.0000e+00\n",
            "Epoch 278/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.4415e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 279/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.4268e-04 - acc: 0.0000e+00 - val_loss: 4.7272e-04 - val_acc: 0.0000e+00\n",
            "Epoch 280/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.6787e-04 - acc: 0.0000e+00 - val_loss: 3.8257e-04 - val_acc: 0.0000e+00\n",
            "Epoch 281/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.8173e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 282/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 8.6613e-04 - acc: 0.0000e+00 - val_loss: 3.9450e-04 - val_acc: 0.0000e+00\n",
            "Epoch 283/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 4.8989e-04 - acc: 0.0000e+00 - val_loss: 3.0968e-04 - val_acc: 0.0000e+00\n",
            "Epoch 284/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.7141e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 285/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 6.4777e-04 - acc: 0.0000e+00 - val_loss: 4.1652e-04 - val_acc: 0.0000e+00\n",
            "Epoch 286/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.7835e-04 - acc: 0.0000e+00 - val_loss: 6.0497e-04 - val_acc: 0.0000e+00\n",
            "Epoch 287/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 288/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.1603e-04 - acc: 0.0000e+00 - val_loss: 3.5147e-04 - val_acc: 0.0000e+00\n",
            "Epoch 289/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 7.7827e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 290/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 4.5778e-04 - acc: 0.0000e+00 - val_loss: 4.8704e-04 - val_acc: 0.0000e+00\n",
            "Epoch 291/400\n",
            "471/471 [==============================] - 2s 3ms/step - loss: 4.5053e-04 - acc: 0.0000e+00 - val_loss: 3.6878e-04 - val_acc: 0.0000e+00\n",
            "Epoch 292/400\n",
            "471/471 [==============================] - 2s 3ms/step - loss: 6.7890e-04 - acc: 0.0000e+00 - val_loss: 3.7344e-04 - val_acc: 0.0000e+00\n",
            "Epoch 293/400\n",
            "471/471 [==============================] - 2s 3ms/step - loss: 6.9683e-04 - acc: 0.0000e+00 - val_loss: 3.4897e-04 - val_acc: 0.0000e+00\n",
            "Epoch 294/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 6.1788e-04 - acc: 0.0000e+00 - val_loss: 8.5635e-04 - val_acc: 0.0000e+00\n",
            "Epoch 295/400\n",
            "471/471 [==============================] - 2s 4ms/step - loss: 9.3271e-04 - acc: 0.0000e+00 - val_loss: 7.8422e-04 - val_acc: 0.0000e+00\n",
            "Epoch 296/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.5453e-04 - acc: 0.0000e+00 - val_loss: 4.5630e-04 - val_acc: 0.0000e+00\n",
            "Epoch 297/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.2452e-04 - acc: 0.0000e+00 - val_loss: 7.7345e-04 - val_acc: 0.0000e+00\n",
            "Epoch 298/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.0763e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 299/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 6.0514e-04 - acc: 0.0000e+00 - val_loss: 4.7164e-04 - val_acc: 0.0000e+00\n",
            "Epoch 300/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.2365e-04 - acc: 0.0000e+00 - val_loss: 5.0211e-04 - val_acc: 0.0000e+00\n",
            "Epoch 301/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.9654e-04 - acc: 0.0000e+00 - val_loss: 5.1563e-04 - val_acc: 0.0000e+00\n",
            "Epoch 302/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.4146e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 303/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.1627e-04 - acc: 0.0000e+00 - val_loss: 3.4717e-04 - val_acc: 0.0000e+00\n",
            "Epoch 304/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.8388e-04 - acc: 0.0000e+00 - val_loss: 7.7699e-04 - val_acc: 0.0000e+00\n",
            "Epoch 305/400\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 5.4496e-04 - acc: 0.0000e+00 - val_loss: 7.3659e-04 - val_acc: 0.0000e+00\n",
            "Epoch 306/400\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 6.2253e-04 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 307/400\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 2.9349e-04 - val_acc: 0.0000e+00\n",
            "Epoch 308/400\n",
            "471/471 [==============================] - 2s 4ms/step - loss: 4.7018e-04 - acc: 0.0000e+00 - val_loss: 4.9323e-04 - val_acc: 0.0000e+00\n",
            "Epoch 309/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.2157e-04 - acc: 0.0000e+00 - val_loss: 5.4424e-04 - val_acc: 0.0000e+00\n",
            "Epoch 310/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.5205e-04 - acc: 0.0000e+00 - val_loss: 3.5227e-04 - val_acc: 0.0000e+00\n",
            "Epoch 311/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 7.4880e-04 - acc: 0.0000e+00 - val_loss: 9.1178e-04 - val_acc: 0.0000e+00\n",
            "Epoch 312/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.2171e-04 - acc: 0.0000e+00 - val_loss: 3.8503e-04 - val_acc: 0.0000e+00\n",
            "Epoch 313/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.6564e-04 - acc: 0.0000e+00 - val_loss: 7.5874e-04 - val_acc: 0.0000e+00\n",
            "Epoch 314/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.3157e-04 - acc: 0.0000e+00 - val_loss: 6.3103e-04 - val_acc: 0.0000e+00\n",
            "Epoch 315/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 9.8439e-04 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 316/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 4.9013e-04 - acc: 0.0000e+00 - val_loss: 3.0829e-04 - val_acc: 0.0000e+00\n",
            "Epoch 317/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 6.3637e-04 - acc: 0.0000e+00 - val_loss: 3.3500e-04 - val_acc: 0.0000e+00\n",
            "Epoch 318/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.6145e-04 - acc: 0.0000e+00 - val_loss: 7.0548e-04 - val_acc: 0.0000e+00\n",
            "Epoch 319/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.0319e-04 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 320/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 7.4027e-04 - acc: 0.0000e+00 - val_loss: 5.1264e-04 - val_acc: 0.0000e+00\n",
            "Epoch 321/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 3.5961e-04 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 322/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.8106e-04 - acc: 0.0000e+00 - val_loss: 3.7999e-04 - val_acc: 0.0000e+00\n",
            "Epoch 323/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.5094e-04 - acc: 0.0000e+00 - val_loss: 8.0947e-04 - val_acc: 0.0000e+00\n",
            "Epoch 324/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.1714e-04 - acc: 0.0000e+00 - val_loss: 3.6541e-04 - val_acc: 0.0000e+00\n",
            "Epoch 325/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.3558e-04 - acc: 0.0000e+00 - val_loss: 3.5054e-04 - val_acc: 0.0000e+00\n",
            "Epoch 326/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 4.5972e-04 - acc: 0.0000e+00 - val_loss: 5.1947e-04 - val_acc: 0.0000e+00\n",
            "Epoch 327/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.9595e-04 - acc: 0.0000e+00 - val_loss: 4.2882e-04 - val_acc: 0.0000e+00\n",
            "Epoch 328/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.0998e-04 - acc: 0.0000e+00 - val_loss: 3.9051e-04 - val_acc: 0.0000e+00\n",
            "Epoch 329/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.2580e-04 - acc: 0.0000e+00 - val_loss: 4.0790e-04 - val_acc: 0.0000e+00\n",
            "Epoch 330/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.2824e-04 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 331/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.5730e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 332/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.5308e-04 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 333/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.9621e-04 - acc: 0.0000e+00 - val_loss: 4.4104e-04 - val_acc: 0.0000e+00\n",
            "Epoch 334/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.2574e-04 - acc: 0.0000e+00 - val_loss: 4.0817e-04 - val_acc: 0.0000e+00\n",
            "Epoch 335/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.4171e-04 - acc: 0.0000e+00 - val_loss: 5.0181e-04 - val_acc: 0.0000e+00\n",
            "Epoch 336/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.7109e-04 - acc: 0.0000e+00 - val_loss: 3.1303e-04 - val_acc: 0.0000e+00\n",
            "Epoch 337/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.9315e-04 - acc: 0.0000e+00 - val_loss: 3.2181e-04 - val_acc: 0.0000e+00\n",
            "Epoch 338/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 5.0139e-04 - val_acc: 0.0000e+00\n",
            "Epoch 339/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 3.8611e-04 - acc: 0.0000e+00 - val_loss: 3.4876e-04 - val_acc: 0.0000e+00\n",
            "Epoch 340/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 4.8607e-04 - acc: 0.0000e+00 - val_loss: 3.9440e-04 - val_acc: 0.0000e+00\n",
            "Epoch 341/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.6772e-04 - acc: 0.0000e+00 - val_loss: 4.6525e-04 - val_acc: 0.0000e+00\n",
            "Epoch 342/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.3221e-04 - acc: 0.0000e+00 - val_loss: 3.4083e-04 - val_acc: 0.0000e+00\n",
            "Epoch 343/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 6.7012e-04 - acc: 0.0000e+00 - val_loss: 4.0858e-04 - val_acc: 0.0000e+00\n",
            "Epoch 344/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.1963e-04 - acc: 0.0000e+00 - val_loss: 4.4800e-04 - val_acc: 0.0000e+00\n",
            "Epoch 345/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.1287e-04 - acc: 0.0000e+00 - val_loss: 9.9668e-04 - val_acc: 0.0000e+00\n",
            "Epoch 346/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.2066e-04 - acc: 0.0000e+00 - val_loss: 4.2112e-04 - val_acc: 0.0000e+00\n",
            "Epoch 347/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.1409e-04 - acc: 0.0000e+00 - val_loss: 4.8035e-04 - val_acc: 0.0000e+00\n",
            "Epoch 348/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 8.8171e-04 - val_acc: 0.0000e+00\n",
            "Epoch 349/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.6782e-04 - acc: 0.0000e+00 - val_loss: 3.6215e-04 - val_acc: 0.0000e+00\n",
            "Epoch 350/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.8030e-04 - acc: 0.0000e+00 - val_loss: 3.1432e-04 - val_acc: 0.0000e+00\n",
            "Epoch 351/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 3.0965e-04 - acc: 0.0000e+00 - val_loss: 2.7806e-04 - val_acc: 0.0000e+00\n",
            "Epoch 352/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.8672e-04 - acc: 0.0000e+00 - val_loss: 4.9041e-04 - val_acc: 0.0000e+00\n",
            "Epoch 353/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.1286e-04 - acc: 0.0000e+00 - val_loss: 3.1849e-04 - val_acc: 0.0000e+00\n",
            "Epoch 354/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.9835e-04 - acc: 0.0000e+00 - val_loss: 3.6061e-04 - val_acc: 0.0000e+00\n",
            "Epoch 355/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 3.4901e-04 - acc: 0.0000e+00 - val_loss: 3.6191e-04 - val_acc: 0.0000e+00\n",
            "Epoch 356/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.1186e-04 - acc: 0.0000e+00 - val_loss: 3.8306e-04 - val_acc: 0.0000e+00\n",
            "Epoch 357/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 3.7472e-04 - acc: 0.0000e+00 - val_loss: 3.0509e-04 - val_acc: 0.0000e+00\n",
            "Epoch 358/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.9806e-04 - acc: 0.0000e+00 - val_loss: 6.1085e-04 - val_acc: 0.0000e+00\n",
            "Epoch 359/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.3089e-04 - acc: 0.0000e+00 - val_loss: 4.1964e-04 - val_acc: 0.0000e+00\n",
            "Epoch 360/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 9.4802e-04 - acc: 0.0000e+00 - val_loss: 3.0995e-04 - val_acc: 0.0000e+00\n",
            "Epoch 361/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 3.6870e-04 - acc: 0.0000e+00 - val_loss: 3.0582e-04 - val_acc: 0.0000e+00\n",
            "Epoch 362/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.4033e-04 - acc: 0.0000e+00 - val_loss: 2.9195e-04 - val_acc: 0.0000e+00\n",
            "Epoch 363/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 8.9420e-04 - val_acc: 0.0000e+00\n",
            "Epoch 364/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.4645e-04 - acc: 0.0000e+00 - val_loss: 2.9986e-04 - val_acc: 0.0000e+00\n",
            "Epoch 365/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.1049e-04 - acc: 0.0000e+00 - val_loss: 2.8981e-04 - val_acc: 0.0000e+00\n",
            "Epoch 366/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.3864e-04 - acc: 0.0000e+00 - val_loss: 2.6923e-04 - val_acc: 0.0000e+00\n",
            "Epoch 367/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.6033e-04 - acc: 0.0000e+00 - val_loss: 6.0193e-04 - val_acc: 0.0000e+00\n",
            "Epoch 368/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.5663e-04 - acc: 0.0000e+00 - val_loss: 7.8744e-04 - val_acc: 0.0000e+00\n",
            "Epoch 369/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 7.1050e-04 - acc: 0.0000e+00 - val_loss: 5.7350e-04 - val_acc: 0.0000e+00\n",
            "Epoch 370/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 7.3954e-04 - acc: 0.0000e+00 - val_loss: 3.6471e-04 - val_acc: 0.0000e+00\n",
            "Epoch 371/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.4460e-04 - acc: 0.0000e+00 - val_loss: 2.8598e-04 - val_acc: 0.0000e+00\n",
            "Epoch 372/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.8321e-04 - acc: 0.0000e+00 - val_loss: 4.6974e-04 - val_acc: 0.0000e+00\n",
            "Epoch 373/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.7189e-04 - acc: 0.0000e+00 - val_loss: 4.5446e-04 - val_acc: 0.0000e+00\n",
            "Epoch 374/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.3731e-04 - acc: 0.0000e+00 - val_loss: 6.9363e-04 - val_acc: 0.0000e+00\n",
            "Epoch 375/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 3.9874e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 376/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.3887e-04 - acc: 0.0000e+00 - val_loss: 3.8421e-04 - val_acc: 0.0000e+00\n",
            "Epoch 377/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 8.4231e-04 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 378/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.2624e-04 - acc: 0.0000e+00 - val_loss: 3.1106e-04 - val_acc: 0.0000e+00\n",
            "Epoch 379/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 4.8486e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 380/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.8937e-04 - acc: 0.0000e+00 - val_loss: 4.3275e-04 - val_acc: 0.0000e+00\n",
            "Epoch 381/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.2054e-04 - acc: 0.0000e+00 - val_loss: 4.1461e-04 - val_acc: 0.0000e+00\n",
            "Epoch 382/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.3528e-04 - acc: 0.0000e+00 - val_loss: 4.6675e-04 - val_acc: 0.0000e+00\n",
            "Epoch 383/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.3217e-04 - acc: 0.0000e+00 - val_loss: 4.6181e-04 - val_acc: 0.0000e+00\n",
            "Epoch 384/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 8.7160e-04 - acc: 0.0000e+00 - val_loss: 3.0509e-04 - val_acc: 0.0000e+00\n",
            "Epoch 385/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 4.9892e-04 - acc: 0.0000e+00 - val_loss: 3.6384e-04 - val_acc: 0.0000e+00\n",
            "Epoch 386/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.6166e-04 - acc: 0.0000e+00 - val_loss: 5.2974e-04 - val_acc: 0.0000e+00\n",
            "Epoch 387/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 3.7084e-04 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 388/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.8088e-04 - acc: 0.0000e+00 - val_loss: 3.3451e-04 - val_acc: 0.0000e+00\n",
            "Epoch 389/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 3.7058e-04 - acc: 0.0000e+00 - val_loss: 6.6968e-04 - val_acc: 0.0000e+00\n",
            "Epoch 390/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 391/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.7415e-04 - acc: 0.0000e+00 - val_loss: 8.5044e-04 - val_acc: 0.0000e+00\n",
            "Epoch 392/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.3024e-04 - acc: 0.0000e+00 - val_loss: 3.3038e-04 - val_acc: 0.0000e+00\n",
            "Epoch 393/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.0808e-04 - acc: 0.0000e+00 - val_loss: 2.8879e-04 - val_acc: 0.0000e+00\n",
            "Epoch 394/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 4.5928e-04 - val_acc: 0.0000e+00\n",
            "Epoch 395/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.2206e-04 - acc: 0.0000e+00 - val_loss: 2.4601e-04 - val_acc: 0.0000e+00\n",
            "Epoch 396/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 4.0047e-04 - acc: 0.0000e+00 - val_loss: 9.2241e-04 - val_acc: 0.0000e+00\n",
            "Epoch 397/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 5.1813e-04 - acc: 0.0000e+00 - val_loss: 3.4884e-04 - val_acc: 0.0000e+00\n",
            "Epoch 398/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 6.0243e-04 - acc: 0.0000e+00 - val_loss: 4.3825e-04 - val_acc: 0.0000e+00\n",
            "Epoch 399/400\n",
            "471/471 [==============================] - 1s 3ms/step - loss: 5.4760e-04 - acc: 0.0000e+00 - val_loss: 3.8033e-04 - val_acc: 0.0000e+00\n",
            "Epoch 400/400\n",
            "471/471 [==============================] - 1s 2ms/step - loss: 3.6112e-04 - acc: 0.0000e+00 - val_loss: 5.4995e-04 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPz5SaGpcxjg"
      },
      "source": [
        "y_pred = model_period.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUX9rXryc4-I"
      },
      "source": [
        "import keras.backend as K \n",
        "\n",
        "def my_accuracy(y_pred, y_true):\n",
        "    diff = K.abs(y_true-y_pred)\n",
        "    correct = K.less(diff, 0.05)\n",
        "    return K.mean(correct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8tB_Uu7c7ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1989339f-672c-4f3d-a980-3e04367e5834"
      },
      "source": [
        "my_accuracy(y_pred, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9607043>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFPya2xwc-24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc70c40a-7f57-4bde-f96e-31580e87931b"
      },
      "source": [
        "mse = mean_squared_error(Y_train, y_pred)\n",
        "print(\"RMSE: %f\" % (mse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.000547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "BdaZgo64qxFj",
        "outputId": "489ad57b-c46d-4b92-b02b-4ea33aa82f22"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "#plt.ylim([0, 0.002])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa0fdd7d978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omKffU9NqedQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZtWDdASdb-a"
      },
      "source": [
        "model_period.save('/content/gdrive/MyDrive/model_nn_period.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYKobxxAdK5Z"
      },
      "source": [
        "#ts training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "Aww9lg1fdGeo",
        "outputId": "c78ba745-38bf-4fab-a3fd-8572494cfb09"
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/all_trans3.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># t_s</th>\n",
              "      <th>period</th>\n",
              "      <th>w_si</th>\n",
              "      <th>1400.0</th>\n",
              "      <th>1401.0</th>\n",
              "      <th>1402.0</th>\n",
              "      <th>1403.0</th>\n",
              "      <th>1404.0</th>\n",
              "      <th>1405.0</th>\n",
              "      <th>1406.0</th>\n",
              "      <th>1407.0</th>\n",
              "      <th>1408.0</th>\n",
              "      <th>1409.0</th>\n",
              "      <th>1410.0</th>\n",
              "      <th>1411.0</th>\n",
              "      <th>1412.0</th>\n",
              "      <th>1413.0</th>\n",
              "      <th>1414.0</th>\n",
              "      <th>1415.0</th>\n",
              "      <th>1416.0</th>\n",
              "      <th>1417.0</th>\n",
              "      <th>1418.0</th>\n",
              "      <th>1419.0</th>\n",
              "      <th>1420.0</th>\n",
              "      <th>1421.0</th>\n",
              "      <th>1422.0</th>\n",
              "      <th>1423.0</th>\n",
              "      <th>1424.0</th>\n",
              "      <th>1425.0</th>\n",
              "      <th>1426.0</th>\n",
              "      <th>1427.0</th>\n",
              "      <th>1428.0</th>\n",
              "      <th>1429.0</th>\n",
              "      <th>1430.0</th>\n",
              "      <th>1431.0</th>\n",
              "      <th>1432.0</th>\n",
              "      <th>1433.0</th>\n",
              "      <th>1434.0</th>\n",
              "      <th>1435.0</th>\n",
              "      <th>1436.0</th>\n",
              "      <th>...</th>\n",
              "      <th>1611.0</th>\n",
              "      <th>1612.0</th>\n",
              "      <th>1613.0</th>\n",
              "      <th>1614.0</th>\n",
              "      <th>1615.0</th>\n",
              "      <th>1616.0</th>\n",
              "      <th>1617.0</th>\n",
              "      <th>1618.0</th>\n",
              "      <th>1619.0</th>\n",
              "      <th>1620.0</th>\n",
              "      <th>1621.0</th>\n",
              "      <th>1622.0</th>\n",
              "      <th>1623.0</th>\n",
              "      <th>1624.0</th>\n",
              "      <th>1625.0</th>\n",
              "      <th>1626.0</th>\n",
              "      <th>1627.0</th>\n",
              "      <th>1628.0</th>\n",
              "      <th>1629.0</th>\n",
              "      <th>1630.0</th>\n",
              "      <th>1631.0</th>\n",
              "      <th>1632.0</th>\n",
              "      <th>1633.0</th>\n",
              "      <th>1634.0</th>\n",
              "      <th>1635.0</th>\n",
              "      <th>1636.0</th>\n",
              "      <th>1637.0</th>\n",
              "      <th>1638.0</th>\n",
              "      <th>1639.0</th>\n",
              "      <th>1640.0</th>\n",
              "      <th>1641.0</th>\n",
              "      <th>1642.0</th>\n",
              "      <th>1643.0</th>\n",
              "      <th>1644.0</th>\n",
              "      <th>1645.0</th>\n",
              "      <th>1646.0</th>\n",
              "      <th>1647.0</th>\n",
              "      <th>1648.0</th>\n",
              "      <th>1649.0</th>\n",
              "      <th>1650.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>382.50</td>\n",
              "      <td>0.951240</td>\n",
              "      <td>0.950670</td>\n",
              "      <td>0.95009</td>\n",
              "      <td>0.94949</td>\n",
              "      <td>0.94889</td>\n",
              "      <td>0.94828</td>\n",
              "      <td>0.94766</td>\n",
              "      <td>0.94702</td>\n",
              "      <td>0.94638</td>\n",
              "      <td>0.94573</td>\n",
              "      <td>0.94507</td>\n",
              "      <td>0.94440</td>\n",
              "      <td>0.94372</td>\n",
              "      <td>0.94303</td>\n",
              "      <td>0.94233</td>\n",
              "      <td>0.94163</td>\n",
              "      <td>0.94091</td>\n",
              "      <td>0.94019</td>\n",
              "      <td>0.93945</td>\n",
              "      <td>0.93871</td>\n",
              "      <td>0.93796</td>\n",
              "      <td>0.93720</td>\n",
              "      <td>0.93643</td>\n",
              "      <td>0.93566</td>\n",
              "      <td>0.93487</td>\n",
              "      <td>0.93408</td>\n",
              "      <td>0.93328</td>\n",
              "      <td>0.93247</td>\n",
              "      <td>0.93166</td>\n",
              "      <td>0.93083</td>\n",
              "      <td>0.93000</td>\n",
              "      <td>0.92916</td>\n",
              "      <td>0.92832</td>\n",
              "      <td>0.92747</td>\n",
              "      <td>0.92661</td>\n",
              "      <td>0.92574</td>\n",
              "      <td>0.92486</td>\n",
              "      <td>...</td>\n",
              "      <td>0.73293</td>\n",
              "      <td>0.73188</td>\n",
              "      <td>0.73083</td>\n",
              "      <td>0.72978</td>\n",
              "      <td>0.72874</td>\n",
              "      <td>0.72770</td>\n",
              "      <td>0.72666</td>\n",
              "      <td>0.72562</td>\n",
              "      <td>0.72458</td>\n",
              "      <td>0.72355</td>\n",
              "      <td>0.72252</td>\n",
              "      <td>0.72149</td>\n",
              "      <td>0.72047</td>\n",
              "      <td>0.71944</td>\n",
              "      <td>0.71842</td>\n",
              "      <td>0.71740</td>\n",
              "      <td>0.71639</td>\n",
              "      <td>0.71537</td>\n",
              "      <td>0.71436</td>\n",
              "      <td>0.71335</td>\n",
              "      <td>0.71234</td>\n",
              "      <td>0.71134</td>\n",
              "      <td>0.71034</td>\n",
              "      <td>0.70934</td>\n",
              "      <td>0.70834</td>\n",
              "      <td>0.70734</td>\n",
              "      <td>0.70635</td>\n",
              "      <td>0.70536</td>\n",
              "      <td>0.70437</td>\n",
              "      <td>0.70339</td>\n",
              "      <td>0.70240</td>\n",
              "      <td>0.70142</td>\n",
              "      <td>0.70045</td>\n",
              "      <td>0.69947</td>\n",
              "      <td>0.69850</td>\n",
              "      <td>0.69753</td>\n",
              "      <td>0.69656</td>\n",
              "      <td>0.69559</td>\n",
              "      <td>0.69463</td>\n",
              "      <td>0.69367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>405.00</td>\n",
              "      <td>0.963090</td>\n",
              "      <td>0.962850</td>\n",
              "      <td>0.96260</td>\n",
              "      <td>0.96234</td>\n",
              "      <td>0.96207</td>\n",
              "      <td>0.96179</td>\n",
              "      <td>0.96149</td>\n",
              "      <td>0.96118</td>\n",
              "      <td>0.96086</td>\n",
              "      <td>0.96053</td>\n",
              "      <td>0.96018</td>\n",
              "      <td>0.95983</td>\n",
              "      <td>0.95946</td>\n",
              "      <td>0.95908</td>\n",
              "      <td>0.95869</td>\n",
              "      <td>0.95828</td>\n",
              "      <td>0.95787</td>\n",
              "      <td>0.95744</td>\n",
              "      <td>0.95701</td>\n",
              "      <td>0.95656</td>\n",
              "      <td>0.95610</td>\n",
              "      <td>0.95563</td>\n",
              "      <td>0.95515</td>\n",
              "      <td>0.95466</td>\n",
              "      <td>0.95415</td>\n",
              "      <td>0.95364</td>\n",
              "      <td>0.95312</td>\n",
              "      <td>0.95258</td>\n",
              "      <td>0.95204</td>\n",
              "      <td>0.95148</td>\n",
              "      <td>0.95091</td>\n",
              "      <td>0.95034</td>\n",
              "      <td>0.94975</td>\n",
              "      <td>0.94915</td>\n",
              "      <td>0.94855</td>\n",
              "      <td>0.94793</td>\n",
              "      <td>0.94731</td>\n",
              "      <td>...</td>\n",
              "      <td>0.76473</td>\n",
              "      <td>0.76361</td>\n",
              "      <td>0.76250</td>\n",
              "      <td>0.76138</td>\n",
              "      <td>0.76027</td>\n",
              "      <td>0.75916</td>\n",
              "      <td>0.75805</td>\n",
              "      <td>0.75694</td>\n",
              "      <td>0.75584</td>\n",
              "      <td>0.75473</td>\n",
              "      <td>0.75363</td>\n",
              "      <td>0.75253</td>\n",
              "      <td>0.75143</td>\n",
              "      <td>0.75034</td>\n",
              "      <td>0.74924</td>\n",
              "      <td>0.74815</td>\n",
              "      <td>0.74706</td>\n",
              "      <td>0.74597</td>\n",
              "      <td>0.74488</td>\n",
              "      <td>0.74380</td>\n",
              "      <td>0.74271</td>\n",
              "      <td>0.74163</td>\n",
              "      <td>0.74055</td>\n",
              "      <td>0.73948</td>\n",
              "      <td>0.73840</td>\n",
              "      <td>0.73733</td>\n",
              "      <td>0.73626</td>\n",
              "      <td>0.73519</td>\n",
              "      <td>0.73412</td>\n",
              "      <td>0.73306</td>\n",
              "      <td>0.73199</td>\n",
              "      <td>0.73093</td>\n",
              "      <td>0.72988</td>\n",
              "      <td>0.72882</td>\n",
              "      <td>0.72777</td>\n",
              "      <td>0.72672</td>\n",
              "      <td>0.72567</td>\n",
              "      <td>0.72462</td>\n",
              "      <td>0.72357</td>\n",
              "      <td>0.72253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>270.00</td>\n",
              "      <td>0.787300</td>\n",
              "      <td>0.786100</td>\n",
              "      <td>0.78491</td>\n",
              "      <td>0.78372</td>\n",
              "      <td>0.78253</td>\n",
              "      <td>0.78135</td>\n",
              "      <td>0.78017</td>\n",
              "      <td>0.77899</td>\n",
              "      <td>0.77781</td>\n",
              "      <td>0.77663</td>\n",
              "      <td>0.77546</td>\n",
              "      <td>0.77429</td>\n",
              "      <td>0.77313</td>\n",
              "      <td>0.77196</td>\n",
              "      <td>0.77080</td>\n",
              "      <td>0.76964</td>\n",
              "      <td>0.76848</td>\n",
              "      <td>0.76733</td>\n",
              "      <td>0.76618</td>\n",
              "      <td>0.76503</td>\n",
              "      <td>0.76388</td>\n",
              "      <td>0.76274</td>\n",
              "      <td>0.76160</td>\n",
              "      <td>0.76046</td>\n",
              "      <td>0.75933</td>\n",
              "      <td>0.75820</td>\n",
              "      <td>0.75707</td>\n",
              "      <td>0.75594</td>\n",
              "      <td>0.75482</td>\n",
              "      <td>0.75370</td>\n",
              "      <td>0.75259</td>\n",
              "      <td>0.75147</td>\n",
              "      <td>0.75036</td>\n",
              "      <td>0.74925</td>\n",
              "      <td>0.74815</td>\n",
              "      <td>0.74705</td>\n",
              "      <td>0.74595</td>\n",
              "      <td>...</td>\n",
              "      <td>0.60222</td>\n",
              "      <td>0.60165</td>\n",
              "      <td>0.60108</td>\n",
              "      <td>0.60051</td>\n",
              "      <td>0.59995</td>\n",
              "      <td>0.59939</td>\n",
              "      <td>0.59883</td>\n",
              "      <td>0.59827</td>\n",
              "      <td>0.59772</td>\n",
              "      <td>0.59717</td>\n",
              "      <td>0.59662</td>\n",
              "      <td>0.59607</td>\n",
              "      <td>0.59552</td>\n",
              "      <td>0.59498</td>\n",
              "      <td>0.59444</td>\n",
              "      <td>0.59390</td>\n",
              "      <td>0.59337</td>\n",
              "      <td>0.59283</td>\n",
              "      <td>0.59230</td>\n",
              "      <td>0.59177</td>\n",
              "      <td>0.59125</td>\n",
              "      <td>0.59072</td>\n",
              "      <td>0.59020</td>\n",
              "      <td>0.58968</td>\n",
              "      <td>0.58916</td>\n",
              "      <td>0.58865</td>\n",
              "      <td>0.58813</td>\n",
              "      <td>0.58762</td>\n",
              "      <td>0.58711</td>\n",
              "      <td>0.58660</td>\n",
              "      <td>0.58610</td>\n",
              "      <td>0.58560</td>\n",
              "      <td>0.58510</td>\n",
              "      <td>0.58460</td>\n",
              "      <td>0.58410</td>\n",
              "      <td>0.58361</td>\n",
              "      <td>0.58311</td>\n",
              "      <td>0.58262</td>\n",
              "      <td>0.58214</td>\n",
              "      <td>0.58165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>225.00</td>\n",
              "      <td>0.701080</td>\n",
              "      <td>0.700130</td>\n",
              "      <td>0.69918</td>\n",
              "      <td>0.69823</td>\n",
              "      <td>0.69729</td>\n",
              "      <td>0.69635</td>\n",
              "      <td>0.69542</td>\n",
              "      <td>0.69449</td>\n",
              "      <td>0.69357</td>\n",
              "      <td>0.69264</td>\n",
              "      <td>0.69173</td>\n",
              "      <td>0.69081</td>\n",
              "      <td>0.68990</td>\n",
              "      <td>0.68900</td>\n",
              "      <td>0.68810</td>\n",
              "      <td>0.68720</td>\n",
              "      <td>0.68630</td>\n",
              "      <td>0.68541</td>\n",
              "      <td>0.68453</td>\n",
              "      <td>0.68365</td>\n",
              "      <td>0.68277</td>\n",
              "      <td>0.68189</td>\n",
              "      <td>0.68102</td>\n",
              "      <td>0.68016</td>\n",
              "      <td>0.67929</td>\n",
              "      <td>0.67843</td>\n",
              "      <td>0.67758</td>\n",
              "      <td>0.67673</td>\n",
              "      <td>0.67588</td>\n",
              "      <td>0.67503</td>\n",
              "      <td>0.67419</td>\n",
              "      <td>0.67336</td>\n",
              "      <td>0.67252</td>\n",
              "      <td>0.67170</td>\n",
              "      <td>0.67087</td>\n",
              "      <td>0.67005</td>\n",
              "      <td>0.66923</td>\n",
              "      <td>...</td>\n",
              "      <td>0.57256</td>\n",
              "      <td>0.57222</td>\n",
              "      <td>0.57187</td>\n",
              "      <td>0.57153</td>\n",
              "      <td>0.57120</td>\n",
              "      <td>0.57086</td>\n",
              "      <td>0.57053</td>\n",
              "      <td>0.57019</td>\n",
              "      <td>0.56986</td>\n",
              "      <td>0.56953</td>\n",
              "      <td>0.56920</td>\n",
              "      <td>0.56888</td>\n",
              "      <td>0.56855</td>\n",
              "      <td>0.56823</td>\n",
              "      <td>0.56791</td>\n",
              "      <td>0.56759</td>\n",
              "      <td>0.56727</td>\n",
              "      <td>0.56696</td>\n",
              "      <td>0.56664</td>\n",
              "      <td>0.56633</td>\n",
              "      <td>0.56602</td>\n",
              "      <td>0.56571</td>\n",
              "      <td>0.56541</td>\n",
              "      <td>0.56510</td>\n",
              "      <td>0.56480</td>\n",
              "      <td>0.56449</td>\n",
              "      <td>0.56419</td>\n",
              "      <td>0.56389</td>\n",
              "      <td>0.56360</td>\n",
              "      <td>0.56330</td>\n",
              "      <td>0.56301</td>\n",
              "      <td>0.56271</td>\n",
              "      <td>0.56242</td>\n",
              "      <td>0.56213</td>\n",
              "      <td>0.56184</td>\n",
              "      <td>0.56156</td>\n",
              "      <td>0.56127</td>\n",
              "      <td>0.56099</td>\n",
              "      <td>0.56071</td>\n",
              "      <td>0.56043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>208.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>292.50</td>\n",
              "      <td>0.829690</td>\n",
              "      <td>0.828470</td>\n",
              "      <td>0.82725</td>\n",
              "      <td>0.82604</td>\n",
              "      <td>0.82482</td>\n",
              "      <td>0.82361</td>\n",
              "      <td>0.82239</td>\n",
              "      <td>0.82118</td>\n",
              "      <td>0.81996</td>\n",
              "      <td>0.81875</td>\n",
              "      <td>0.81754</td>\n",
              "      <td>0.81633</td>\n",
              "      <td>0.81512</td>\n",
              "      <td>0.81391</td>\n",
              "      <td>0.81270</td>\n",
              "      <td>0.81149</td>\n",
              "      <td>0.81029</td>\n",
              "      <td>0.80908</td>\n",
              "      <td>0.80788</td>\n",
              "      <td>0.80668</td>\n",
              "      <td>0.80548</td>\n",
              "      <td>0.80428</td>\n",
              "      <td>0.80308</td>\n",
              "      <td>0.80189</td>\n",
              "      <td>0.80069</td>\n",
              "      <td>0.79950</td>\n",
              "      <td>0.79831</td>\n",
              "      <td>0.79712</td>\n",
              "      <td>0.79593</td>\n",
              "      <td>0.79474</td>\n",
              "      <td>0.79356</td>\n",
              "      <td>0.79238</td>\n",
              "      <td>0.79119</td>\n",
              "      <td>0.79001</td>\n",
              "      <td>0.78884</td>\n",
              "      <td>0.78766</td>\n",
              "      <td>0.78649</td>\n",
              "      <td>...</td>\n",
              "      <td>0.62351</td>\n",
              "      <td>0.62283</td>\n",
              "      <td>0.62215</td>\n",
              "      <td>0.62147</td>\n",
              "      <td>0.62080</td>\n",
              "      <td>0.62013</td>\n",
              "      <td>0.61947</td>\n",
              "      <td>0.61880</td>\n",
              "      <td>0.61814</td>\n",
              "      <td>0.61748</td>\n",
              "      <td>0.61682</td>\n",
              "      <td>0.61617</td>\n",
              "      <td>0.61552</td>\n",
              "      <td>0.61487</td>\n",
              "      <td>0.61422</td>\n",
              "      <td>0.61358</td>\n",
              "      <td>0.61293</td>\n",
              "      <td>0.61229</td>\n",
              "      <td>0.61166</td>\n",
              "      <td>0.61102</td>\n",
              "      <td>0.61039</td>\n",
              "      <td>0.60976</td>\n",
              "      <td>0.60913</td>\n",
              "      <td>0.60851</td>\n",
              "      <td>0.60789</td>\n",
              "      <td>0.60727</td>\n",
              "      <td>0.60665</td>\n",
              "      <td>0.60604</td>\n",
              "      <td>0.60542</td>\n",
              "      <td>0.60481</td>\n",
              "      <td>0.60420</td>\n",
              "      <td>0.60360</td>\n",
              "      <td>0.60300</td>\n",
              "      <td>0.60239</td>\n",
              "      <td>0.60180</td>\n",
              "      <td>0.60120</td>\n",
              "      <td>0.60061</td>\n",
              "      <td>0.60001</td>\n",
              "      <td>0.59943</td>\n",
              "      <td>0.59884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52306</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>435.50</td>\n",
              "      <td>0.989850</td>\n",
              "      <td>0.989550</td>\n",
              "      <td>0.98926</td>\n",
              "      <td>0.98898</td>\n",
              "      <td>0.98870</td>\n",
              "      <td>0.98844</td>\n",
              "      <td>0.98819</td>\n",
              "      <td>0.98794</td>\n",
              "      <td>0.98770</td>\n",
              "      <td>0.98747</td>\n",
              "      <td>0.98725</td>\n",
              "      <td>0.98704</td>\n",
              "      <td>0.98683</td>\n",
              "      <td>0.98664</td>\n",
              "      <td>0.98645</td>\n",
              "      <td>0.98626</td>\n",
              "      <td>0.98609</td>\n",
              "      <td>0.98592</td>\n",
              "      <td>0.98576</td>\n",
              "      <td>0.98560</td>\n",
              "      <td>0.98545</td>\n",
              "      <td>0.98531</td>\n",
              "      <td>0.98517</td>\n",
              "      <td>0.98503</td>\n",
              "      <td>0.98490</td>\n",
              "      <td>0.98478</td>\n",
              "      <td>0.98466</td>\n",
              "      <td>0.98454</td>\n",
              "      <td>0.98443</td>\n",
              "      <td>0.98432</td>\n",
              "      <td>0.98421</td>\n",
              "      <td>0.98411</td>\n",
              "      <td>0.98401</td>\n",
              "      <td>0.98391</td>\n",
              "      <td>0.98381</td>\n",
              "      <td>0.98371</td>\n",
              "      <td>0.98362</td>\n",
              "      <td>...</td>\n",
              "      <td>0.89112</td>\n",
              "      <td>0.89020</td>\n",
              "      <td>0.88928</td>\n",
              "      <td>0.88836</td>\n",
              "      <td>0.88744</td>\n",
              "      <td>0.88652</td>\n",
              "      <td>0.88560</td>\n",
              "      <td>0.88469</td>\n",
              "      <td>0.88377</td>\n",
              "      <td>0.88285</td>\n",
              "      <td>0.88194</td>\n",
              "      <td>0.88102</td>\n",
              "      <td>0.88011</td>\n",
              "      <td>0.87920</td>\n",
              "      <td>0.87828</td>\n",
              "      <td>0.87737</td>\n",
              "      <td>0.87647</td>\n",
              "      <td>0.87556</td>\n",
              "      <td>0.87466</td>\n",
              "      <td>0.87376</td>\n",
              "      <td>0.87286</td>\n",
              "      <td>0.87196</td>\n",
              "      <td>0.87106</td>\n",
              "      <td>0.87017</td>\n",
              "      <td>0.86928</td>\n",
              "      <td>0.86840</td>\n",
              "      <td>0.86751</td>\n",
              "      <td>0.86663</td>\n",
              "      <td>0.86576</td>\n",
              "      <td>0.86489</td>\n",
              "      <td>0.86402</td>\n",
              "      <td>0.86315</td>\n",
              "      <td>0.86230</td>\n",
              "      <td>0.86144</td>\n",
              "      <td>0.86059</td>\n",
              "      <td>0.85975</td>\n",
              "      <td>0.85891</td>\n",
              "      <td>0.85807</td>\n",
              "      <td>0.85724</td>\n",
              "      <td>0.85642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52307</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>318.25</td>\n",
              "      <td>0.973550</td>\n",
              "      <td>0.973080</td>\n",
              "      <td>0.97260</td>\n",
              "      <td>0.97211</td>\n",
              "      <td>0.97162</td>\n",
              "      <td>0.97111</td>\n",
              "      <td>0.97061</td>\n",
              "      <td>0.97009</td>\n",
              "      <td>0.96957</td>\n",
              "      <td>0.96905</td>\n",
              "      <td>0.96852</td>\n",
              "      <td>0.96799</td>\n",
              "      <td>0.96745</td>\n",
              "      <td>0.96692</td>\n",
              "      <td>0.96638</td>\n",
              "      <td>0.96584</td>\n",
              "      <td>0.96529</td>\n",
              "      <td>0.96475</td>\n",
              "      <td>0.96421</td>\n",
              "      <td>0.96366</td>\n",
              "      <td>0.96312</td>\n",
              "      <td>0.96258</td>\n",
              "      <td>0.96204</td>\n",
              "      <td>0.96151</td>\n",
              "      <td>0.96098</td>\n",
              "      <td>0.96046</td>\n",
              "      <td>0.95994</td>\n",
              "      <td>0.95942</td>\n",
              "      <td>0.95892</td>\n",
              "      <td>0.95842</td>\n",
              "      <td>0.95793</td>\n",
              "      <td>0.95745</td>\n",
              "      <td>0.95698</td>\n",
              "      <td>0.95653</td>\n",
              "      <td>0.95608</td>\n",
              "      <td>0.95565</td>\n",
              "      <td>0.95524</td>\n",
              "      <td>...</td>\n",
              "      <td>0.65345</td>\n",
              "      <td>0.65266</td>\n",
              "      <td>0.65187</td>\n",
              "      <td>0.65108</td>\n",
              "      <td>0.65029</td>\n",
              "      <td>0.64950</td>\n",
              "      <td>0.64871</td>\n",
              "      <td>0.64792</td>\n",
              "      <td>0.64714</td>\n",
              "      <td>0.64635</td>\n",
              "      <td>0.64557</td>\n",
              "      <td>0.64479</td>\n",
              "      <td>0.64400</td>\n",
              "      <td>0.64323</td>\n",
              "      <td>0.64245</td>\n",
              "      <td>0.64167</td>\n",
              "      <td>0.64089</td>\n",
              "      <td>0.64012</td>\n",
              "      <td>0.63935</td>\n",
              "      <td>0.63858</td>\n",
              "      <td>0.63781</td>\n",
              "      <td>0.63704</td>\n",
              "      <td>0.63628</td>\n",
              "      <td>0.63551</td>\n",
              "      <td>0.63475</td>\n",
              "      <td>0.63399</td>\n",
              "      <td>0.63324</td>\n",
              "      <td>0.63248</td>\n",
              "      <td>0.63173</td>\n",
              "      <td>0.63098</td>\n",
              "      <td>0.63023</td>\n",
              "      <td>0.62948</td>\n",
              "      <td>0.62873</td>\n",
              "      <td>0.62799</td>\n",
              "      <td>0.62725</td>\n",
              "      <td>0.62651</td>\n",
              "      <td>0.62578</td>\n",
              "      <td>0.62504</td>\n",
              "      <td>0.62431</td>\n",
              "      <td>0.62358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52308</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>284.75</td>\n",
              "      <td>0.025706</td>\n",
              "      <td>0.069033</td>\n",
              "      <td>0.12378</td>\n",
              "      <td>0.18295</td>\n",
              "      <td>0.24168</td>\n",
              "      <td>0.29707</td>\n",
              "      <td>0.34770</td>\n",
              "      <td>0.39309</td>\n",
              "      <td>0.43333</td>\n",
              "      <td>0.46877</td>\n",
              "      <td>0.49988</td>\n",
              "      <td>0.52718</td>\n",
              "      <td>0.55113</td>\n",
              "      <td>0.57219</td>\n",
              "      <td>0.59073</td>\n",
              "      <td>0.60709</td>\n",
              "      <td>0.62157</td>\n",
              "      <td>0.63441</td>\n",
              "      <td>0.64581</td>\n",
              "      <td>0.65597</td>\n",
              "      <td>0.66504</td>\n",
              "      <td>0.67314</td>\n",
              "      <td>0.68040</td>\n",
              "      <td>0.68691</td>\n",
              "      <td>0.69276</td>\n",
              "      <td>0.69801</td>\n",
              "      <td>0.70273</td>\n",
              "      <td>0.70698</td>\n",
              "      <td>0.71081</td>\n",
              "      <td>0.71425</td>\n",
              "      <td>0.71734</td>\n",
              "      <td>0.72012</td>\n",
              "      <td>0.72262</td>\n",
              "      <td>0.72485</td>\n",
              "      <td>0.72685</td>\n",
              "      <td>0.72864</td>\n",
              "      <td>0.73023</td>\n",
              "      <td>...</td>\n",
              "      <td>0.59986</td>\n",
              "      <td>0.59915</td>\n",
              "      <td>0.59843</td>\n",
              "      <td>0.59773</td>\n",
              "      <td>0.59702</td>\n",
              "      <td>0.59632</td>\n",
              "      <td>0.59562</td>\n",
              "      <td>0.59493</td>\n",
              "      <td>0.59424</td>\n",
              "      <td>0.59355</td>\n",
              "      <td>0.59287</td>\n",
              "      <td>0.59219</td>\n",
              "      <td>0.59151</td>\n",
              "      <td>0.59084</td>\n",
              "      <td>0.59017</td>\n",
              "      <td>0.58951</td>\n",
              "      <td>0.58884</td>\n",
              "      <td>0.58819</td>\n",
              "      <td>0.58753</td>\n",
              "      <td>0.58688</td>\n",
              "      <td>0.58623</td>\n",
              "      <td>0.58559</td>\n",
              "      <td>0.58495</td>\n",
              "      <td>0.58431</td>\n",
              "      <td>0.58368</td>\n",
              "      <td>0.58305</td>\n",
              "      <td>0.58242</td>\n",
              "      <td>0.58180</td>\n",
              "      <td>0.58118</td>\n",
              "      <td>0.58056</td>\n",
              "      <td>0.57995</td>\n",
              "      <td>0.57934</td>\n",
              "      <td>0.57873</td>\n",
              "      <td>0.57813</td>\n",
              "      <td>0.57753</td>\n",
              "      <td>0.57693</td>\n",
              "      <td>0.57634</td>\n",
              "      <td>0.57575</td>\n",
              "      <td>0.57516</td>\n",
              "      <td>0.57458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52309</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>217.75</td>\n",
              "      <td>0.649640</td>\n",
              "      <td>0.648220</td>\n",
              "      <td>0.64682</td>\n",
              "      <td>0.64542</td>\n",
              "      <td>0.64404</td>\n",
              "      <td>0.64267</td>\n",
              "      <td>0.64130</td>\n",
              "      <td>0.63995</td>\n",
              "      <td>0.63860</td>\n",
              "      <td>0.63727</td>\n",
              "      <td>0.63594</td>\n",
              "      <td>0.63462</td>\n",
              "      <td>0.63332</td>\n",
              "      <td>0.63202</td>\n",
              "      <td>0.63073</td>\n",
              "      <td>0.62946</td>\n",
              "      <td>0.62819</td>\n",
              "      <td>0.62693</td>\n",
              "      <td>0.62568</td>\n",
              "      <td>0.62444</td>\n",
              "      <td>0.62321</td>\n",
              "      <td>0.62199</td>\n",
              "      <td>0.62077</td>\n",
              "      <td>0.61957</td>\n",
              "      <td>0.61838</td>\n",
              "      <td>0.61719</td>\n",
              "      <td>0.61602</td>\n",
              "      <td>0.61485</td>\n",
              "      <td>0.61369</td>\n",
              "      <td>0.61255</td>\n",
              "      <td>0.61141</td>\n",
              "      <td>0.61027</td>\n",
              "      <td>0.60915</td>\n",
              "      <td>0.60804</td>\n",
              "      <td>0.60694</td>\n",
              "      <td>0.60584</td>\n",
              "      <td>0.60475</td>\n",
              "      <td>...</td>\n",
              "      <td>0.50886</td>\n",
              "      <td>0.50867</td>\n",
              "      <td>0.50848</td>\n",
              "      <td>0.50830</td>\n",
              "      <td>0.50811</td>\n",
              "      <td>0.50793</td>\n",
              "      <td>0.50775</td>\n",
              "      <td>0.50758</td>\n",
              "      <td>0.50740</td>\n",
              "      <td>0.50723</td>\n",
              "      <td>0.50706</td>\n",
              "      <td>0.50690</td>\n",
              "      <td>0.50673</td>\n",
              "      <td>0.50657</td>\n",
              "      <td>0.50641</td>\n",
              "      <td>0.50625</td>\n",
              "      <td>0.50610</td>\n",
              "      <td>0.50595</td>\n",
              "      <td>0.50580</td>\n",
              "      <td>0.50565</td>\n",
              "      <td>0.50550</td>\n",
              "      <td>0.50536</td>\n",
              "      <td>0.50522</td>\n",
              "      <td>0.50508</td>\n",
              "      <td>0.50494</td>\n",
              "      <td>0.50481</td>\n",
              "      <td>0.50467</td>\n",
              "      <td>0.50454</td>\n",
              "      <td>0.50442</td>\n",
              "      <td>0.50429</td>\n",
              "      <td>0.50416</td>\n",
              "      <td>0.50404</td>\n",
              "      <td>0.50392</td>\n",
              "      <td>0.50380</td>\n",
              "      <td>0.50369</td>\n",
              "      <td>0.50357</td>\n",
              "      <td>0.50346</td>\n",
              "      <td>0.50335</td>\n",
              "      <td>0.50324</td>\n",
              "      <td>0.50314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52310</th>\n",
              "      <td>248.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>268.00</td>\n",
              "      <td>0.770080</td>\n",
              "      <td>0.770050</td>\n",
              "      <td>0.76994</td>\n",
              "      <td>0.76977</td>\n",
              "      <td>0.76952</td>\n",
              "      <td>0.76922</td>\n",
              "      <td>0.76886</td>\n",
              "      <td>0.76844</td>\n",
              "      <td>0.76798</td>\n",
              "      <td>0.76746</td>\n",
              "      <td>0.76690</td>\n",
              "      <td>0.76630</td>\n",
              "      <td>0.76566</td>\n",
              "      <td>0.76498</td>\n",
              "      <td>0.76427</td>\n",
              "      <td>0.76352</td>\n",
              "      <td>0.76275</td>\n",
              "      <td>0.76194</td>\n",
              "      <td>0.76111</td>\n",
              "      <td>0.76025</td>\n",
              "      <td>0.75936</td>\n",
              "      <td>0.75845</td>\n",
              "      <td>0.75752</td>\n",
              "      <td>0.75657</td>\n",
              "      <td>0.75560</td>\n",
              "      <td>0.75462</td>\n",
              "      <td>0.75361</td>\n",
              "      <td>0.75259</td>\n",
              "      <td>0.75155</td>\n",
              "      <td>0.75050</td>\n",
              "      <td>0.74944</td>\n",
              "      <td>0.74836</td>\n",
              "      <td>0.74727</td>\n",
              "      <td>0.74617</td>\n",
              "      <td>0.74506</td>\n",
              "      <td>0.74394</td>\n",
              "      <td>0.74282</td>\n",
              "      <td>...</td>\n",
              "      <td>0.57273</td>\n",
              "      <td>0.57213</td>\n",
              "      <td>0.57152</td>\n",
              "      <td>0.57092</td>\n",
              "      <td>0.57033</td>\n",
              "      <td>0.56974</td>\n",
              "      <td>0.56915</td>\n",
              "      <td>0.56856</td>\n",
              "      <td>0.56798</td>\n",
              "      <td>0.56741</td>\n",
              "      <td>0.56683</td>\n",
              "      <td>0.56626</td>\n",
              "      <td>0.56570</td>\n",
              "      <td>0.56514</td>\n",
              "      <td>0.56458</td>\n",
              "      <td>0.56402</td>\n",
              "      <td>0.56347</td>\n",
              "      <td>0.56292</td>\n",
              "      <td>0.56238</td>\n",
              "      <td>0.56183</td>\n",
              "      <td>0.56130</td>\n",
              "      <td>0.56076</td>\n",
              "      <td>0.56023</td>\n",
              "      <td>0.55970</td>\n",
              "      <td>0.55918</td>\n",
              "      <td>0.55866</td>\n",
              "      <td>0.55814</td>\n",
              "      <td>0.55763</td>\n",
              "      <td>0.55712</td>\n",
              "      <td>0.55661</td>\n",
              "      <td>0.55610</td>\n",
              "      <td>0.55560</td>\n",
              "      <td>0.55511</td>\n",
              "      <td>0.55461</td>\n",
              "      <td>0.55412</td>\n",
              "      <td>0.55363</td>\n",
              "      <td>0.55315</td>\n",
              "      <td>0.55267</td>\n",
              "      <td>0.55219</td>\n",
              "      <td>0.55171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52311 rows × 254 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       # t_s  period    w_si    1400.0  ...   1647.0   1648.0   1649.0   1650.0\n",
              "0      208.0   450.0  382.50  0.951240  ...  0.69656  0.69559  0.69463  0.69367\n",
              "1      208.0   450.0  405.00  0.963090  ...  0.72567  0.72462  0.72357  0.72253\n",
              "2      208.0   450.0  270.00  0.787300  ...  0.58311  0.58262  0.58214  0.58165\n",
              "3      208.0   450.0  225.00  0.701080  ...  0.56127  0.56099  0.56071  0.56043\n",
              "4      208.0   450.0  292.50  0.829690  ...  0.60061  0.60001  0.59943  0.59884\n",
              "...      ...     ...     ...       ...  ...      ...      ...      ...      ...\n",
              "52306  248.0   670.0  435.50  0.989850  ...  0.85891  0.85807  0.85724  0.85642\n",
              "52307  248.0   670.0  318.25  0.973550  ...  0.62578  0.62504  0.62431  0.62358\n",
              "52308  248.0   670.0  284.75  0.025706  ...  0.57634  0.57575  0.57516  0.57458\n",
              "52309  248.0   670.0  217.75  0.649640  ...  0.50346  0.50335  0.50324  0.50314\n",
              "52310  248.0   670.0  268.00  0.770080  ...  0.55315  0.55267  0.55219  0.55171\n",
              "\n",
              "[52311 rows x 254 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfQW0UfYgRoX"
      },
      "source": [
        "X = df.drop(['# t_s'], 1)\n",
        "Y = df.drop(X, 1)\n",
        "\n",
        "#X = df.values[:, :3]\n",
        "#Y = df.values[:, 3:]\n",
        "X = X.values\n",
        "Y = Y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wD_gkcegWQf"
      },
      "source": [
        "#scaler_ts = preprocessing.StandardScaler().fit(Y)\n",
        "Y = scaler_ts.transform(Y)\n",
        "\n",
        "X[:, 2:] = scaler_R.transform(X[:, 2:])\n",
        "X[:, 0:1] = scaler_period.transform(X[:, 0:1])\n",
        "X[:, 1:2] = scaler_wsi.transform(X[:, 1:2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyBetHELgavH",
        "outputId": "4fcbc1c4-68a0-4078-ecdf-ddba6dc53295"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47079, 253) (5232, 253) (47079, 1) (5232, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3-hBIsJgdvn"
      },
      "source": [
        "model_ts = Sequential([\n",
        "    Dense(100, activation='relu', input_shape=X_train[0].shape),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(100, activation='relu'), \n",
        "    Dense(1, activation= 'linear')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZgF6bqqggfX",
        "outputId": "c1916f87-28bb-4fae-ab11-4e98e538df08"
      },
      "source": [
        "import keras.backend as K \n",
        "\n",
        "model_ts.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = tf.losses.MeanSquaredError(),\n",
        "              metrics=['acc'])\n",
        "\n",
        "hist = model_ts.fit(X_train, Y_train,\n",
        "          batch_size=32, epochs=400, \n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.2799 - acc: 0.0000e+00 - val_loss: 0.1364 - val_acc: 0.0000e+00\n",
            "Epoch 2/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.1122 - acc: 0.0000e+00 - val_loss: 0.1099 - val_acc: 0.0000e+00\n",
            "Epoch 3/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0811 - acc: 0.0000e+00 - val_loss: 0.0736 - val_acc: 0.0000e+00\n",
            "Epoch 4/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0740 - acc: 0.0000e+00 - val_loss: 0.0579 - val_acc: 0.0000e+00\n",
            "Epoch 5/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0668 - acc: 0.0000e+00 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
            "Epoch 6/400\n",
            "1472/1472 [==============================] - 3s 2ms/step - loss: 0.0570 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
            "Epoch 7/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0514 - acc: 0.0000e+00 - val_loss: 0.0881 - val_acc: 0.0000e+00\n",
            "Epoch 8/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0482 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
            "Epoch 9/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0410 - acc: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.0000e+00\n",
            "Epoch 10/400\n",
            "1472/1472 [==============================] - 4s 2ms/step - loss: 0.0386 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
            "Epoch 11/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
            "Epoch 12/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
            "Epoch 13/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0404 - val_acc: 0.0000e+00\n",
            "Epoch 14/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0000e+00\n",
            "Epoch 15/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
            "Epoch 16/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
            "Epoch 17/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
            "Epoch 18/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 19/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 20/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0204 - acc: 0.0000e+00 - val_loss: 0.0411 - val_acc: 0.0000e+00\n",
            "Epoch 21/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
            "Epoch 22/400\n",
            "1472/1472 [==============================] - 4s 2ms/step - loss: 0.0222 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
            "Epoch 23/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
            "Epoch 24/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
            "Epoch 25/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 26/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0520 - val_acc: 0.0000e+00\n",
            "Epoch 27/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0209 - acc: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.0000e+00\n",
            "Epoch 28/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
            "Epoch 29/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
            "Epoch 30/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
            "Epoch 31/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
            "Epoch 32/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0234 - val_acc: 0.0000e+00\n",
            "Epoch 33/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 34/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
            "Epoch 35/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 36/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
            "Epoch 37/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0000e+00\n",
            "Epoch 38/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
            "Epoch 39/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
            "Epoch 40/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0167 - val_acc: 0.0000e+00\n",
            "Epoch 41/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 42/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
            "Epoch 43/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
            "Epoch 44/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0000e+00\n",
            "Epoch 45/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
            "Epoch 46/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
            "Epoch 47/400\n",
            "1472/1472 [==============================] - 4s 2ms/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0000e+00\n",
            "Epoch 48/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 49/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 50/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
            "Epoch 51/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 52/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 53/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0064 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
            "Epoch 54/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 55/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 56/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 57/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
            "Epoch 58/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
            "Epoch 59/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
            "Epoch 60/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
            "Epoch 61/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
            "Epoch 62/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 63/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0796 - val_acc: 0.0000e+00\n",
            "Epoch 64/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 65/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
            "Epoch 66/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0075 - acc: 0.0000e+00 - val_loss: 0.0214 - val_acc: 0.0000e+00\n",
            "Epoch 67/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0067 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 68/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0070 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
            "Epoch 69/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0070 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
            "Epoch 70/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 71/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0066 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 72/400\n",
            "1472/1472 [==============================] - 4s 2ms/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 73/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0068 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
            "Epoch 74/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 75/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 76/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 77/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0076 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
            "Epoch 78/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 79/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 80/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0057 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 81/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 82/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0066 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 83/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
            "Epoch 84/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 85/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
            "Epoch 86/400\n",
            "1472/1472 [==============================] - 4s 2ms/step - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 87/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0059 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
            "Epoch 88/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
            "Epoch 89/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0067 - acc: 0.0000e+00 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
            "Epoch 90/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 91/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 92/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0054 - acc: 0.0000e+00 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
            "Epoch 93/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 94/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0073 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 95/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
            "Epoch 96/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 97/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 98/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 99/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0075 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 100/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0143 - val_acc: 0.0000e+00\n",
            "Epoch 101/400\n",
            "1472/1472 [==============================] - 4s 2ms/step - loss: 0.0076 - acc: 0.0000e+00 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
            "Epoch 102/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 103/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 104/400\n",
            "1472/1472 [==============================] - 6s 4ms/step - loss: 0.0057 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 105/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0131 - val_acc: 0.0000e+00\n",
            "Epoch 106/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0054 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 107/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0068 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 108/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0099 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 109/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 110/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 111/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
            "Epoch 112/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 113/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0063 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 114/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
            "Epoch 115/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0054 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 116/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
            "Epoch 117/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 118/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0069 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 119/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 120/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0066 - acc: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.0000e+00\n",
            "Epoch 121/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0057 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 122/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 123/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0052 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 124/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 125/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0089 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
            "Epoch 126/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 127/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0039 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 128/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 129/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0059 - acc: 0.0000e+00 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
            "Epoch 130/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 131/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 132/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 133/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 134/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
            "Epoch 135/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 136/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 137/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 138/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 139/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 140/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 141/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0063 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 142/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 143/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0050 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 144/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 145/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 146/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 147/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 148/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0075 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 149/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 150/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 151/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 152/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 153/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
            "Epoch 154/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 155/400\n",
            "1472/1472 [==============================] - 6s 4ms/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 156/400\n",
            "1472/1472 [==============================] - 6s 4ms/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 157/400\n",
            "1472/1472 [==============================] - 6s 4ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 158/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 159/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0057 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 160/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0072 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 161/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 162/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0067 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 163/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 164/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 165/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 166/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0039 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 167/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
            "Epoch 168/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 169/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0075 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 170/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 171/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0070 - acc: 0.0000e+00 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
            "Epoch 172/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0072 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 173/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 174/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0072 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 175/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 176/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0063 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 177/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 178/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 179/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
            "Epoch 180/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 181/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 182/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
            "Epoch 183/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 184/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 185/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 186/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 187/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 188/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 189/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 190/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 191/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 192/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0446 - val_acc: 0.0000e+00\n",
            "Epoch 193/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 194/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 195/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 196/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 197/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0044 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 198/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0052 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 199/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 200/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 201/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0052 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 202/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 203/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 204/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 205/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0039 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 206/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 207/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
            "Epoch 208/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 209/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0000e+00\n",
            "Epoch 210/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 211/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 212/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 213/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 214/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 215/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 216/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 217/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0054 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 218/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
            "Epoch 219/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 220/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 221/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0069 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 222/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 223/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 224/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 225/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 226/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 227/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 228/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 229/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 230/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0050 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 231/400\n",
            "1472/1472 [==============================] - 4s 2ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 232/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 233/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 234/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 235/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 236/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 237/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 238/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 239/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 240/400\n",
            "1472/1472 [==============================] - 4s 2ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 241/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0064 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 242/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 243/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
            "Epoch 244/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0039 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 245/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 246/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 247/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 9.2927e-04 - val_acc: 0.0000e+00\n",
            "Epoch 248/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 249/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 250/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 251/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 252/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 253/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 254/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0054 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 255/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 256/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
            "Epoch 257/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 258/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0057 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 259/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
            "Epoch 260/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 261/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 262/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 263/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 264/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 265/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0000e+00\n",
            "Epoch 266/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
            "Epoch 267/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0057 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 268/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 269/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 270/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 271/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 272/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 273/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0069 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 274/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 275/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0384 - val_acc: 0.0000e+00\n",
            "Epoch 276/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 277/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 278/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 279/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 280/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 281/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
            "Epoch 282/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 283/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
            "Epoch 284/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 285/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 286/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 287/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 288/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 289/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 290/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
            "Epoch 291/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
            "Epoch 292/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 293/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0069 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 294/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 295/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 296/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 297/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 298/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 299/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 300/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 301/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 302/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 9.9553e-04 - val_acc: 0.0000e+00\n",
            "Epoch 303/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 304/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 305/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 306/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 307/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 308/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 309/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 310/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 311/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 312/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 313/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 314/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0064 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 315/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 316/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 317/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0062 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 318/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 319/400\n",
            "1472/1472 [==============================] - 5s 4ms/step - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 320/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 321/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 322/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 323/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0050 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
            "Epoch 324/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 325/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 326/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 327/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 328/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 329/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0067 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 330/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 331/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 332/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 333/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 334/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 335/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 336/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 337/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 338/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 339/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 340/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 341/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 342/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 343/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 344/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 345/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0050 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
            "Epoch 346/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 347/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 8.3935e-04 - val_acc: 0.0000e+00\n",
            "Epoch 348/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 349/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 350/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 351/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
            "Epoch 352/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 353/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 354/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 9.6843e-04 - val_acc: 0.0000e+00\n",
            "Epoch 355/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 356/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 357/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 358/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 359/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 360/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 361/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 362/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 363/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0062 - acc: 0.0000e+00 - val_loss: 0.0520 - val_acc: 0.0000e+00\n",
            "Epoch 364/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0044 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 365/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 366/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 367/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 368/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 369/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
            "Epoch 370/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 9.7463e-04 - val_acc: 0.0000e+00\n",
            "Epoch 371/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 372/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 373/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 374/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 375/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 376/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 377/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 378/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 379/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 380/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 381/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 382/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 383/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 384/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 385/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 386/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 8.0577e-04 - val_acc: 0.0000e+00\n",
            "Epoch 387/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 388/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 389/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 390/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 391/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 392/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 393/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 394/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 395/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 396/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 397/400\n",
            "1472/1472 [==============================] - 5s 3ms/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 398/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 399/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 400/400\n",
            "1472/1472 [==============================] - 4s 3ms/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Vt6hDn_jS-et",
        "outputId": "142f215f-75ff-4af1-8ef8-c82119e840e3"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "#plt.ylim([0, 0.002])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa0fa35f080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU9dX48c+Z2U5vojQpYi+g2GJJ7KiJ6E+j2B6TmMckxsQUjZrYkzwxxRJjLyTGhtgiRhREQFEE6dJh6buw7MJWtk45vz/und07s7PLttnZZc/79drXztwyc/buzD33W6+oKsYYY0wsX7IDMMYY0zFZgjDGGBOXJQhjjDFxWYIwxhgTlyUIY4wxcVmCMMYYE5clCGPagIj8S0T+0MRtt4jIua19HWMSzRKEMcaYuCxBGGOMicsShOky3Kqd20XkaxEpF5EXRWSgiHwoImUiMlNE+ni2v0REVolIsYjMEZEjPOvGisgSd783gIyY9/q2iCxz950nIse2MOb/FZFsESkUkakiMshdLiLyqIjki0ipiKwQkaPddReJyGo3tlwRua1FB8x0eZYgTFdzOXAecCjwHeBD4LfAAJzvw88BRORQ4HXgF+66acD7IpImImnAf4CXgb7Am+7r4u47FpgE/AjoBzwLTBWR9OYEKiJnA38CrgQOArYCk93V5wNnun9HL3ebPe66F4EfqWoP4GhgVnPe15gISxCmq/mHqu5S1VxgLrBAVZeqahXwLjDW3e4q4ANV/VhVA8DfgEzgG8ApQCrwmKoGVPUtYKHnPW4CnlXVBaoaUtWXgGp3v+a4FpikqktUtRq4CzhVRIYDAaAHcDggqrpGVXe6+wWAI0Wkp6oWqeqSZr6vMYAlCNP17PI8rozzvLv7eBDOFTsAqhoGtgOD3XW5Gj3T5VbP44OBX7vVS8UiUgwMdfdrjtgY9uKUEgar6izgCeBJIF9EnhORnu6mlwMXAVtF5FMRObWZ72sMYAnCmIbswDnRA06dP85JPhfYCQx2l0UM8zzeDvxRVXt7frJU9fVWxtANp8oqF0BVH1fVE4AjcaqabneXL1TVCcABOFVhU5r5vsYAliCMacgU4GIROUdEUoFf41QTzQO+BILAz0UkVUT+H3CSZ9/ngR+LyMluY3I3EblYRHo0M4bXge+LyBi3/eL/cKrEtojIie7rpwLlQBUQdttIrhWRXm7VWCkQbsVxMF2YJQhj4lDVdcB1wD+A3TgN2t9R1RpVrQH+H/A9oBCnveIdz76LgP/FqQIqArLdbZsbw0zgHuBtnFLLKGCiu7onTiIqwqmG2gP81V13PbBFREqBH+O0ZRjTbGI3DDLGGBOPlSCMMcbEZQnCGGNMXJYgjDHGxGUJwhhjTFwpyQ6grfTv31+HDx+e7DCMMaZTWbx48W5VHRBv3X6TIIYPH86iRYuSHYYxxnQqIrK1oXVWxWSMMSYuSxDGGGPisgRhjDEmrv2mDcIYY1oiEAiQk5NDVVVVskNJqIyMDIYMGUJqamqT97EEYYzp0nJycujRowfDhw8neoLe/YeqsmfPHnJychgxYkST97MqJmNMl1ZVVUW/fv322+QAICL069ev2aUkSxDGmC5vf04OES35G7t8giivDvLIjHUs3VaU7FCMMaZD6fIJoioQ4vFZ2azILUl2KMaYLqi4uJinnnqq2ftddNFFFBcXJyCiOl0+QfjcYlc4bPfFMMa0v4YSRDAYbHS/adOm0bt370SFBVgvJiLVcpYfjDHJcOedd7Jx40bGjBlDamoqGRkZ9OnTh7Vr17J+/XouvfRStm/fTlVVFbfeeis33XQTUDe90N69e7nwwgs5/fTTmTdvHoMHD+a9994jMzOz1bFZgnAzhOUHY8wD769i9Y7SNn3NIwf15L7vHNXg+oceeoiVK1eybNky5syZw8UXX8zKlStru6NOmjSJvn37UllZyYknnsjll19Ov379ol5jw4YNvP766zz//PNceeWVvP3221x33XWtjr3LJwifW4KwW68aYzqCk046KWqswuOPP867774LwPbt29mwYUO9BDFixAjGjBkDwAknnMCWLVvaJJYunyAiJYiwJQhjurzGrvTbS7du3Wofz5kzh5kzZ/Lll1+SlZXFt771rbhjGdLT02sf+/1+Kisr2yQWa6SuLUEkNw5jTNfUo0cPysrK4q4rKSmhT58+ZGVlsXbtWubPn9+usVkJgkgJIsmBGGO6pH79+nHaaadx9NFHk5mZycCBA2vXjR8/nmeeeYYjjjiCww47jFNOOaVdY7MEESlBWDO1MSZJXnvttbjL09PT+fDDD+Oui7Qz9O/fn5UrV9Yuv+2229osLqtiivRisvxgjDFRunyCqB0HYXVMxhgTpcsnCJ+NgzDGmLgsQdSOpLYUYYwxXl0+QdSNg0hyIMYY08F0+QQBbjuElSCMMSaKJQicdggrQRhjkqGl030DPPbYY1RUVLRxRHUsQQCCtUEYY5KjIyeILj9QDpwShKUHY0wyeKf7Pu+88zjggAOYMmUK1dXVXHbZZTzwwAOUl5dz5ZVXkpOTQygU4p577mHXrl3s2LGDs846i/79+zN79uw2jy2hCUJExgN/B/zAC6r6UMz6XwE/BIJAAfADVd3qrgsBK9xNt6nqJYkL1EoQxhjgwzshb8W+t2uOA4+BCx9qcLV3uu8ZM2bw1ltv8dVXX6GqXHLJJXz22WcUFBQwaNAgPvjgA8CZo6lXr1488sgjzJ49m/79+7dtzK6EVTGJiB94ErgQOBK4WkSOjNlsKTBOVY8F3gL+4llXqapj3J/EJQfcrq6WH4wxSTZjxgxmzJjB2LFjOf7441m7di0bNmzgmGOO4eOPP+aOO+5g7ty59OrVq13iSWQJ4iQgW1U3AYjIZGACsDqygap6y0Tzgdbf4aIFnEZqyxDGdHmNXOm3B1Xlrrvu4kc/+lG9dUuWLGHatGncfffdnHPOOdx7770JjyeRjdSDge2e5znusobcCHhnpcoQkUUiMl9ELo23g4jc5G6zqKCgoMWBOo3ULd7dGGNazDvd9wUXXMCkSZPYu3cvALm5ueTn57Njxw6ysrK47rrruP3221myZEm9fROhQzRSi8h1wDjgm57FB6tqroiMBGaJyApV3ejdT1WfA54DGDduXItP8T4RGwZhjEkK73TfF154Iddccw2nnnoqAN27d+eVV14hOzub22+/HZ/PR2pqKk8//TQAN910E+PHj2fQoEGdrpE6FxjqeT7EXRZFRM4Ffgd8U1WrI8tVNdf9vUlE5gBjgY2x+7cFsUZqY0wSxU73feutt0Y9HzVqFBdccEG9/X72s5/xs5/9LGFxJbKKaSEwWkRGiEgaMBGY6t1ARMYCzwKXqGq+Z3kfEUl3H/cHTsPTdtHWRMTuSW2MMTESVoJQ1aCI3AJMx+nmOklVV4nIg8AiVZ0K/BXoDrzpzokU6c56BPCsiIRxkthDqpqwBOET68RkjDGxEtoGoarTgGkxy+71PD63gf3mAcckMjYv68VkTNemqrUTd+6vWlJLYlNtEGmDSHYUxphkyMjIYM+ePft1NbOqsmfPHjIyMpq1X4foxZRsYr2YjOmyhgwZQk5ODq3pKt8ZZGRkMGTIkGbtYwkCtw3CMoQxXVJqaiojRoxIdhgdklUxAYK1QRhjTCxLEERKEMmOwhhjOhZLEDhtENZIbYwx0SxB4PRiUhsJYYwxUSxBYHMxGWNMPJYgsLmYjDEmHksQWAnCGGPisQSBlSCMMSYeSxA4Nwyy/GCMMdEsQeBWMVkvJmOMiWIJAnc213CyozDGmI7FEgTWBmGMMfFYgsCdzTXZQRhjTAdjCYJII7WlCGOM8bIEAfh81ovJGGNiWYLAbjlqjDHxWILAqWKy2VyNMSaaJQiskdoYY+KxBIHdctQYY+KxBEHkhkGWIIwxxssSBHbLUWOMiccSBFaCMMaYeCxBYL2YjDEmHksQOOMgrBuTMcZES2iCEJHxIrJORLJF5M44638lIqtF5GsR+UREDvasu0FENrg/NyQyTp/PJuszxphYCUsQIuIHngQuBI4ErhaRI2M2WwqMU9VjgbeAv7j79gXuA04GTgLuE5E+CYsVa4MwxphYiSxBnARkq+omVa0BJgMTvBuo6mxVrXCfzgeGuI8vAD5W1UJVLQI+BsYnKlCrYTLGmPoSmSAGA9s9z3PcZQ25EfiwOfuKyE0iskhEFhUUFLQ4UKcXU4t3N8aY/VKHaKQWkeuAccBfm7Ofqj6nquNUddyAAQNa/P4+uym1McbUk8gEkQsM9Twf4i6LIiLnAr8DLlHV6ubs21Z8VoIwxph6EpkgFgKjRWSEiKQBE4Gp3g1EZCzwLE5yyPesmg6cLyJ93Mbp891lCeGMg7AMYYwxXimJemFVDYrILTgndj8wSVVXiciDwCJVnYpTpdQdeFNEALap6iWqWigiv8dJMgAPqmphomIVEathMsaYGAlLEACqOg2YFrPsXs/jcxvZdxIwKXHR1fGJlSCMMSZWh2ikTjaxyfqMMaYeSxA4jdRqIyGMMSaKJQisF5MxxsRjCQLA2iCMMaYeSxDYbK7GGBOPJQhsHIQxxsRjCQL3lqPJDsIYYzoYSxBEGqktRRhjjJclCHAaqcPJDsIYYzoWSxC4jdTGGGOiWILAptowxph4LEFgtxw1xph4LEEAPp/NxWSMMbEsQWC3HDXGmHgsQeAMlFMrQhhjTBRLEERmczXGGONlCQLnfhDWSG2MMdEsQeCOpLZGCGOMiWIJAveOcskOwhhjOhhLEDjjIKyGyRhjolmCwJ3N1TKEMcZEsQQB+Hw2DsIYY2JZgsBuGGSMMfFYgsAZSW3pwRhjolmCwNogjDEmHksQRAbKJTsKY4zpWBKaIERkvIisE5FsEbkzzvozRWSJiARF5IqYdSERWeb+TE1knD4RK0EYY0yMlES9sIj4gSeB84AcYKGITFXV1Z7NtgHfA26L8xKVqjomUfF52WyuxhhTX8ISBHASkK2qmwBEZDIwAahNEKq6xV2X1DtCR244qqqI3X7UGGOAxFYxDQa2e57nuMuaKkNEFonIfBG5NN4GInKTu82igoKCFgcauSe11TIZY0ydJiUIEblVRHqK40W33eD8BMd2sKqOA64BHhORUbEbqOpzqjpOVccNGDCgxW8UKTTYWAhjjKnT1BLED1S1FDgf6ANcDzy0j31ygaGe50PcZU2iqrnu703AHGBsU/dtLp+bICw9GGNMnaYmiEjF/EXAy6q6yrOsIQuB0SIyQkTSgIlAk3ojiUgfEUl3H/cHTsPTdtHWIu0OVoIwxpg6TU0Qi0VkBk6CmC4iPYBGG5ZVNQjcAkwH1gBTVHWViDwoIpcAiMiJIpIDfBd4VkRWubsfASwSkeXAbOChmN5PbSpSxWT5wRhj6jS1F9ONwBhgk6pWiEhf4Pv72klVpwHTYpbd63m8EKfqKXa/ecAxTYyt1ayR2hhj6mtqCeJUYJ2qFovIdcDdQEniwmpfPmukNsaYepqaIJ4GKkTkOODXwEbg3wmLqp0J1gZhjDGxmpoggurMRTEBeEJVnwR6JC6s9iXWi8kYY+ppaoIoE5G7cLq3fiAiPiA1cWG1o70FTPx8PJf7PkOTOp7bGGM6lqYmiKuAapzxEHk4Dct/TVhU7cmfSvfqXfSWvVbFZIwxHk1KEG5SeBXoJSLfBqpUdf9og0jrBkAm1VbFZIwxHk2dauNK4Cuc8QpXAgtip+futPyphCWFTKm2EoQxxng0dRzE74ATVTUfQEQGADOBtxIVWHsK+jPJCliCMMYYr6a2QfgiycG1pxn7dnhBfwYZ1Fg3JmOM8WhqCeIjEZkOvO4+v4qYEdKdWcif4VYxJTsSY4zpOJqUIFT1dhG5HGfSPIDnVPXdxIXVvoL+TLKoRq0IYYwxtZp8RzlVfRt4O4GxJE3In0kGNVaCMMYYj0YThIiUEb9mXgBV1Z4JiaqdhVIyyZJCwpYhjDGmVqMJQlX3m+k0GhPyZ5BJdbLDMMaYDmW/6YnUGnVVTFaCMMaYCEsQRKqYrBeTMcZ4WYIAwm4Vk1oJwhhjalmCAEIpWWRiJQhjjPGyBAGEUjJIlyAaCiQ7FGOM6TAsQQDqz3QeBKuSG4gxxnQgliBwqpgACJQnNxBjjOlALEEApDoliHB1RZIDMcaYjsMSBOBLd0oQwaq9SY7EGGM6DksQQEqakyAC1dYGYYwxEZYggJS0DAAC1ZVJjsQYYzoOSxBAarrTBhEKWIIwxpgISxBAaqQNosYm7DPGmIiEJggRGS8i60QkW0TujLP+TBFZIiJBEbkiZt0NIrLB/bkhkXGmpqcDEKqxEoQxxkQkLEGIiB94ErgQOBK4WkSOjNlsG/A94LWYffsC9wEnAycB94lIn0TFmpbhlCDCAStBGGNMRCJLECcB2aq6SVVrgMnABO8GqrpFVb8GwjH7XgB8rKqFqloEfAyMT1SgkTYIDVgvJmOMiUhkghgMbPc8z3GXtdm+InKTiCwSkUUFBQUtDjTdEoQxxtTTqRupVfU5VR2nquMGDBjQ4teRVKebazhkVUzGGBORyASRCwz1PB/iLkv0vs3ndxqpsRKEMcbUSmSCWAiMFpERIpIGTASmNnHf6cD5ItLHbZw+312WGClugghaCcIYYyISliBUNQjcgnNiXwNMUdVVIvKgiFwCICInikgO8F3gWRFZ5e5bCPweJ8ksBB50lyWGCDWkgFUxGWNMrZREvriqTgOmxSy71/N4IU71Ubx9JwGTEhmfV4A0JFjTXm9njDEdXqdupG5LAUlDwlaCMMaYCEsQrqCk4otUMeWtgLkPJzcgY4xJsoRWMXUmQV8avrBbxfTcWRAOwGm/BJ/lUGNM12RnP1fQl0ZKJEGEA85vDSUvIGOMSTJLEK6QtwRRuzCQnGCMMaYDsAThCvvS60oQtQstQRhjui5LEK6wL41UjU0QVsVkjOm6LEG4fKkZ+MI1VAU8SaEzVDGtfg82zEx2FMaY/ZAlCFd6ZhbpBNiyp7xuYTiYvICaau4jsODpZEdhjNkPWYJwZWVmkUaAzQXeBNEJShDhUOdIZMaYTscShKtbt26kS4BNuz0JItQJTrwasrYSY0xCWIJwpaZnkilBNhbsrVvYGa7Mw0FLEMaYhLAEEZGSQaZUs3l3Z6tiCnaORGaM6XQsQURk9iZDq9mWX1y3rDOceK0NwhiTIJYgIjJ6AyBVJXXLOkMbRDhkU4IYYxLCEkREZh8Aeom3DaKzVDFZgjDGtD1LEBGZTgmiF51sHIRaFZMxJjEsQUS4JYi+Pm83VytBGGO6LksQEW6CGJZZVbesM5x4rZHaGJMgliAi3EbqwRme2452ijYIGyhnjEkMSxARGb0A4cA0Twmis1QxWS8mY0wCWIKI8PkhoycD/BV1yzpD1Y01UhtjEsQShFdmH/r4OlGCULWR1MaYhLEE4dVzCENKFtU97+gnXg07v60NwhiTAJYgvMb/icyq/LrnHb0NIpIYLEEYYxLAEoTXQcei/rS654kqQXz0W1j8UutfJxJfS+Ms2wVbPm99HMaY/VJCE4SIjBeRdSKSLSJ3xlmfLiJvuOsXiMhwd/lwEakUkWXuzzOJjDMqppTMuictOfGGQ07bQGPmPwnv/7z5r13vvVqZIF44F/51cevjMMbslxKWIETEDzwJXAgcCVwtIkfGbHYjUKSqhwCPAn/2rNuoqmPcnx8nKs56UtJrH2pzq5jCIXiwL3x8bxsH1YBI99aWdnMt2ebuv4+EZoxpuvt7wfu/SHYUbSKRJYiTgGxV3aSqNcBkYELMNhOASF3LW8A5IiIJjGnfUjNqHxaUlDeyYRxBdwzF/KfaMKBGRNoeNAzhcOtfxxjTNhb/M9kRtIlEJojBwHbP8xx3WdxtVDUIlAD93HUjRGSpiHwqImfEewMRuUlEFonIooKCgraJ2lPFtH5nYfP2DbgJor2uyL1VS60ZLBeqaX0sxpj9TkdtpN4JDFPVscCvgNdEpGfsRqr6nKqOU9VxAwYMaJt39lQx5e4ubd6+wUo3sEau5tsyeXiv/FtTCrAEYUzbaE1JvgNKZILIBYZ6ng9xl8XdRkRSgF7AHlWtVtU9AKq6GNgIHJrAWOuk1pUgSiuq0Oac0IOReZwa2actu856SxCt6XHV0cd7GNNZdIb525ohkQliITBaREaISBowEZgas81U4Ab38RXALFVVERngNnIjIiOB0cCmBMZaJ6WuDeJsXUDhzi1N3zdQue9tglX73qapvNVKrTnJWwmi9Xathle/67lIMF3SfvZdSliCcNsUbgGmA2uAKaq6SkQeFJFL3M1eBPqJSDZOVVKkK+yZwNcisgyn8frHqtrMBoEW8iSIUb6d9Pz3OU3fN97JIfuT6OqftjyBeF+3sWqtfdnPPtRJsX0+bJgBpTuSHYlJpo4+uLaZUhL54qo6DZgWs+xez+Mq4Ltx9nsbeDuRsTXI04sJILVqT8Pblu+Bit0w4DDneTCmBLFhJrx6OZxzH5zxK2dZqC0TRBtVMXWGe293dJETw352gjDNtJ/9/ztqI3XypGTEX/7WD2DpK9HLnj0Dnjyp7nls9VG527OqYK1nG0+CaG2DddiqmDqMyP+1LS8ATOezn32XLEHEipMgtmxaByvfhvd+Gr2iNKbNPRCTIFLcaTu8HxpvEmlte0RUCcJ6MSVV5BgGu+ixXDsNKouTHUXyWSP1fs7TiynipRf/Ufdkd3b9fSIlgdgTfmReJ+9Jw1uCaEqjdmPaqgRhvZhaL5IgumKyrSyCyVfDijeTHUnyWRXTfu6wi+otOsu3rO7JjiX194mc9GMTRCRxeKsdohJEBa2iNg6iw6hNEF2wiqnG/RzX7E1uHB3BfvZdsgQRa+Q34d6iqEVn+lfUPaksop7IiT62RFBb7eBNEJ4kElsl1Vw2krrj6MqN1JHPdFetXvPaz/7/liDi8XkOS7cDANgedkdqf/kETP9d9PaRxBDbhbW24dLzxfE+DlQ4PYhaevXfZo3UVsXUarWlyC5Ygqi9EGrDMT6dlSWILqa/M4B7kR5KMLU7FG+DRZOih9TXJghPCSIU8FxZNVCCCFbBHwfCM+5UUy+cC8+d1fTY2qybq135tVpXboOIfKa74t8eaz87BpYg9iXgzOg6L3wUO6vdBuxABZR5BkSVbHMShjcRFG+DEneuwqheTDEliHAQ8lc5z3MWxm/jaIjNxdRxdOkEYSWIWvF6MRVthf/c3Cmr4CxB7Eu/QwCYFzqKErrVLn79w9l127x8GXx8T3QbxD+Oh88fdR431LW1tW0QbdVIbb2YWq9LJ4g4JeWuKl4V0/s/h2WvwtYv2j+eVrIE0RBxD83FD8P3PiCXAQRS6yaUXbVicfT2iyY1fAUVbGAcREO9mGo8y3ethnd/Ej8BWBVTx9GSNoiNs+Dxsa3v7pxsXTk5xoqXICLT4CT5VjctYQmiIXdshTu3QUYvGH46y+49j+OG9a1dPUpi5twJVDScILzd/7xfoqqS+NuX7YQdy2Drl/Dm92D5a7B7Q/3trBdTx9GSXky7VkHhJqhoZDqXzqC2BBHn8z/lf2DNf9s3nmSK913qxHdsTOhcTJ1aRvTtJ3pnpUXVL9ZLENBwlVF1mfMhEYn+EpXkxN++bGfdvaL7jW44xjbrxbR/9bxIilALptqoHT/QyvEwyVZbeoo5OYZDsPo96DEIjvh2+8eVDI19lzphorASRHO4VwcF2pPDfdvrrf5sZQMzkmuorjrJ/TJVaSo56z3VVN4PT1le/deId3XW2RJEOORMYLg/ihzD5jRE1o6faeatbTuahgaK7i9/X3M0NtVGJ2zEtwTRHO5JYFV4BAdI/XlnRoS3U6Wp8fct3+38DlYT9qWRowOQ/DV169/8Xt3j/NWeHd3EEa+9wpsUKgph+8J9/w21+3qSS3tVMWW7s9vuWtU+79ee4o152ZeGBlh2RCW5TnVYPA11c60pj/7dFXiPQWyJoTP8n2NYgmiOb/4GgOPPvzbu6qG+AnZpn/j7RkoFwWrC/jR2aD8Gq6eksPo/dY+3za97HPmQxfuSedsd3vlfePHcfQ96iyQGb6mhvSYYi9S1d/Y693haMtVGILlVTKGwkp3fxOkxHj3SaVCP+0INdHPtkgnC+72K+S5aCWI/d/jFcH8JPUed1OAmO7R//BVlO53fwSqCkkpOQ9uBMx4iInLyjvcli1etVN3IfbRXvAUP9nX6ZXuTQntVMVWXub/3wzl7WtJIXZPcKpi/z1zPuY98yqaCVv4/GppqI9I5o6smiEji1EZqATo4SxAt4Y6N8Aq5h3KNDou7yyPvfMY1z8+ntKyMGtLI1QENv763mFrdyJcsXtfXxhLE0ped37s3xP8gJ1ptgihrdLP1u8r46WtLqAl2ohvAh1rQzTVS5ZCkEsSCzc5NGvNKWnllG2yg9NQlSxDeaXViLhZaO+4pCSxBtER6j3qLIj2cN+jgqOUVmk6N+smszufLTXtYvzGbQl9fchsrQXiEIyfTuG0QcRJEVSMJovYDqjEJor1LEI3ECPx6ynI++Honq3Y00A24I2pJCSJSckjSlaXf53xqA+Fm9K4Jx0naDXVz7YoJwluqr/0sREoQ1gbRZflwvjgbwoPrLd+bNoCJh6fy3PXj6B3IZ015dxZrA91XfdE9j33eKqZwyBk4F9HcKqbIiaiyuPErncZUFDavkbmmAla968bmJoh9TAsdck9YgVAn6hbYkjvKRU4YSU4QpZXN+P9Xx0naDd0sqUtWMXmOQTjmoiH2lsSdgCWIluo+MO7il+/4n6jnab4wfQYOpU9oD2cd2p9Bvj3s1H50G1i/mgqgIv2A+O9XU07JjIfg6VOpznWnH483OK6xEkTkCq+yKKYNohlVTP+8EJ7+Rl29as5iyF3c8PYz73N6aG2bX3fC2EcVU9h97aKKdhzA9/UUuL9X/Oncm8I7mjhvRdOSbpLHQfjckb3F+0oQ3o4P8QZ37qsE0ZW6uca78Kq9ELAqpq6j5yDn99jr4Zo34cqX4YjvkNk7um3BpyGk52Ao2U5KoIwsqpFeg3n4yuP4Om1MvZddU+7M91Tlj67G0ppydnztzP/01eJFzhucS9oAABsCSURBVMIGShBLthXx89eXEgzFVAdEPqiVRS3vxRS5v3bkRPrC2fD82Q1vX7TV+V1eUL+RuroMdn5db5egW4IoLHe/bPlr60ohbaAmGKY6GJNc5z7sxrulZS8aOTHs2QTPnF5/Svh4aru5JitBOL9L9pWIvaXSuAkiThff3dl1c5E1sQQRDIUprWphdefuDfDwEc4kme1AVfnHJxvYvDvmbwvFqWIKJrek2BqWIFrqgj9B9wPh/D/AoefDkZfAVa/E33bgUU4fcnd09PcvPI2jBvUiMHEKN/oejNo0z+0muzHQN2r5m1+uJbfM+fCt37Ce7YUVzF0XZ0BdVSk/enkxU5fvYNWOUsKR+mVV2JvvblMclSBKy1vwwY25H3d1MMS6vDglA787LqSisH4j9fxnnCnOY66sQrEJ4qmTnVJIvPrvFjj74Tmc+ZfZ0Qsj7TnlLeyCGzk5lrgnqM2f7Xuf5iSI1VOd+6K3oaqAczyLKmJOyqpOKah2Q09SiHff6XjzUL18Kexxb88bqom+IPn0r/CPcfXGCdz1zgqOvX9G3We2OXKXODMs71ze/H1boKCsmoc/Xs+N/4oZexSviilyYbbiLdj+VbvE11YsQbTUwafCbesgs/e+tz3wGOf3rpXO755DADhh5ECeuGl81KbDDh4FQKFGlyBSw1Wk4V6dFG3mjL/MZuGm3fXfq3Ajj9fcxxApYMKTX3D3e+57VhbV1o9r6Q545rTaXT5bs4O8Hdth/Yx6L1dWFeCjlXlo7KCfkpyoE/tPX1nCBY99RlnsFWBkgrLSXE8bhPO7bMc6J6aYZFNW5fydReUxV7Z7d9X/e1sgp6iSXaUxbQWR0likO3LtexbA+7c6V8GlO+OPlA6H6/aPnEybMrK9Ob2YplwPb/1g39s1Q1m1878qjk0QyyfDM6ez9JM3nOfeBNFYFZOG6q6gIxcjEd5SxOw/wJ4NsGVu1CZvLnamninY24JZYSOfoVL3/5e3Ej76bZtdVMSKfH52lcZUG8W7OVjteJcy+OyvCYknUSxBJMKpt0Q/jySIiL4jah9mZkXP+XT0KKeb7ClHjYpaftwBqRzb06maOcW/hp7sZVRqnASx4BlOlZVc7f8EgNcWbOP95Tv4v39Prd2kZsv8qF1SCPHF0z+G176LegbphcPKZU/N48evLObWyct4c8Hm2nUbNqyNOrF/tdYZZbt5d7lTTaPqXDFlO3GEinPQmBLEuvVOg3tJXt0I3VBYKSx3vnyFsVUfDVT/vLFwG2vzGu8ZtXVPOTtLKqkK1FUtlbgnxveW5RIIOI935W5m3sbdddut/wgW/ws2zYEnToSvnq3/4vHacMJBKmtCXPbUF8xZl19/ff6auqqbeCWInEXwxeNRcQKgymsLtvHYzPWN/r3RsYTjJqFIIi6pjIk/16nCnDZrDhU1wZgqpugSRCAUJhTwnNAjjfT+tOjX9CaIXm5X8OVv1L8IALbuaUGJNpLYI5/J1yfC/CehtIH5zlopkhjqdaSI6sXkPvb2Xmpo/rUOyhJEIpz/B/itZzK/nm7PpoHHwK/WQndPQ3RqRtSukpLuLM6KLpn0SwvQu8Y50RwlW/g64yYmMKfBEHpT94X82etLkQLnZLw1fADpFdFVU+P9C7nc/zkAeZOu5f+ef4Xpq/L4+ycbKMnP4Wb/e0xbvo2H36274pu3ZBnzly6rfR6ZeiRv9efw9+NY9p9H4e0ba09+S5Yvo6TQib+0pAhVZUCoAIBd2zdSunI6RU+cTWFJGWGFn/incs2W37GrpO7LVbxjPT97bQmFewp48fPNbCrYy7q8Mu54ewU/enkxe6uDaE0Fu9/8BaHCrbX75ZVUMeHJL/jOPz7n8Hs+ql2+amcJ01bs5NbJSwmVOaWTjxcs45rnF3Dx43P5x38X1FVZrPvQuQJ0G+SDoTCvzN9KZU0ofs+lcJAPV+5k6bZi/jZjXfS6UBCeOqX2aWFxnGqbF86Bj+9hztcbOfXBuuROeQG/fXcFj83cUFsVEworz3y6kfyYq1lV5fY3l7Ppo7/Do0fV62ZZWlFDT8oprgg47VW7N8DqqewudhJCH9lLdv5evli5sXaf/IL8qNLkXz5ay9LNns9TpJrJHzPlTCRBqEKFc2FTtGUZY3//Mat3RCf3bYXRCSK/LH7j7vbCCm5+dTEllQGys92EGUkUkdH6bhuYqvLNv87mjx+sjvNKzZfnHuuamHa+6uq6WLPzCpm1ZmfTJujsoGw210QQgTT35kKpWc7zX65ypg6PHUOR2Qcuew4+vN0pvqe4CSOm6qpnxVanN8jwM9zG3WU0ZsJBhYwbsprcMuX5wmP4Zf+dsKU7u/yjObgyzhUtTvtHCgFO3/YM87d8yjDJ5+5+A5hQ/iZFdKdYu9due25oLt3mflw7AOTYXtVkF8PyT9/j/FTosfS5qMuPE6nrGrurYDcn/O4DVqU6X+K8bRsYPP9+elLJ5/+6mbEyjjtSJ0MFnP/QS8xwcibvzfqcS6pewr9uDS/X/J6+8+axaMj3Aeeq8+j7pvPCYQs5d+s/+WhjHqtPeJBbzxnNr99cFlONooDw4+c/4faUKTyaWkmGOOsHuoluc0EZPyubULtHeM0H+ICK3FX8/KWF+Cv2MHNrDdsLK7jssHQOjzmW4b0FPDHLmaJ9ZW4pVz7xCa8ds5SUAYeiW7/Ae2eAtdvyGFMTJMsXpkr9LNhcyDfddfPnf85gqTvB5GxajZ8Q09LuYs3kL3i45jIuGzuYhz5cy6odpYwd2psDeqbz7WMHsbFgL28uzuG8tP8y0leI7vwaGXYyqspjMzdwQc0MHsp4ge/k/Jlb/jCPJ/kTfg2yMzyc/j4YLnn8feYG+mxYw2nu+X7y3BX06L6F75/mlIJnryvg3EB17f96Y94epHsqwwOV0VefkZ5MlUW1Fw1ZJdmAsunzNzj8xCNqN91WWIGqUloZZE1eKROfm8/T1x7PNw7pT1UgxIzVu7j6xKH8Y9YGpq3IY2DPDC7dvQ18kJ+7iQGqaCiID6jM30jmiDNYt6uMrXsqeH7uZm45azS9shqYM83j/XnLKCou4X8ucv8bNeUw+Ro4627yS+tK/lWBEBmpfqgoJLT2w9rl97yzlGXhUtZ4rwGrS53veUavfb5/eXWQykCI/t3TG9ymsjrItt2lHDa4b4PbtEZCE4SIjAf+DviBF1T1oZj16cC/gROAPcBVqrrFXXcXcCMQAn6uqtMTGWtCXP4iDHLnr+k1pOHtjrsKDjkHdq93qqPy18Dpv4QtXzhF+rTuyM5lkN4LLvobHHC4cyX2gJtEuh8II78FX092no88i+6bZnNYwVIOA84GKAS6DWDUsJGwpu7OVk8GL+Fi3wKG+3bR74wfkiLKmXP/xpl+t5HS/V7/NuMteoSc+uevMr7BSVXzov6ER6ru4ZCUS7g5xbnaHeWrq8uvUT9pUle1010quZAva5edueOF2nWnl7zP6env1z6f6K9rTL4hMMX5JAFz0n8NFTBk7Qqy0k5lTuAoBkgxIze/Dj7oXbGF92d9xt6vXmF92aHcMCzEl9srOcW3mhv8M3g0eAU/T3mHQ3111WQVZHKw5HFHyuuUaVbU3+erckYdpxRtZFHeRham38z6tCH8cu7NLP+8jMkxNSq+UBXhvbsZ3q8/eXuK+G3+3aTMdqrSYm8bkyk1TH3pYa7Y8VceCn2P12pOZ717UkndPo/7UuoajP82eTrX+/dymC+HwnUv8Xn1Scxam89pvhXctu42rlz+W3bRl7ySKv7wgTMZ5LHilACefGUKaw5O5fiKzwlt+ZpfpzhfqfdT76gdywVwjG8LACMkjy/Wbuc/adMAqJZ0RspOHv1kMVcdmEfKF3+jV8FppKfWVRNt/ecPKaEbI/3RpZVZ09+l98EbKU/pwxnAsrSxjKlZykjZydmr7yGwYzDwAIIyd9Y03vj0IIrpSZrfOVo/eXUJ3/EvYEP4INbqMMqrg+SXOaWVT+fN475059juLdjOrAWbmBh2Ypo+dx7n9TiIaVsP5Cf+qWTrII57EGb+6kwOOaD+gNdA3moI1uA/4DCOnnEtqVpF0Zmr6LN7Mcx73KlqLN/Nrv5PcKv/bUb7cnnyjSD5/oH8YucdHKR1pZ8b/DMo0svrvYcWb+PN7b3pnpHCRUcf6CwLBZAU90O09FUYeCQfTv4ng4sWkv6bj5C0bmSl+nn2s00s3FLIX74zkpziStZOfYTLil8i75a1HDigkdkZWkjqNT621QuL+IH1wHlADrAQuFpVV3u2uRk4VlV/LCITgctU9SoRORJ4HTgJGATMBA5VbfiuOOPGjdNFixYl5G9JuiUvQ/bHcP4foffQuuWFm51kcuh48Plg8rXOILZLn4YPfg1DT4QBh8PMB5yudqfe4nTLfepkGHwC4UHHs/eb91Ex62EOXPIojH/Iea0nTozu+nryT2DB06j4CF32PCnHXO700snqy9K12Yyd871Gw1928A/4b/Vx3J13a5P/5KqDz6Iy52v6hJxSxt5+x9B9zwrK0g5gbsZZXFT6RoP71qT2JC1QV20Rxo+P+B+dwJl3saE0hT99FeD6QTs4f/e/mxxjrGpNJV3qjlugzyg+630Z1dmfMd63kIeD3+Us/zLG+aLbD8rJJKhCL2l63XulppEpNfw3dDI9qOSb/rruwrNDxzEvfBSn+NYwQIo51lfXdnRDzR28lPbn2ufZPU9h6N7lpIdjBnH5UqkOweLwaL7hX83U0KmUawZXp8ymSLvTR5z2sDLNpIYU+kn9HmzLwyPZrAdyqb/uYmJB+HBO9q3lD4FruTv11ajtN4UPZKTPqa4q1m48Fr6KG+V9Vupw1ulQfpHyDtvDA3gg7VdsK/cxWHZTTSpPpf6d3lJOCCFECn8IXMODqS9FvfYGHcxocS4GLq7+P44ePZxe4VIywhUUFBbROzXA0b2qOSfnSXwaYl74aL7ld6oXn+v3G27a85eo13sqWHcxFCuQdQCpFfFL6QDvhb7B48HLuCHlY65OmUOq1lCu6byZdRUV/p7cvPeJqO03hg9imw4knNWPwvIAX+nh/DLlLQKawsE+531mHnY/5179ywbfszEislhVx8Vdl8AEcSpwv6pe4D6/C0BV/+TZZrq7zZcikgLkAQOAO73berdr6P326wTRVKrOjy9O01Io4IzSFnGmbk7NhCy3WFrt9q4483anCqyy2OkxVJLj1CWPOBNm3u/MQTX2uvrv+dJ3oN8oyny92H3MDxnRywdfPuWUhnoPhcHjIDWDDV++x7Ahw0if/hunmuGQc9HBxyM15c57apiasgJ8J9xASt+DIX81OvMBKlN7kfXtP8MHv4KTfgTDToVFLzqlsu1fwZGXEPxqEim710Kf4XD4RU632DHXoQceg6yYUtt2EMrog/+UHztVef1GwaHjqVYff5u+jptOHcSA/0wkkNaL9dV9OHzCb/B/eBvabxR8PQUdfiZauBF//ioCBxxH9sm/Z/WiT5lwaBq+7BmsGHodx83/JaGjr8R/zOXOfcp3O8kg/+Q7yTjrNpZuK+YbW57Av/VzfLmL0EMvQItz2B3uju/c++jzye34C9zquFFnw8bZaEoG1b1HUTX622TMf4zSY29k9+jv0n3jfxm6/DEkHCTQfTCpe6N7g9X+68VPcOS5pG2cgbhFhcqhZ/KrjWO59vs/5/Th3Z04Z/zO6ZnmS4FvP0LZcxfRI1hI6NirmXvUg3TbNocTv/jf2tfdnjqcPlJOugQp6Xk4/Qucr2f1kNNIz/mCp454mTXBQdy+/acMq1pbu1+xdmPZRe9z4vQJZEoNNVkHEi7fQ1Z4L8Eeg/ENP43Aps9JL4++KVcwvTf+6pLav8FrZs/LOGfCDYSnfB9/dRGF/n706Z6JlOQQVsEnTTvPBfGzVg/maNnEZ2lncGrNfFIJEFA/qRJ9kVHh70HWT+fy9Yx/4kcp7XEIq7ufyg+OCCFPncIu7cOKoddSXlbChJKX671XGGGP9iCDADu0H4f56rdPzM08h5S9OznZtwafKDWSTprWb/Na6j+WsffMrbe8KZKVIK4AxqvqD93n1wMnq+otnm1WutvkuM83AicD9wPzVfUVd/mLwIeq+lbMe9wE3AQwbNiwE7Zu3YoxqDpVc5l96i9L616/AbW5ImMB4nVxLstz2p/SezjvWZrrbD/wqPr3JI5XFx0Kgs/vNPamZjjdav2pdfuGw9EXALtWOfX6w093xpoUb4MeBzmj1sUHpTug9zAnUQcqYekrzrpv3IqKILExeS8yKgqdxDHkRCcmt2daqN9oQgccTVqKvy6uUBDW/tf520ef51x0RNrbqvcSyltJcOAxpO7dxQ7tw5ABfZy/JbJ/eYFTGh5+hvPehZtg3Udw3ESqCzaypaiGw0YfDpWFULSFXQUF0P0ABmYq5ZKJDDuFrLQUKMujKHshPUafRkrVHigvoOqgk0jfudDpAJLZh6I1c8grKmP0iBGkZPWC1G6QlkVNGNL8PorTBtJjw3tOks9dRHDNh/jGfR/J6k0wDLsWvsPAXt0I9zuE9JGnEde2+ejgcYjfrcXPXwtFmyGrH6pKcMdyqvsdQXH/E8jwhQkHayid90+GDR7EtkBP0rv1hnUfMGTC/Xy+uYQxPUqhcDM9Rp9OWfY81nIwJ/YLwN488nK30j3NR/eTr2/4M9uI/TZBeFkJwhhjmq+xBJHIbq65gKfCnCHusrjbuFVMvXAaq5uyrzHGmARKZIJYCIwWkREikgZMBGJbdaYCN7iPrwBmqVOkmQpMFJF0ERkBjAY61xh1Y4zp5BLWzVVVgyJyCzAdp3PiJFVdJSIPAotUdSrwIvCyiGTjdMSc6O67SkSmAKuBIPDTxnowGWOMaXsJa4Nob9YGYYwxzZesNghjjDGdmCUIY4wxcVmCMMYYE5clCGOMMXHtN43UIlIAtGYodX8gzg0Wks7iah6Lq3k6alzQcWPb3+I6WFXjzvS33ySI1hKRRQ215CeTxdU8FlfzdNS4oOPG1pXisiomY4wxcVmCMMYYE5cliDrPJTuABlhczWNxNU9HjQs6bmxdJi5rgzDGGBOXlSCMMcbEZQnCGGNMXF0+QYjIeBFZJyLZInJnkmPZIiIrRGSZiCxyl/UVkY9FZIP7u8++XqeNYpkkIvnuTZ0iy+LGIo7H3WP4tYgc385x3S8iue5xWyYiF3nW3eXGtU5ELkhgXENFZLaIrBaRVSJyq7s8qceskbiSesxEJENEvhKR5W5cD7jLR4jIAvf933BvFYA79f8b7vIFIjK8neP6l4hs9hyvMe7ydvvsu+/nF5GlIvJf93lij5eqdtkfnGnINwIjgTRgOXBkEuPZAvSPWfYX4E738Z3An9spljOB44GV+4oFuAj4EBDgFGBBO8d1P3BbnG2PdP+n6cAI93/tT1BcBwHHu497AOvd90/qMWskrqQeM/fv7u4+TgUWuMdhCjDRXf4M8BP38c3AM+7jicAbCTpeDcX1L+CKONu322fffb9fAa8B/3WfJ/R4dfUSxElAtqpuUtUaYDIwIckxxZoAvOQ+fgm4tD3eVFU/w7lHR1NimQD8Wx3zgd4iclA7xtWQCcBkVa1W1c1ANs7/PBFx7VTVJe7jMmANMJgkH7NG4mpIuxwz9+/e6z5NdX8UOBuI3Fo49nhFjuNbwDkisTfUTmhcDWm3z76IDAEuBl5wnwsJPl5dPUEMBrZ7nufQ+Jcn0RSYISKLReQmd9lAVd3pPs4DBiYntEZj6QjH8Ra3iD/JUw2XlLjc4vxYnKvPDnPMYuKCJB8zt7pkGZAPfIxTWilW1WCc966Ny11fAvRrj7hUNXK8/uger0dFJD02rjgxt7XHgN8AYfd5PxJ8vLp6guhoTlfV44ELgZ+KyJneleqUFztEv+SOFAvwNDAKGAPsBB5OViAi0h14G/iFqpZ61yXzmMWJK+nHTFVDqjoG557zJwGHt3cM8cTGJSJHA3fhxHci0Be4oz1jEpFvA/mqurg937erJ4hcYKjn+RB3WVKoaq77Ox94F+dLsytSZHV/5ycrvkZiSepxVNVd7pc6DDxPXZVIu8YlIqk4J+FXVfUdd3HSj1m8uDrKMXNjKQZmA6fiVNFEboXsfe/auNz1vYA97RTXeLeqTlW1Gvgn7X+8TgMuEZEtOFXhZwN/J8HHq6sniIXAaLcnQBpOY87UZAQiIt1EpEfkMXA+sNKN5wZ3sxuA95IRn6uhWKYC/+P26DgFKPFUqyRcTJ3vZTjHLRLXRLdHxwhgNPBVgmIQnHusr1HVRzyrknrMGoor2cdMRAaISG/3cSZwHk77yGzgCnez2OMVOY5XALPcEll7xLXWk+QFp57fe7wS/n9U1btUdYiqDsc5T81S1WtJ9PFqyxb2zviD0wthPU795++SGMdInN4jy4FVkVhw6g0/ATYAM4G+7RTP6zhVDwGcus0bG4oFpwfHk+4xXAGMa+e4Xnbf92v3i3GQZ/vfuXGtAy5MYFyn41QffQ0sc38uSvYxaySupB4z4Fhgqfv+K4F7Pd+Dr3Aax98E0t3lGe7zbHf9yHaOa5Z7vFYCr1DX06ndPvueGL9FXS+mhB4vm2rDGGNMXF29iskYY0wDLEEYY4yJyxKEMcaYuCxBGGOMicsShDHGmLgsQRjTAYjItyIzdBrTUViCMMYYE5clCGOaQUSuc+8XsExEnnUndtvrTuC2SkQ+EZEB7rZjRGS+O8Hbu1J3L4hDRGSmOPccWCIio9yX7y4ib4nIWhF5NRGzlRrTHJYgjGkiETkCuAo4TZ3J3ELAtUA3YJGqHgV8Ctzn7vJv4A5VPRZnlG1k+avAk6p6HPANnJHh4My0+gucezKMxJl/x5ikSdn3JsYY1znACcBC9+I+E2fyvTDwhrvNK8A7ItIL6K2qn7rLXwLedOfbGqyq7wKoahWA+3pfqWqO+3wZMBz4PPF/ljHxWYIwpukEeElV74paKHJPzHYtnb+m2vM4hH0/TZJZFZMxTfcJcIWIHAC195s+GOd7FJlR8xrgc1UtAYpE5Ax3+fXAp+rc1S1HRC51XyNdRLLa9a8wponsCsWYJlLV1SJyN85d/3w4M8r+FCjHubHM3ThVTle5u9wAPOMmgE3A993l1wPPisiD7mt8tx3/DGOazGZzNaaVRGSvqnZPdhzGtDWrYjLGGBOXlSCMMcbEZSUIY4wxcVmCMMYYE5clCGOMMXFZgjDGGBOXJQhjjDFx/X8Jri33eCcFbwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpRkMUfFgm5I"
      },
      "source": [
        "y_pred = model_ts.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA5VYG4pgp_f"
      },
      "source": [
        "import keras.backend as K \n",
        "\n",
        "def my_accuracy(y_pred, y_true):\n",
        "    diff = K.abs(y_true-y_pred)\n",
        "    correct = K.less(diff, 0.05)\n",
        "    return K.mean(correct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dM2LhwlgtOg",
        "outputId": "6db09baa-d7ae-41f7-97a4-dca38e5f5c2c"
      },
      "source": [
        "my_accuracy(y_pred, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9239297>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVsu__kLgyaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e5b48b-7bfc-46bd-80d8-38852f44df6b"
      },
      "source": [
        "rmse = np.sqrt(mean_squared_error(Y_test, y_pred))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.031987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScBo8mH4g1i4"
      },
      "source": [
        "model_ts.save('/content/gdrive/MyDrive/model_nn_ts.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EcXzZuszLvM"
      },
      "source": [
        "#testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUecnVVF5FkG"
      },
      "source": [
        "model_period = tf.keras.models.load_model('/content/gdrive/MyDrive/model_nn_period.h5')\n",
        "model_wsi = tf.keras.models.load_model('/content/gdrive/MyDrive/model_nn_wsi.h5')\n",
        "model_ts = tf.keras.models.load_model('/content/gdrive/MyDrive/model_nn_ts.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y82PK8RCio4E",
        "outputId": "f8e49f37-2cea-4928-f381-c3a3a0be1cf6"
      },
      "source": [
        "model_ts.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 100)               25400     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 65,901\n",
            "Trainable params: 65,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgdPPNUrzMYi"
      },
      "source": [
        "prreds = model_wsi.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrXLRr4-zRO6"
      },
      "source": [
        " import keras.backend as K \n",
        "\n",
        "def my_accuracy(y_pred, y_true):\n",
        "    diff = K.abs(y_true-y_pred)\n",
        "    correct = K.less(diff, 0.05)\n",
        "    return K.mean(correct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTgLDzJKzbuo",
        "outputId": "8671f578-31e0-44e5-8325-3ec28d270697"
      },
      "source": [
        "my_accuracy(prreds, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.94227827>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odKr_Ik9g7zw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "d6bfe574-93db-4883-d3b7-dbb29c870679"
      },
      "source": [
        "x_axis = [i for i in range(1400, 1651)]\n",
        "\n",
        "plt.plot(x_axis, scaler_R.inverse_transform(X_test[:, 2:])[88])\n",
        "plt.xlabel('wavelength')\n",
        "plt.ylabel('transmittance')\n",
        "plt.title('Input')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Input')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-uYRsjKrZLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cdf1f7-3b51-4988-8c10-2c548031d212"
      },
      "source": [
        "scaler_R.inverse_transform(X_test[:, 2:])[88]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.0612e-01, 8.0770e-01, 8.0926e-01, 8.1081e-01, 8.1234e-01,\n",
              "       8.1386e-01, 8.1536e-01, 8.1685e-01, 8.1832e-01, 8.1977e-01,\n",
              "       8.2121e-01, 8.2263e-01, 8.2404e-01, 8.2543e-01, 8.2680e-01,\n",
              "       8.2815e-01, 8.2949e-01, 8.3081e-01, 8.3212e-01, 8.3340e-01,\n",
              "       8.3467e-01, 8.3593e-01, 8.3716e-01, 8.3838e-01, 8.3957e-01,\n",
              "       8.4075e-01, 8.4192e-01, 8.4306e-01, 8.4419e-01, 8.4529e-01,\n",
              "       8.4638e-01, 8.4745e-01, 8.4850e-01, 8.4953e-01, 8.5054e-01,\n",
              "       8.5153e-01, 8.5250e-01, 8.5345e-01, 8.5438e-01, 8.5529e-01,\n",
              "       8.5618e-01, 8.5705e-01, 8.5790e-01, 8.5872e-01, 8.5953e-01,\n",
              "       8.6031e-01, 8.6107e-01, 8.6181e-01, 8.6253e-01, 8.6322e-01,\n",
              "       8.6389e-01, 8.6453e-01, 8.6515e-01, 8.6575e-01, 8.6632e-01,\n",
              "       8.6686e-01, 8.6738e-01, 8.6788e-01, 8.6834e-01, 8.6878e-01,\n",
              "       8.6919e-01, 8.6957e-01, 8.6992e-01, 8.7025e-01, 8.7054e-01,\n",
              "       8.7080e-01, 8.7102e-01, 8.7122e-01, 8.7138e-01, 8.7150e-01,\n",
              "       8.7159e-01, 8.7164e-01, 8.7165e-01, 8.7162e-01, 8.7155e-01,\n",
              "       8.7143e-01, 8.7127e-01, 8.7107e-01, 8.7081e-01, 8.7051e-01,\n",
              "       8.7015e-01, 8.6974e-01, 8.6927e-01, 8.6874e-01, 8.6815e-01,\n",
              "       8.6749e-01, 8.6676e-01, 8.6595e-01, 8.6507e-01, 8.6411e-01,\n",
              "       8.6307e-01, 8.6193e-01, 8.6069e-01, 8.5935e-01, 8.5791e-01,\n",
              "       8.5635e-01, 8.5466e-01, 8.5284e-01, 8.5089e-01, 8.4878e-01,\n",
              "       8.4651e-01, 8.4407e-01, 8.4145e-01, 8.3863e-01, 8.3559e-01,\n",
              "       8.3232e-01, 8.2880e-01, 8.2502e-01, 8.2094e-01, 8.1655e-01,\n",
              "       8.1182e-01, 8.0671e-01, 8.0121e-01, 7.9527e-01, 7.8885e-01,\n",
              "       7.8191e-01, 7.7440e-01, 7.6628e-01, 7.5748e-01, 7.4795e-01,\n",
              "       7.3761e-01, 7.2640e-01, 7.1422e-01, 7.0101e-01, 6.8665e-01,\n",
              "       6.7106e-01, 6.5413e-01, 6.3576e-01, 6.1582e-01, 5.9422e-01,\n",
              "       5.7084e-01, 5.4560e-01, 5.1842e-01, 4.8924e-01, 4.5807e-01,\n",
              "       4.2493e-01, 3.8995e-01, 3.5332e-01, 3.1535e-01, 2.7645e-01,\n",
              "       2.3718e-01, 1.9821e-01, 1.6036e-01, 1.2453e-01, 9.1656e-02,\n",
              "       6.2697e-02, 3.8521e-02, 1.9851e-02, 7.1998e-03, 8.2680e-04,\n",
              "       7.1800e-04, 6.5980e-03, 1.7967e-02, 3.4154e-02, 5.4384e-02,\n",
              "       7.7838e-02, 1.0371e-01, 1.3124e-01, 1.5977e-01, 1.8871e-01,\n",
              "       2.1760e-01, 2.4605e-01, 2.7377e-01, 3.0056e-01, 3.2626e-01,\n",
              "       3.5079e-01, 3.7409e-01, 3.9615e-01, 4.1697e-01, 4.3658e-01,\n",
              "       4.5503e-01, 4.7234e-01, 4.8859e-01, 5.0383e-01, 5.1811e-01,\n",
              "       5.3149e-01, 5.4402e-01, 5.5577e-01, 5.6678e-01, 5.7710e-01,\n",
              "       5.8678e-01, 5.9585e-01, 6.0437e-01, 6.1237e-01, 6.1988e-01,\n",
              "       6.2693e-01, 6.3357e-01, 6.3980e-01, 6.4567e-01, 6.5119e-01,\n",
              "       6.5639e-01, 6.6128e-01, 6.6589e-01, 6.7024e-01, 6.7434e-01,\n",
              "       6.7820e-01, 6.8184e-01, 6.8528e-01, 6.8852e-01, 6.9158e-01,\n",
              "       6.9447e-01, 6.9719e-01, 6.9976e-01, 7.0219e-01, 7.0448e-01,\n",
              "       7.0664e-01, 7.0867e-01, 7.1059e-01, 7.1240e-01, 7.1411e-01,\n",
              "       7.1572e-01, 7.1723e-01, 7.1865e-01, 7.1999e-01, 7.2125e-01,\n",
              "       7.2242e-01, 7.2353e-01, 7.2457e-01, 7.2553e-01, 7.2644e-01,\n",
              "       7.2728e-01, 7.2807e-01, 7.2880e-01, 7.2948e-01, 7.3011e-01,\n",
              "       7.3068e-01, 7.3121e-01, 7.3170e-01, 7.3215e-01, 7.3255e-01,\n",
              "       7.3291e-01, 7.3324e-01, 7.3353e-01, 7.3378e-01, 7.3400e-01,\n",
              "       7.3419e-01, 7.3435e-01, 7.3448e-01, 7.3458e-01, 7.3465e-01,\n",
              "       7.3469e-01, 7.3471e-01, 7.3471e-01, 7.3468e-01, 7.3463e-01,\n",
              "       7.3455e-01, 7.3446e-01, 7.3434e-01, 7.3421e-01, 7.3405e-01,\n",
              "       7.3388e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obFCAWG6za1c"
      },
      "source": [
        "\n",
        "def pred_params(model_period, model_wsi, model_ts, test_arr):\n",
        "  t_s = [-6.432930734567939e-16]\n",
        "  w_si = [7.66762964455997e-17]\n",
        "  period = [-2.9841952753052706e-16]\n",
        "  test = np.ones([253])\n",
        "\n",
        "  i = 0\n",
        "  test[2:] = test_arr\n",
        "\n",
        "  go = True\n",
        "  while go == True:\n",
        "    test[0] = t_s[-1]\n",
        "    test[1] = w_si[-1]\n",
        "\n",
        "    period = np.append(period, model_period.predict(np.array([test])))\n",
        "\n",
        "    test[0] = t_s[-1]\n",
        "    test[1] = period[-1] \n",
        "\n",
        "    w_si = np.append(w_si, model_wsi.predict(np.array([test])))\n",
        "\n",
        "    test[0] = period[-1]\n",
        "    test[1] = w_si[-1] \n",
        "\n",
        "    t_s = np.append(t_s, model_ts.predict(np.array([test])))\n",
        "\n",
        "    if (abs(t_s[-1]-t_s[-2])<=0.000001 and abs(w_si[-1]-w_si[-2])<=0.000001 and abs(period[-1]-period[-2])<=0.000001):\n",
        "      go = False \n",
        "    \n",
        "    print(i)\n",
        "    i = i+1\n",
        "\n",
        "  print(\"t_s: \", scaler_ts.inverse_transform([t_s[-1]]))\n",
        "  print(\"period: \", scaler_period.inverse_transform([period[-1]]))\n",
        "  print(\"w_si: \", scaler_wsi.inverse_transform([w_si[-1]]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx7jdGWc0UVW"
      },
      "source": [
        "import math\n",
        "def eval(required, received_file):\n",
        "  df1 = pd.read_table(received_file,  header=None, sep='\\s+').values\n",
        "  X_orig = df1[:, 0:1]\n",
        "  T_orig = df1[:, 1:]\n",
        "  print([item for sublist in T_orig for item in sublist])\n",
        "\n",
        "  rmse = np.sqrt(mean_squared_error(required, T_orig))\n",
        "  print(\"rmse: \", rmse)\n",
        "\n",
        "  mse = mean_squared_error(required, T_orig)\n",
        "\n",
        "  rmse = math.sqrt(mse)\n",
        "\n",
        "  print(mse)\n",
        "  plt.plot(X_orig, required, '.')\n",
        "  plt.plot(X_orig, T_orig)\n",
        "\n",
        "  plt.legend([\"input respose\", \"response from parameters\"])\n",
        "  plt.title('DL based')\n",
        "  plt.xlabel('wavelength')\n",
        "  plt.ylabel('transmittance')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP1ANYaf0X7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d06f781-79fb-461b-c7d3-176ea674d5ee"
      },
      "source": [
        "pred_params(model_period, model_wsi, model_ts, X_test[:, 2:][88])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "t_s:  [232.68397009]\n",
            "period:  [725.53415122]\n",
            "w_si:  [548.28264463]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUr0Q9d1bbIF",
        "outputId": "5e9bb32a-d26d-4db9-e017-0927b1ba07a8"
      },
      "source": [
        "scaler_wsi.inverse_transform(X_test[:, 1:2][88])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([547.5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTMRZChhcU5T",
        "outputId": "1df5ded2-be40-4d96-ab20-6700b2588ae7"
      },
      "source": [
        "scaler_ts.inverse_transform(X_test[:, 0:1][88])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([233.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z66AmnVPbyEH",
        "outputId": "88430610-8337-4aee-90da-7680fd4bdebf"
      },
      "source": [
        "scaler_period.inverse_transform(Y_test[88])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([730.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhYsDO9n0dQN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "2f931235-ff7e-472c-cc53-7d561217a84a"
      },
      "source": [
        "eval(scaler_R.inverse_transform(X_test[:, 2:])[88], '/content/result_88.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.81161, 0.81318, 0.8147399999999999, 0.81628, 0.81781, 0.81932, 0.8208200000000001, 0.8223, 0.82376, 0.82521, 0.82665, 0.8280700000000001, 0.82947, 0.83085, 0.8322200000000001, 0.8335799999999999, 0.83491, 0.8362299999999999, 0.83754, 0.8388200000000001, 0.84009, 0.84135, 0.8425799999999999, 0.8438, 0.845, 0.8461799999999999, 0.84735, 0.8485, 0.8496299999999999, 0.8507399999999999, 0.85183, 0.8529100000000001, 0.85396, 0.855, 0.8560200000000001, 0.8570200000000001, 0.858, 0.8589600000000001, 0.8599100000000001, 0.8608299999999999, 0.8617299999999999, 0.86262, 0.8634799999999999, 0.8643200000000001, 0.8651399999999999, 0.8659399999999999, 0.86672, 0.8674799999999999, 0.8682200000000001, 0.86893, 0.8696299999999999, 0.8703, 0.8709399999999999, 0.8715700000000001, 0.8721700000000001, 0.87274, 0.87329, 0.87382, 0.8743200000000001, 0.8748, 0.87525, 0.8756700000000001, 0.8760600000000001, 0.8764299999999999, 0.87677, 0.87708, 0.87735, 0.8776, 0.87782, 0.878, 0.87815, 0.87826, 0.87834, 0.8783799999999999, 0.87839, 0.87835, 0.8782700000000001, 0.87815, 0.8779899999999999, 0.8777799999999999, 0.8775200000000001, 0.87721, 0.87685, 0.8764299999999999, 0.8759600000000001, 0.8754200000000001, 0.8748299999999999, 0.87416, 0.8734299999999999, 0.8726200000000001, 0.87174, 0.87077, 0.86971, 0.8685700000000001, 0.8673200000000001, 0.86597, 0.86451, 0.86292, 0.8612200000000001, 0.8593700000000001, 0.8573799999999999, 0.8552299999999999, 0.8529200000000001, 0.8504200000000001, 0.8477299999999999, 0.84483, 0.8417100000000001, 0.8383299999999999, 0.8347, 0.8307700000000001, 0.8265299999999999, 0.82195, 0.817, 0.81165, 0.80585, 0.79957, 0.79277, 0.7853899999999999, 0.77737, 0.76867, 0.7592, 0.7489, 0.73768, 0.72546, 0.71214, 0.69762, 0.68178, 0.66451, 0.64568, 0.62516, 0.60282, 0.5785399999999999, 0.5522100000000001, 0.52374, 0.49306000000000005, 0.46015, 0.42507, 0.38795, 0.34903, 0.30868, 0.26742, 0.22594, 0.18507, 0.1458, 0.10920999999999999, 0.076404, 0.048466, 0.026325, 0.010683, 0.0019527999999999998, 0.00021184, 0.0052125, 0.016419, 0.033073000000000005, 0.054280999999999996, 0.079087, 0.10655, 0.1358, 0.16605999999999999, 0.19667, 0.22712, 0.25698000000000004, 0.28595, 0.31382, 0.34042, 0.3657, 0.3896, 0.41212, 0.43328, 0.45314, 0.47173000000000004, 0.48913, 0.50539, 0.52059, 0.53478, 0.54804, 0.56043, 0.572, 0.58282, 0.5929399999999999, 0.6024, 0.61125, 0.61954, 0.62731, 0.63459, 0.64141, 0.64781, 0.65382, 0.65946, 0.66476, 0.66974, 0.67443, 0.67883, 0.68297, 0.68687, 0.6905399999999999, 0.694, 0.69725, 0.7003199999999999, 0.70321, 0.7059300000000001, 0.70849, 0.7109, 0.71317, 0.71531, 0.71733, 0.71922, 0.72101, 0.72268, 0.72426, 0.7257399999999999, 0.72713, 0.72844, 0.7296600000000001, 0.7308100000000001, 0.73188, 0.73288, 0.7338100000000001, 0.73468, 0.73549, 0.73624, 0.7369399999999999, 0.73758, 0.73817, 0.7387100000000001, 0.73921, 0.73966, 0.74007, 0.74044, 0.7407699999999999, 0.74106, 0.74131, 0.74153, 0.7417199999999999, 0.74188, 0.742, 0.7421, 0.74216, 0.7422, 0.74222, 0.74221, 0.74217, 0.74211, 0.74203, 0.74192, 0.7418, 0.74165, 0.74149, 0.74131, 0.7411, 0.7408899999999999]\n",
            "rmse:  0.013130083429524642\n",
            "0.00017239909086627758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU9fX48feZycYSQoCwk4Swyg5hcwXccEertu4rWttaq1Zard9aa22rtbWuP3dt3epexa1aq4AiEUjY9yQkEAiQhCSEQLaZ8/tjZuIASZhAJpPMnNfzzDMzd+7cez4zyT1zP9sVVcUYY0zkcoQ6AGOMMaFlicAYYyKcJQJjjIlwlgiMMSbCWSIwxpgIZ4nAGGMinCUCYwIkIqkioiISFeI4VEQGhzIGE14sEZiwJiJ5IrJfRCpEpExEvhWRm0TE4bfOP0Tk/lDGaUwoWSIwkeBcVY0HUoAHgF8DL4Q2JGPaDksEJmKoarmqzgV+BFwtIqOOcFPXich2ESkUkTt8C0Vksogs8p55FIrIEyIS431NROTvIrJLRPaIyCrf/kUkVkT+KiJbRGSniDwtIh38tjvHu73tInLdUXwExjTIEoGJOKq6GCgATjzCTcwAhgCnA78WkVO9y13AbUAP4FjgFOCn3tdOB04ChgIJwA+BEu9rD3iXjwMGA/2AewBE5AzgDuA07z59+zKmxVgiMJFqO9DtCN/7e1WtVNVVwEvApQCqmqmqGapap6p5wDPANO97aoF4YDggqrpOVQtFRIAbgdtUdbeqVgB/Ai7xvu+HwEuqulpVK4F7jzBmYxoV0t4PxoRQP2D3Eb53q9/jfGA0gIgMBR4GJgId8fx/ZQKo6pci8gTwJJAiIu/h+aUf510305MTABDA6X3c17cNv/0Z06LsjMBEHBGZhCcRfHOEmxjg9zgZz9kFwFPAemCIqnYBfoPnoA6Aqj6mqunACDxVQXOAYmA/MFJVu3pvCara2fu2wgb2Z0yLskRgIoaIdBGRc4A3gFe9VTs+ThGJ87vFNLGp34pIRxEZCVwLvOldHg/sAfaKyHDgJ377niQiU0QkGqgEqgC3qrqB54C/i0hP77r9RGSm961vAdeIyAgR6Qj87mg/B2MOZonARIIPRaQCT5XO3Xiqb649aJ078fwy992+bGJ784Fs4H/AX1X1c+/yO4DLgAo8B/c3/d7TxbusFE/1TgnwkPe1X3u3lyEie4AvgGEAqvop8Ig3nuzDxGXMERG7MI0xxkQ2OyMwxpgIZ4nAGGMinCUCY4yJcJYIjDEmwrW7AWU9evTQ1NTUUIdhjDHtSmZmZrGqJjX0WrtLBKmpqSxdujTUYRhjTLsiIo2OSreqIWOMiXCWCIwxJsJZIjDGmAhnicAYYyKcJQJjjIlwlgiMMSbCWSIwxpgI1+7GEZhW5KqDqjLYXwpV5VC7D2qrPPd1VVC733OrqwJ1NbwNZwxEd4ToDt577+O4BOjUAzr2gOi41i2XMeYAlggiTU0lVOzw3gph706oKKRkx1Z279pGR9ceEthLVHUZce7KVgnJFdUJZ3wSdOkHXVMgMcV7nwpJw6DjkV5a2BgTCEsE4aamEkrzoWwLlOWzc8sGKnfk0LVmBx0qC+jg3nvIW2olmkp3V/ZqAlu1M2UkUa6dKNPOlNGZMu3EHjqxn1iqNIYqYthPDFXqua8mBlcDtYwCRFNHB6rpIDXEUU0HauhINV2kkm5SQXfKSXJVMCKuhm47d9Kj4HMSXCU4+P46GTUdexPTdzT0Hg0DJsOAKZYcjGlBlgjaI1cdlOVD8UYKNq2gMHcViZV59HYV0Lmu7IBV4zWWcu3BMu3JVj2OHdqNnZrILrp67rUre+iE36V1W1QtUewjDg6+/pH/cxeeK/d6xVBLPykmRXYwTAoYXrGV8XnZDMj+EifeKqgeQyH1RBg603Mf0zEo8RsTCdrdFcomTpyoETPXkNsFJTmwczWFGzPZnb+SxH359KzdRhR19asVaQK52odcdx+2ak+2alL9fQldCNZBvrXFUc2EqFwuTtrG4Ko1DK1eSax7P0TFwcCTYNSFcMy5ENMp1KEa0+aISKaqTmzwNUsEbcT+Uti5Bnaspjgni6qCFfSsyiVGawCoUwf52osc7fv9zd2XHO3DHjq3SAgOgVOP6cX0YT1Zvb2c4orq+teS4mMZ2TfhgOUNLTuS5V9u2EWdq/l/hzHUMtWxjqt7bGBK7WI679+GK6ojzpHnw/jLIeV4kPBIgsYcLUsEbU11BWxfTsGahZRuyqBP5Tp61O2of7lE41nnTmadprDencx6TWaT9qOG6CPandMh3HDCQPZU1zV6YBbgBxP6k56SeLSla7bM/FLezSo4JLb42Cie+zqXQHKE4GaSbOTCqAWcF7WYDroPeo2GY3/mOVOIigliCYxp+ywRhFJtFexczZZV31C8cRG9966ld+3W+sbQre4kVmgaq90DWasprHMnU0RXAq3OETy/5NNTEhnSK77BX+2hOsC3hIOTRCBnD3FUc37UIu7s+iVd92Z7eiBNvxNG/xCc1ixmIpMlgtZUWQxbMtixZj7kLyJp7zqc6qnPL9IEVrjTWOkexEpNY6U7jd10CWiz/gf8rh1j6n/Nl+6rYWpa93Z7oG8uX2LI3lnB0vxS3E38+TpEeWD0TqZvf46ee9dB0nA48y+QNq31AjamjbBEECyqsDuXvGVfsC97If0qVpBQmQdAtUaxUtPIdA9jmXsQK92DKKQbgfzSb+hXfqQd8APhSwoCTVYjCcqZzqX8pctbdN6/zVNVdMaD0LnBizUZE5YsEbQUVSjeCJsXULrmC6K3ZdR31yzVzix1DyXTPZQl7mGs1oFU03S9tP3Kb1mZ+aU8PT+HL9btpKE/6zhqeKj3l5xd8QaO2C4w6wkYdmbrB2pMCFgiOBqleeQt/Q9la75gYEUmCa7dABRoD75zH8MS9zCWuoeSo33Rw0zd5BCYaL/yg+7177Zwzwercbn1kOELAMc4C3gh/jn6Vm2CidfDGQ9YY7IJe5YImqNiB5uXfErJ6v+StjeLbjWFAOzSrnzrHsG37pF86x5JgfY87Kb8e+uEsldOJMrMLyUjt4SK/bU8+3XuIW0JMdTyq+i3mO38GJKPgx++bFVFJqxZImhKXQ1s/Y4dWR/h3vQFfauyASjTTizyO/DnaF+aqt8/uItme++tE05e/24Lv31/VYPtB7Oc3/K32OeIiu8JV7wHSUNbP0BjWoElgoOV5pO/eC6Vaz4jrWIpcbqfWnWSqUOZ7xrLAvdo1mkK7iaqeg5u0LWDftvm3w31f+t34fI7RRjjyOXNzn+nQ5TAlf+GPmNCGKkxwWGJAGBbFqx8i6r1nxFXngt4+vDPd49hvnssi9wj2EvD89VYL57w8vp3W/i/91cdUF00yFHI3C4P0Yn9njOD/g3+vxjTbjWVCII6ukZEzgAeBZzA86r6wEGvJwP/BLp617lTVT8JRixbVs6nz+IXyHCNYJ7rKha4x5CrfWisusd/ugU76IeXy6YkAxyQDHLcfThzz2/4b/e/EvvqhXD9554psI2JAEE7IxARJ7AROA0oAJYAl6rqWr91ngWWqepTIjIC+ERVU5va7pGcEWTml3LD8/PYVwtVjXTpjHIKJw/zNABb/X5kOPjMQIALBtbyYNkviY7pANf/F7r0CWmMxrSUUJ0RTAayVTXXG8QbwCxgrd86CvVDaxOA7cEIJCO3hLK6GNwHLffvzmkH/sjjOzPw72r6783R5Dhv5524+4l+7SLPmYHNZmrCXDATQT9gq9/zAmDKQevcC3wuIj8HOgGnNrQhEbkRuBEgOTm52YFMTetOTJSD2jo3TocwfVhP+9VvAE8yGNY7nke+2Mg3m4pRYIUrldn7f84/dv4F+eg2uOAZm8XUhLVQz8B1KfAPVf2biBwLvCIio1T1gB/vqvos8Cx4qoaau5P0lERemz2VjNwSq+s3h0hPSeTWU4eyKKeEOm890Xz3WB6tu5BbV74JycfCxGtDHKUxwdP0UNijsw0Y4Pe8v3eZv+uBtwBUdREQB/QIRjDpKYn8bMZgSwKmQekpidw3axQOvx/+j9Wdz8b4yfDpr6FwReiCMybIgpkIlgBDRGSgiMQAlwBzD1pnC3AKgIgcgycRFAUxJmMaddmUZO4/fzRObzJw4+DK0tnUxHaF938KrtrQBmhMkAQtEahqHXAz8BmwDnhLVdeIyH0icp53tV8CN4jICuBfwDXa3gY2mLBy2ZRkLpmcXN+puKiuM090/CnsXA0LHwlpbMYES+QMKDMmQJn5pVz+fAY1tW7ceLqVPh79OGdGLcX504U2vsC0S011Hw1m1ZAx7ZKvc8HxQ3ogePo4/672Kva4Y9n79k9pcI5rY9oxSwTGNMDXk8jpbT0uIYE/111G511LYe0HIY7OmJZlicCYRvh6Evkaj99xncQGHUDVf+7xzFprTJiwRGBME/wbj904eLDuUuIq8iHzpVCHZkyLsURgzGH8YEJ/YqMdOIAFOo4d3SbD/AehqjzUoRnTIiwRGHMY6SmJ3HPOSBwOwa1wc9Es2FcC3z0b6tCMaRGhnmLCmHahdF8NblXcCpm1A9nQdQrDFj8Dx90M0R1CHZ5pDa46zw+AyiLYVwyV3lv1HqjZCzWV3pv3cV01uOv8bq7v79UF4gSHExxRII7vHzuiwBnj+buKioWoDhAdB1FxMPIHkHzwlG1HzxKBMQGYmtadKIdQ4/LMUvqHstN51fkHWPEvmHhdqMMzLUEVygugaAPszoXyLVDmd9tX0uhbaySGWkdHNKYTezWWfRpLrcTgEidRUdF0iutEebWy3wVunLhx0CEKusY52bu/itq6WhzqJs4J8TEuqqt2I3X7idIaYrSGWGqIpZZvSnuScPzQFp8qxxKBMQFIT0nk4okDeP27LSjwbe1wcjoMo9/8R4mbcLXn15xpP+pqYMcqKFjiuS9a50kANXvrV6mRGMpjelMbP4CCuOPJc3RhdWk0RdqF3dqFYrqwW+OpoCN1vkNpZXDDdqyCmHUZvDZ7aosmA0sExgToBxP6825WgXfEsfBw5Rk8WfMoOV+/yaBpl4U6PNOU6grY/DXkL/Qc/LcvB1c1ABVR3SiISqG0yxns6ZzGSxvjyHX3pogE2C/QhvoEuBVq69xk5JZYIjAmFHwjjh/5YiMLs4v51DWJPGcvOmY+BZYI2p6iDbDuQ8j5ErZ+B+463M4YdnQ6hvLkS5hXmcorW3uwvaq7Z/2y0IYbCIdAdJSDqWndW3S7lgiMaQbfiOMlebupqYXX3afxmz2vwq510POYUIdnijbA6nc9o7+L1gNQ2X0US3pcwvzaUbyxsy9VlVHoriPfhf/1zFdvL6e4wnNmkRQfy8i+CQcsa+7yw60brOunWyIwppl83Unv+WA177lO4A7nvyid/xy9Ln441KFFppp9sPZ9yPwHbP0ORdjcaSyr+93GlqST+ft3FbiaMT2U4DnYp3svY+t/YA7XKxtaIjDmCPi6kxZrF75wpzNjwztQ92dPdz/TOvYUwqInIOsVqC6nqksaH3b7MQ8VjmVXVVcoAXIqDrsZ/2uXB/NXd1tmicCYI+C7DnZNrZu33SdzVt1i2PAJjLwg1KGFv5IcWPgorPgX6naxMmE6n3c7h2e29KLOdfi3Ox3CDScMZE91HQJh+Qu/uSwRGHME/KuHvnaPYrt2p9O3L5JgiSB4Kovhqz955nlyRLOx3wXcuGkqeft7Nfm2g6t67MB/KEsExhyh70cbO3jbNY1btv0byrZC1wGHf7MJXF0NLH4G5j8ENXvZNfxKHqw8h/c21TZ6aQj/Bt1IrOppLksExhwh/+qh990n8Qve8/RWOe7mUIcWPrZkwAc3Q8kmyvtN58XOs3lypZO6Bq4fHeUUTh7WM2wbdIPJEoExR8i/eihfe7JGU0lZ9i6dLREcvdr98MXv4bunqe7cl6d7/4nHNg/E7VY8k3x8T4DTRvTix9MG2cH/CFkiMOYo+E9G96lrMncUvQXl2yChX6hDa7+KNsDb18CutWxMvoQLN51ORXEccGg9kNMh/GHWKC6bktzqYYYTm4bamKPgqx5yCvxPpnoWrv8otEG1ZyvfgmenU1u+g5cG/pUzs2dRoXEHrOIUOH1ELy6fksxbPz7WkkALsDMCY46Cb9qJd7MKEJLZnz+MDms/gCk/DnVo7YvbDV/+Ab55mJ2J6Vyw8zoK1yUeUg1kZwDBYYnAmBbwXlYBNXVuekeP5uayd5GKnRDfdLdG41W7H967AdZ9SPaACzkrexY1euChySlwyjHWDhAslgiMOUoZuSXU1LlxK3xSN4mfx7zjqR6adH2oQ2v7qivgX5dC3jdkDp/DxSvG4Vapf9kpcMnkZOsFFGSWCIw5Sr52gto6N5udyVR1SSNu/ceWCA5nfym8djFsy+LbMX/iiiUpuP1qghwCfzh/tFUDtQJLBMYcJV87QUZuCYkdY9iwcgqj897DUVvlucSgOVT1Xnj1QtyFq3g95T5+tzQVt9/oMIfA/ZYEWo31GjKmBaSnJDI1rTv3fbSGR/P643BVs3Hpf0MdVttUVw1vXIZuX87Ntbfw2/UDcbktCYSSJQJjWoivrWCR6xiqNYrKNZ+FOqS2x+2Gd2fD5vm80/9OPq2dcEC/oCiHWBIIAasaMqaF1E85URdHFsMYW7kk1CG1PV/dD+vmkjX8Du5cMbI+CUQ5hR9NHGCNwiFiicCYFuI/pqB814l0LHwaKnZAfO9Qh9Y2rHoHvv4bmwZcxEUrxtc3DAvww4kD+OMFo0MaXiSzqiFjWth7WQU8ke+p2ti82EYZA1C4Aj64mYpekzkvZ9aBXUQdwoUT+ocwOGOJwJgW5GsnWONOpli7ULPhi1CHFHrVe+Hta6FjNx7v/lv2u531LzkE7ps1yqqDQswSgTEtyNdO4BAH3+oY0vYs8TSQRrL//BrdnctzSXfy4oq99Yud1jDcZlgiMKYF+doJfjQ5mZqUk4iuKoai9aEOK3RWvwfLXuVp9/n8aU136rxXkRfgR5MGWBJoIywRGBME72UV8ER2EgD5y78McTQhsrcIPrqNrR2P4eGaC+p7CAkQG+2wdoE2xBKBMS3M106Qpz0p0gSqchaGOqTQ+Owu3DWV3Fh+PbXeDopRTuGyKcm8NnuqtQu0IUFNBCJyhohsEJFsEbmzkXV+KCJrRWSNiLwezHiMaQ3fX6NAyGIYqftWhTqk1rfpC1j1Nl8lXcF6V1/gwG6ilgTalqCNIxARJ/AkcBpQACwRkbmqutZvnSHAXcDxqloqIj2DFY8xrcV/7qER+08ndvH9sKcQuvQJdWito6YSPr6NqoQ0bimYUV8lFB1l1UFtVTDPCCYD2aqaq6o1wBvArIPWuQF4UlVLAVR1VxDjMabV+OYeyqgd6lmwNSO0AbWmhY9B2RZe6XEb+1ye35oCXJRuo4bbqmAmgn7AVr/nBd5l/oYCQ0VkoYhkiMgZDW1IRG4UkaUisrSoqChI4RrTcjLzS7n8+QzuzoB9GsvONfNDHVLrqNgB3z5GaepZPLS+h50NtBOhbiyOAoYA04FLgedEpOvBK6nqs6o6UVUnJiUltXKIxjSfr8G4RqNYqYOQLRFyRvDVH3G7arm/6mLq3N93FbWzgbYtmIlgGzDA73l/7zJ/BcBcVa1V1c3ARjyJwZh2zf+i9lkMI6lyo2eEbTjbuRZd9iqv1J3Ke3mxuNUzcti6irZ9wUwES4AhIjJQRGKAS4C5B63zPp6zAUSkB56qotwgxmRMq/A1GN9++jBOmzkLURdsWxrqsILrf7+nSjrySM35KJ6Dy/GDe1hX0XbgsIlAPK4QkXu8z5NFZPLh3qeqdcDNwGfAOuAtVV0jIveJyHne1T4DSkRkLfAVMEdVS460MMa0JekpifxsxmD29pyAImxfNS/UIQVP4QrY+B+eqT2TUuIBiIpycOupQy0JtAOBdB/9f4AbOBm4D6gA3gUmHe6NqvoJ8MlBy+7xe6zA7d6bMWEnM7+Uy19ey4fSly1ZCygcVxqeB8YFf6XK0YkXq04HrF2gvQmkamiKqv4MqALwdvWMCWpUxoQJX6Pxak1lBJvJyA3DE95d69F1H/Ji7WnsoRNgvYTam0ASQa13cJgCiEgSnjMEY8xh+BqN1+hA+shuTugThv863zxMnSOWF+o8vb/tbKD9CSQRPAb8G+gpIn8EvgH+FNSojAkTvkbjkeknATDWmR/iiFpYaT6seofs5B9SLgnWS6idOmwbgaq+JiKZwCl4kv35qrou6JEZEybSUxJJ73UmrAC2L4chp4U6pJaz5HkUuClnCi634nQI95wz0s4G2plAeg1NBbap6pOq+gSwTUSmBD80Y8JH5k4XZR2SKc0Jowva1+yDrJfJ6T6drXWJKKCqlO6rCXVkppkCqRp6CvAfCbPXu8wYEwDfdBNf7+3HvvxMMvNLQx1Sy1j9LlSVkZd2OQ4RHOJpJJ6a1j3UkZlmCiQRiLebJwCq6iaIs5YaE258PYdWuVPpJ8Us35Ad6pCOniosfob9XYdx86IOuNyKQ6xaqL0KJBHkisgtIhLtvf0CG/1rTMB8PYfWahoAJ3beHuKIWsDWxbBjFf+SmdTUqVULtXOBJIKbgOPwzBNUAEwBbgxmUMaEE1/PoenTTwVgqCsnxBEdvZL5T1GhHfhb4bj6OYWsWqj9CqTX0C488wQZY45Qekqip8pkXSoULg91OEenuoIumz/lbffxVBJXP6eQTSfRfh02EXgHkN0ApPqvr6rXBS8sY8JPZn4pCVGDGbAli9hQB3M01s4l2l3Fv90n4RCIsTmF2r1AqoY+ABKAL4CP/W7GmAD5eg69X9iN2L1bWbZpS6hDOmJ7vnuFPO3NUtdgayAOE4H0/umoqr8OeiTGhDFfz6H14rlER87aTMYPSQ5xVEegbAtddizieddFKGINxGEikDOCj0TkrKBHYkwY8/UcylHP1AsTO+4McURHaOWbAHwsJ+G0BuKwEcgZwS+A34hINVCLZ5oJVdUuQY3MmDDi6zmUkVOEe2Ecqa52OOeQKqx4g4pek5nSewJTgR9MsMnlwkEgvYbiWyMQY8Jdfc+hTcNhVzucrmvHSijJ5i/uG3hjyxZiohz8wCaXCwsBjRAWkUQ81xKO8y1T1QXBCsqYsNZzBOR8Geoomm/dh7hx8GltOm6F2jo3GbkldkYQBgLpPjobT/VQf2A5MBVYhOeKZcaYZsjML6WqIonj9+6AfbuhY7dQhxS4dR9S1C2dsh0JOFBrHwgjgTQW/wLPZSnzVXUGMB4oC2pUxoQhXxfS5zd4RhFsWNWOZiIt2ghF63mueKTNKxSGAkkEVapaBSAisaq6HhgW3LCMCT/1XUhdni6khdlZIY6oGdbNBeCT2nSbVygMBdJGUCAiXYH3gf+KSCnQDrs8GBNavi6ku+q6UaEdGOFsR5PPrfuQvUnj2L0jCWed26qFwkwgvYYu8D68V0S+wjPK+NOgRmVMGKrvQppbgqw9hp7728kkvmVboHA5Kwfewj3njKR0Xw1T07pbtVAYCeQKZa/4HqvqfFWdC7wY1KiMCVPpKYn8bMZgOg8YBbvWevrmt3Fbv30LgLvXp3LfR2ssCYShQNoIRvo/EREnkB6ccIyJED1HwP7dUFkU6kgOSzf9l03ufmzW3vVdRk14aTQRiMhdIlIBjBGRPd5bBbALmNtqERoTZjLzS/lge4LnSVsfWFazj/57sljIWJtSIow12kagqn8G/iwif1bVu1oxJmPClq8LaZc6ZVYsbNmQRXLatFCH1bj8hThcNbgHn8ol8ck2pUSYCqRqaPLBC0Tkf0GIxZiw5+tCuksTqNAOlG1t22cEO7M+Yr/G8Jd13Xg3qyDU4ZggaapqKE5EugM9RCRRRLp5b6lAv9YK0Jhw4utC6hQhjz6k0La7kMbkfcV37mOo0hhrHwhjTXUf/TFwK9AX8B/5sgd4IphBGROu/LuQ9t06moSSZaEOqXG7N5O4P5+FMt3aB8JcU20EjwKPisjPVfXxVozJmLBWPwvpvJGQOxdq90N0h1CHdagcTw1w3IiZXBJr7QPhrNFEICInq+qXwDYR+cHBr6vqe0GNzJhw130QoLB7M/QaEepoDlG28lMqtCdPrlBiogpsyukw1lRjsa8rw7kN3M4JclzGhL21Nb0AyFm/PMSRNMBVS8ft37LAPRq3irUPhLmmqoZ+572/tvXCMSYyZOaXcsP7xWQ54YP/zWda6pltq9qlcAUxrn0skVHWPhABArkeQVfgKiDVf31VvSV4YRkT3jJySyiri2GHI5EU3d72LvCS9w0APUedwiXR3ax9IMwFMvvoJ0AGsApwBzccYyKDrxtpnvYhzVFIahv7tV2+fh7F2pfnl+0lJmqftQ+EuUASQZyq3h70SIyJIL5upLH/OYbhu78kqi392nbV0aFwMRnuqXZJyggRyMjiV0TkBhHp4zeoLKDr64nIGSKyQUSyReTOJta7UERURCYGHLkx7Vx6SiKjRk8gqrrUc9nKtmLHSmJclWTKSGsfiBCBnBHUAA8BdwO+OXMVSGvqTd5ZSp8ETgMKgCUiMldV1x60Xjyey2F+17zQjQkD3Qd77kuyoeMhs7mEhrd94OpLr2DQDqdNOx0BAjkj+CUwWFVTVXWg99ZkEvCaDGSraq6q1gBvALMaWO8PwINAVcBRGxMuegzx3JdkhzYOf/kLqeqSxjeWBCJGIIkgG9h3BNvuB2z1e17AQXMUicgEYICqftzUhkTkRhFZKiJLi4ra/vztxgQqc088LnFSmLsq1KF4uF3U5S1kblkqf/t8A5c/n0FmfmmoozJBFkgiqASWi8gzIvKY73a0OxYRB/AwnjOOJqnqs6o6UVUnJiUlHe2ujWkTMvNLufzFTPJcPVm5YmnbOODuWEVUTQXfuo45oKHYhLdA2gje996aaxswwO95f+8yn3hgFDBPRAB6A3NF5DxVXXoE+zOmXfFNSZ0b1YdUCvmiLfTM2ZIBwDLHCJxuayiOFIFcvP6fvscikoinKmdlANteAgwRkYF4EsAlwGV+2y0Hevhtex5whyUBEyl8Ywm2ai+Od6xh6sCAOuMFV9sEEykAACAASURBVMFi6NKPhy88m4zcEmsjiBCBXLx+noh08XYZzQKeE5GHD/c+Va0DbgY+A9YBb6nqGhG5T0TOO9rAjWnvfGMJBg8fTUepJr17TahDojrvO7JjhgPwsxmDLQlEiEDaCBJUdQ/wA+BlVZ0CnBrIxlX1E1UdqqqDVPWP3mX3qOoh1zxW1el2NmAiTXpKIidN8XYb3b05pLGsWLeB2L0FvLmjtzUSR5hAEkGUiPQBfgh8FOR4jIk8iQM996V5IQ1j2+qvAch0DbFG4ggTSCK4D0/1TraqLhGRNGBTcMMyJoJ0TQZxQGlozwgmODZRo07Wk2qNxBEmkMbit4G3/Z7nAhcGMyhjIknmtkqGxPSidusGQnno7b1nNZVJo/jZyNHWSBxhApmGOgm4gUOnob4ueGEZExky80u5/PkMXpRudMxZQ15+aWgOwK46XNsyye41y5JABAqkaugDIAH4AvjY72aMOUq+sQR57p4MYGfI6uXXrliEs24/L+b1sIbiCBTIgLKOqvrroEdiTATyH0vQXfZw3IDYkMSxa903jAAy3YOpddu005EmkDOCj0TkrKBHYkwE8o0lGDtmPADjO4Xml/ho90aKNIFCkqyhOAIFckbwC+A3IlIN1AICqKp2CWpkxkSI9JREiDkW1uLpOdRnTKvH0L1sFWXJk7g9bbi1EUSgQHoNxbdGIMZENN9YglAMKquugJJsuo6+mJ9NH9z6+zchF8gZgW+OoSFAnG+Zqi4IVlDGRJy4LtCxe2jGEhSuBJSPinvSJ1S9lkxIBTLX0GxgAZ5BZb/33t8b3LCMiUCJqSEZXbx17bcA3JcZYz2GIlQgjcW/ACYB+ao6AxgPlAU1KmMiTGZ+KRtre1C9K6fV970vL4sdmsgu7WpTS0SoQBJBlapWAYhIrKquB4YFNyxjIodvUNln2zvgrNhG5uZdrbr/5OqNrCXNLlQfwQJpIygQka54Lk7zXxEpBfKDG5YxkcM3qCzf0YsocbNu3RrSB/ZsnZ1X76VDeQ7Dx/+C2xOGWY+hCBVIr6ELvA/vFZGv8Iwy/k9QozImgtQPKnP1AmBK1/LW2/mOVYCSVZdiSSCCNVk1JCJOEVnve66q81V1rqqG/goaxoQJ36CyM046DoAh0cWttu+tazwNxfdbQ3FEazIRqKoL2CAiya0UjzERKT0lkWtPnwJRca3ac6gyP5Nd2pUdmmgNxREskDaCRGCNiCwGKn0LVdUuN2lMS3I4oGtKqyaClOpNfMdAayiOcIEkgjjgHL/nAjwYnHCMiXCtOZagppIO5dkMHX+zNRRHuEASQZSqzvdfICIdghSPMZEtMRW2LAJVEAnuvnauAXXTd/ix/Gy4TS0RyRptIxCRn4jIKmCYiKz0u20GVrZeiMZEjq30hOo9LN/YClNN7FgFwD83x1sjcYRrqrH4deBcYK733ndLV9UrWiE2YyJKZn4pf1q0H4D7X/0k6AfnXTlZ7NGO/H5BufUYinCNJgJVLVfVPFW9VFXz/W67WzNAYyJFRm4Jm11JAPR17wh6D5667atYr8m4VazHUIQLZIoJY0wrmJrWnZ1Oz6CyVGdRcHvwqNJrfw6bSLYeQyawaaiNMcGXnpLI87Ons+/V7lw5EJKC2YOnbAvO2r2ccMJ0bo+2HkORzhKBMW1Iekoi9EqjY+324O5o5xoAUo6ZzM8GWI+hSGdVQ8a0Na0xlsCbCOh5THD3Y9oFSwTGtDWJqVBeAK7aoO2idHMW5XH9ydwRvH2Y9sMSgTFtTWIqqBvKtwZl85n5pZRtXkZGZR/rNmoASwTGtDkbajy9dzauXx2U7S/dVEAKO1jrTrZuowawRGBMm5KZX8qPP/JMQ/3af+YH5df6SV1LcIiykWTrNmoASwTGtCkZuSUU1HWlWqPo694ZlF/rxzi2AHDc8dN4bfZU6zZqrPuoMW3J1LTuREVFsU2TSHHuIikYv9Z3roHoTlx5xjTP1Ncm4tlfgTFtiO9qZc7uAzmxR2VQfq1X5C9nR1wamVtb8ZKYpk2zRGBMG5OekkjK4BF0qmz5XkOZebtxFa7my7Ik6zFk6lkiMKYtSkyFqnLY37IH6lXr19FV9rLOegwZP0FNBCJyhohsEJFsEbmzgddvF5G13usc/E9EUoIZjzHtRmKq576FRxgf33knABvVegyZ7wUtEYiIE3gSOBMYAVwqIiMOWm0ZMFFVxwDvAH8JVjzGtCdrq7oBkLNxTYtud4jmAXDqjJOtx5CpF8wzgslAtqrmqmoN8AYwy38FVf1KVfd5n2YA/YMYjzHtQmZ+KVe+twOAf3/5TcvW4+9cAwkDuOG08ZYETL1gJoJ+gH9rV4F3WWOuBz5t6AURuVFElorI0qKiohYM0Zi2JyO3hNK6OEo0nn7asmMJ9hesZHPUQGskNgdoE43FInIFMBF4qKHXVfVZVZ2oqhOTkpJaNzhjWtnUtO7ERDnYqj1JdrTcBWqycncQXZrNxzu7WY8hc4BgJoJtwAC/5/29yw4gIqcCdwPnqWp1EOMxpl3wjSXo2GswE7uUt1gVzqY1mUSJ23oMmUMEMxEsAYaIyEARiQEuAeb6ryAi44Fn8CSBXUGMxZh2JT0lkaHDRxG7dxu46lpkm5M7FgKwkQHWY8gcIGhTTKhqnYjcDHwGOIEXVXWNiNwHLFXVuXiqgjoDb4sIwBZVPS9YMRnTriSmgrpgT8H33UmPwsC6zbidsVxw6klMGdTLGotNvaDONaSqnwCfHLTsHr/HpwZz/8a0a/5jCVogEbBzNY6ex/DTk4cf/bZMWGkTjcXGmAa09KCynWug16iW2ZYJK5YIjGmjMks74hInhXnrj35je3dBZRFfV/Sy3kLmEJYIjGmDMvNLufzFJWx19WDZimVHffDeuDIDgKfXxVnXUXMISwTGtEEZuSXU1LnZoj3pz66j7upZlJ0JwFr3AOs6ag5hicCYNqh+UBk9SZZdR93Vc7hsYacmske6WNdRcwi7QpkxbZBvUFn1/EV0zf0f6T3lqLbXvXIT5f3HcPvgYUxN625dR80B7IzAmDYqPSWR4yZO9DzZnXvkG3LVQtEGElLH8bMZgy0JmENYIjCmLes+2HN/FIlgzapMcNWw2TmwhYIy4cYSgTFtWbeBgEBJ9hG9PTO/lJfe+xCAX3xVY72FTIMsERjThmVur2JPbG9Ktqw7ovdn5JYw1L2Zao1mQ11v6y1kGmSJwJg2KjO/lMufz2DF/h5sy1l1RL/mp6Z1Z5Qzn43aH4mKsd5CpkFh0WuotraWgoICqqqqQh2KMQeIi4ujf//+REdHN/u9vrEEuc7eXOBcyCs5xc1u6E1P7kpdXAEbEqfz2pl2aUrTsLBIBAUFBcTHx5Oamop3FlNjQk5VKSkpoaCggIEDm99Q6xtLkK996CL7OKHvEQRRXkBUdRkjJ5wAlgRMI8Kiaqiqqoru3btbEjBtiojQvXv3Iz5T9Y0lGD9+EgBjOxQ3fyM7Vnru+4w9ohhMZAiLRABYEjBt0tH+XaanJHLujBM9T0o2Nfv929cvRhGWVR/J6YSJFGGTCIwJW12TIaoDFG1o1tsy80tZu+wbct29ufSfR9bYbCKDJYIWctxxx7X4NvPy8nj99ddbfLumnXE42dcljfz1Wc06mGfklnAMeazRVJtozjQpYhNBZn4pT36V3WK/kr799tsW2Y6/QBNBXV3LXNPWtE2Z+aV8UZxI1O6NzZpC+vi+DvpJMes01SaaM02KyETg65/9t883tNjc7J07dwZg3rx5TJ8+nYsuuojhw4dz+eWXo6oApKam8qtf/YrRo0czefJksrM9o0WvueYa3nnnnUO2deedd/L1118zbtw4/v73vx+wv3nz5nHiiSdy3nnnMWLECFwuF3PmzGHSpEmMGTOGZ555BoDCwkJOOukkxo0bx6hRo/j666/r93HbbbcxcuRITjnlFIqKigBYvnw5U6dOZcyYMVxwwQWUlno+m8cee4wRI0YwZswYLrnkEgAqKyu57rrrmDx5MuPHj+eDDz446s/RHCojt4SN7r70k2Ji6ioD/mU/LnorAMPHn8Brs63rqGlcRCYCX/9stxKUU+Zly5bxyCOPsHbtWnJzc1m4cGH9awkJCaxatYqbb76ZW2+9tcntPPDAA5x44oksX76c22677ZDXs7KyePTRR9m4cSMvvPACCQkJLFmyhCVLlvDcc8+xefNmXn/9dWbOnMny5ctZsWIF48aNAzwH8YkTJ7JmzRqmTZvG73//ewCuuuoqHnzwQVauXMno0aPrlz/wwAMsW7aMlStX8vTTTwPwxz/+kZNPPpnFixfz1VdfMWfOHCorK1vkMzTfm5rWnc0yAIBhUYUB/7Lfuu47AFJHWRIwTYvIRODrn+0UgnLKPHnyZPr374/D4WDcuHHk5eXVv3bppZfW3y9atOio9+Prn/7555/z8ssvM27cOKZMmUJJSQmbNm1i0qRJvPTSS9x7772sWrWK+Ph4ABwOBz/60Y8AuOKKK/jmm28oLy+nrKyMadOmAXD11VezYMECAMaMGcPll1/Oq6++SlRUVP0+H3jgAcaNG8f06dOpqqpiy5YtR1Umc6j0lER+cvHZADw0LTagg3pmfinLvptPoXbjR69usoZi06SwGFDWXL7+2Rm5JUGZmz02Nrb+sdPpPKAO3787oe9xVFQUbrcbALfbTU1NTUD76dSpU/1jVeXxxx9n5syZh6y3YMECPv74Y6655hpuv/12rrrqqkPWOVw3x48//pgFCxbw4Ycf8sc//pFVq1ahqrz77rsMGzYsoHjNkRs1ahx8EEuqO7BEm5FbwhnksNo9sP6s184KTGMi8owAPMkgFHOzv/nmm/X3xx57LOBpO8jM9FxKcO7cudTW1gIQHx9PRUVFQNudOXMmTz31VP17N27cSGVlJfn5+fTq1YsbbriB2bNnk5WVBXgSjq9d4vXXX+eEE04gISGBxMTE+naEV155hWnTpuF2u9m6dSszZszgwQcfpLy8nL179zJz5kwef/zx+jaQZcuWtcRHZBricELP4bBjVUCrH9/PySBHIct1sDUUm8OKyDOCUCotLWXMmDHExsbyr3/9C4AbbriBWbNmMXbsWM4444z6X/pjxozB6XQyduxYrrnmmgbbCXxmz55NXl4eEyZMQFVJSkri/fffZ968eTz00ENER0fTuXNnXn75ZcBzNrF48WLuv/9+evbsWZ+g/vnPf3LTTTexb98+0tLSeOmll3C5XFxxxRWUl5ejqtxyyy107dqV3/72t9x6662MGTMGt9vNwIED+eijj4L8CUauovhj6Jz7KWvzdpOe2q3JdcdJDgBDJszgtXRrIzBNE9+vufZi4sSJunTp0gOWrVu3jmOOOSZEEQUuNTWVpUuX0qNHj1CHQufOndm7d2+ow4gILfH3mZlfykcv3MfvHC8yw/UEf519TtMH96/+DPMfhLu2Qmz8Ue3bhAcRyVTViQ29FrFVQ8a0Jxm5JayoSwFgqDv3sD3dyrMXUdxpEJk7bIyJOTxLBK0oLy+vTZwNAHY20M5MTetOrjMVlwpjnPlN1vln5pVAwVK+2DOgxcbJmPBmicCYdiA9JZEXZk+jvNNALk8pa7JaKHtVBglSyXeu4Ta1hAmIJQJj2on0lETcfScQuyOTzLzdja53nHMtAIt1hPUYMgGxRGBMO5GZX8rDG3vQobaMe154t9Eqn/jCRRTH9Gf65PE2tYQJiCUCY9qJjNwSvq31DN6b4F7TYJVP5uYinFu+5fP9Q3k3q6C1QzTtlCUCA8D69esZN24c48ePJycnJ9ThtLqysjL+3//7f6EOo0lT07qzI6o3hdqNqc71DVb5bF7xNfGyn29dI619wATMEkELU9X66SLak/fff5+LLrqIZcuWMWjQoPrlbak8wYzlSBJBa382nqlRjmVX4gROitkIDYwBOqH2W2rUyTc6xtoHTMDCLxF8eie8dHbL3j69s8ld5uXlMWzYMK666ipGjRrF1q1beeihh+qnhP7d734HeGb8PPvssxk7diyjRo2qH83b2PTUeXl5nHzyyYwZM4ZTTjmlfkK3a665hltuuYXjjjuOtLS0+qkiGpty+vPPP+fYY49lwoQJXHzxxYd0Hf3kk0945JFHeOqpp5gxY0aD5ZkzZw6jRo1i9OjR9XHPmzePadOmMWvWLNLS0rjzzjt57bXXmDx5MqNHj27wzOLee+/lyiuv5Nhjj2XIkCE899xzgKc76ymnnMKECRMYPXp0/ZTWDcXyk5/8hIkTJzJy5Mj6z9b3Od51112MGzeOiRMnkpWVxcyZMxk0aFD9jKlAg9/NnXfeSU5ODuPGjWPOnDmNrtdQPNdcc039Z3PwdOHB8MbuwcTXlfDAC68d0E6QmbebjjkfU9TzOG44fYK1D5iA2RQTLWTTpk3885//ZOrUqXz++eds2rSJxYsXo6qcd955LFiwgKKiIvr27cvHH38MQHl5ef37fdNTv/zyy9x666189NFH/PznP+fqq6/m6quv5sUXX+SWW27h/fffBzwH/W+++Yb169dz3nnncdFFF9VPOX333XfjcrnYt28fxcXF3H///XzxxRd06tSJBx98kIcffph77rmnft9nnXUWN910E507d+aOO+4gLy/vgPK8++679dNYFxcXM2nSJE466SQAVqxYwbp16+jWrRtpaWnMnj2bxYsX8+ijj/L444/zyCOPHPJZrVy5koyMDCorKxk/fjxnn302PXv25N///jddunShuLiYqVOnct555x3y2YJn+utu3brhcrk45ZRTWLlyJWPGjAEgOTm5ftrua665hoULF1JVVcWoUaO46aabGv1uHnjgAVavXs3y5csBGl0vOTn5gHgyMzPZtm0bq1evBjxnFsGUkVvCJ7Xp3BsTxRm6kIzcM0lPSSQzv5Q/vvAG7zm388C+c7nwnJafTNGEr/BLBGc+EJLdpqSk1B+oPv/8cz7//HPGjx8PeH7tbtq0iRNPPJFf/vKX/PrXv+acc87hxBNPrH+///TUvjmFFi1axHvvvQfAlVdeya9+9av69c8//3wcDgcjRoxg586dAEyaNInrrruO2tpazj//fMaNG8f8+fNZu3Ytxx9/PAA1NTX1k90FWp5vvvmGSy+9FKfTSa9evZg2bRpLliyhS5cuTJo0iT59+gAwaNAgTj/9dABGjx7NV1991eC2Z82aRYcOHejQoQMzZsxg8eLFnH322fzmN79hwYIFOBwOtm3bVl8u/1gA3nrrLZ599lnq6uooLCxk7dq19YnAlzxGjx7N3r17iY+PJz4+ntjYWMrKyhr9bpKTkw+Isan1/ONJS0sjNzeXn//855x99tn15Q+WqWndeTwqnnnucZztzOCrDk4A3ssq4GL9nGqN5rPaCfSz2UZNMwQ1EYjIGcCjgBN4XlUfOOj1WOBlIB0oAX6kqnnBjClYDp4S+q677uLHP/7xIetlZWXxySef8H//93+ccsop9b/MG5qeuin+U1375os66aSTDplyOjExkdNOO61+grsjKU+gcTgcjvrnDoej0UtoHlw+EeG1116jqKiIzMxMoqOjSU1Npaqq6pBYNm/ezF//+leWLFlCYmIi11xzTf16/vH4x+IfT2Pfjf81I6Dx7zAvL++AeBITE1mxYgWfffYZTz/9NG+99RYvvvhiwx9WC0hPSeSec0by8YfHMVOWkvHxP1C5ngVLl/O7qAW86ZpBhTPB2gZMswStjUBEnMCTwJnACOBSERlx0GrXA6WqOhj4O/BgsOJpTTNnzuTFF1+sr4vftm0bu3btYvv27XTs2JErrriCOXPm1E8JDQ1PT33cccfxxhtvAPDaa68dcAbRkIamnJ46dSoLFy6sb3eorKxk48aNzSrPiSeeyJtvvonL5aKoqIgFCxYwefLkZm3D3wcffEBVVRUlJSXMmzePSZMmUV5eTs+ePYmOjuarr74iPz+/wffu2bOHTp06kZCQwM6dO/n000+bte/GvpuDp/xubL2DFRcX43a7ufDCC7n//vsP+E6DpXRfDZ+6JrHWncKdjpd55Ysl3O34JwI84zqXi9L729mAaZZgnhFMBrJVNRdARN4AZgFr/daZBdzrffwO8ISIiLa3KVEPcvrpp7Nu3br6A3rnzp159dVXyc7OZs6cOTgcDqKjo3nqqafq39PQ9NSPP/441157LQ899BBJSUm89NJLTe63oSmnk5KS+Mc//sGll15KdXU1APfffz9Dhw4NuDwXXHABixYtYuzYsYgIf/nLX+jduzfr169v7kcDeKbXnjFjBsXFxfz2t7+lb9++XH755Zx77rmMHj2aiRMnMnz48AbfO3bsWMaPH8/w4cMZMGBAfZVXoBr7bgYNGsTxxx/PqFGjOPPMM3nooYcaXM/pdB6wvW3btnHttdfW9x7685//3NyPo9mmpnXHGRXN3bXX827M7/i45nocTuX+2svZ5ezFhRP6Bz0GE16CNg21iFwEnKGqs73PrwSmqOrNfuus9q5T4H2e412n+KBt3QjcCJCcnJx+8K/F9jINdWPa0vTUwXbvvffWN0pHimD8fWbml/LIFxupyM7gLOd3rHAP4mP3VC6bksyfLhjdovsy4aGpaajbRWOxqj4LPAue6xGEOBxjQi49JZFbTx3KpbklLK8bDEBMlMPOBswRCWYi2AYM8Hve37usoXUKRCQKSMDTaBxRDm6oDGf33ntvqEMIG+kpifzrxmN5N6sAAX4wwdoGzJEJZiJYAgwRkYF4DviXAJcdtM5c4GpgEXAR8OWRtg+oakC9bYxpTcFu7kpPSbSDvzlqQes1pKp1wM3AZ8A64C1VXSMi94nIed7VXgC6i0g2cDvQ9BDeRsTFxVFSUhL0fzpjmkNVKSkpIS4uLtShGNOksLhmcW1tLQUFBQf0JzemLYiLi6N///5ER0eHOhQT4dp9Y/HhREdHM3DgwFCHYYwx7VL4TTpnjDGmWSwRGGNMhLNEYIwxEa7dNRaLSBHQ8EQ0h9cDKD7sWuHFyhwZrMyR4WjKnKKqSQ290O4SwdEQkaWNtZqHKytzZLAyR4ZgldmqhowxJsJZIjDGmAgXaYng2VAHEAJW5shgZY4MQSlzRLURGGOMOVSknREYY4w5iCUCY4yJcO0+EYjIiyKyy3u1s4Nf+6WIqIj08D4XEXlMRLJFZKWITPBb92oR2eS9Xd2aZWiuZpZ5uoiUi8hy7+0ev3XPEJEN3s/jiGZ+bS0NlVlE7hWRbX5lO8vvtbu85dogIjP9lreLMjenvCKSKiL7/ZY/7feedBFZ5S3vY9KG52pv7O9aRH4uIutFZI2I/MVvebv+jqF5ZQ7q96yq7foGnARMAFYftHwAnimw84Ee3mVnAZ8CAkwFvvMu7wbkeu8TvY8TQ122FirzdOCjBrbhBHKANCAGWAGMCHXZmlNmPNe7vqOBdUd4yxMLDPSW09meytzM8qYe/Lfg99pi79+6eP/2zwx12ZpZ5hnAF0Cs93nPcPmOj6DMQfue2/0ZgaouAHY38NLfgV8B/q3hs4CX1SMD6CoifYCZwH9VdbeqlgL/Bc4IcuhHrJllbsxkIFtVc1W1BngDz+fTJjVR5obMAt5Q1WpV3Qxk4ylvuylzM8vbIO/fdhdVzVDP0eJl4PyWiC8YGinzT4AHVLXau84u7/J2/x1Ds8vcoJb4ntt9ImiIiMwCtqnqioNe6gds9Xte4F3W2PJ2o4kyAxwrIitE5FMRGeld1u7L7HWzt5rvRRHxXaorbL9nGi4vwEARWSYi80XkRO+yfnjK6NMeyzsUOFFEvvOWbZJ3eTh/x42VGYL0PYddIhCRjsBvgHsOt264OEyZs/DMMTIWeBx4vzVjC7KngEHAOKAQ+Ftowwm6xspbCCSr6ng8V/p7XUS6hCbEFheFp8p2KjAHeKstt3O0kMbKHLTvOewSAZ5/lIHAChHJA/oDWSLSG8+1kwf4rdvfu6yx5e1Fo2VW1T2quhdAVT8Bor0Nye29zKjqTlV1qaobeA5PtQCE6ffcWHm91SMl3seZeOrIh+IpW3+/TbSr8noVAO95q3MXA248E6+F5Xfs1WCZg/k9h10iUNVVqtpTVVNVNRXPhzpBVXcAc4GrxGMqUK6qhXgaWE8XkUTv6fbp3mXtQlNlFpHevl9QIjIZz3deAiwBhojIQBGJAS7B8/m0G966UZ8LAF/Pi7nAJSISKyIDgSF4GtPadZkbK6+IJImI0/s4DU95c71/23tEZKr3b+Aq4INWDvtovY+n8RQRGYqnAbiYMP2OvRosc1C/51C2mLfEDfgXnlOmWjwHwOsPej2P73vQCPAknky6Cpjot951eBqcsoFrQ12uFizzzcAaPL0nMoDj/NY7C9jo/TzuDnW5mltm4BXv97gSzz97H7/17/aWawN+PSjaS5mbU17gQu93vBxPVeC5ftuZiCdh5ABP4J1NoC3eGilzDPCqtwxZwMnh8h03t8zB/J5tigljjIlwYVc1ZIwxpnksERhjTISzRGCMMRHOEoExxkQ4SwTGGBPhLBEYc5REZJ6ItOgFxUWkq4j81O/5dBH5qCX3YYyPJQJj2qauwE8Pu5YxLcASgQlbIjJHRG7xPv67iHzpfXyyiLwmIk+JyFLvnO+/9752hoi87beN+l/iInK6iCwSkSwReVtEOjewzwbXEZE8Efm9d/kqERnuXZ4kIv/1xvC8iOR7pwB5ABgknnnnH/JuvrOIvCOeeepfi4A5d0wrsURgwtnXgG+Gxol4DqTR3mUL8Iw6nQiMAaaJyBg888BPEZFO3vf9CHjDe3D+P+BUVZ0ALMUz8Ve9ANYp9i5/CrjDu+x3wJeqOhJ4B0j2Lr8TyFHVcao6x7tsPHArnrn404Djj/yjMeZ7lghMOMsE0r0zNFYDi/AkhBPxJIkfikgWsAwYiecCJnXAf4BzRSQKOBvPvC1T8RyAF4rIcuBqIOWgQllSOAAAAZFJREFU/R1unff84kr1Pj4Bz5z5qOp/gNImyrNYVf9/e3fsC0EQxXH8+0RCIrSiUV2h1ChEpZH4A0h0Gol/w1+hVTl/wHUqLkcjIXKFTqMgEiIX4XB5ijfFBuGcnE1ufp9mJ5vZmd1i9+3MJG+uPJLOnRXaEPmT4bJvQKRf3P3VzC6BdeCIyNGzCFSAJ+KvfM7d781sBxhNl+4ROZrugBN3b6VpmH13X/umy5/qtNOxQ2/vXrtQ7rUNkU80IpBBVyc++IepvEmMACaAR+DBzCaB5cI1B8T2gRukv3UiYd+CmVUAzGwsZYYs6qbORw1gNdVfIrZKBWgB4797VJHeKBDIoKsDU8Cxu98Az0DdYye3U+AC2CU+yAC4eweoEcGhls7dEiOLqpmdE9NMM8WOuqnzhS0iBXoTWAGugZZH3vmGmTULi8UifaHsoyIlMrMRoOPub2Y2D2y7+2zZ9yV50RyjSLmmia0Ih4AXYjpK5F9pRCAikjmtEYiIZE6BQEQkcwoEIiKZUyAQEcmcAoGISObeAc6nxggo+YwVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4WYX6KDL4Gb",
        "outputId": "223eefee-d831-489a-9a18-69315d321623"
      },
      "source": [
        "model_.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 100)               25400     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 65,901\n",
            "Trainable params: 65,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiEP5ycnKaRB",
        "outputId": "415f8e67-f37d-43e2-b346-fb5857334a74"
      },
      "source": [
        "scaler_ts.inverse_transform(X_test[:, 0:1])[62]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([233.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o96IBoyXRA2",
        "outputId": "02242b6f-6108-4941-e765-f13cd649e16e"
      },
      "source": [
        "scaler_period.inverse_transform(X_test[:, 1:2])[62]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([620.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcAb_eKzXVou",
        "outputId": "177f9d68-0ae5-47cd-fde6-7e4856836c0f"
      },
      "source": [
        "scaler_wsi.inverse_transform(Y_test[:])[62]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([542.5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDab8-fz0YRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "28600bb9-8009-40a1-8c7a-a856c8fbb903"
      },
      "source": [
        "with open('/content/gdrive/MyDrive/x.csv', 'w') as writefile:\n",
        "    for i in range(len(X_test)):\n",
        "      for val in X_test[i:i+1, 2:]:\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-f3acf0feb4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/x.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwritefile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0mwritefile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not numpy.ndarray"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtDeaLUxESVH"
      },
      "source": [
        "import glob\n",
        "all_f = glob.glob('/content/*.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzmmDvPZbm30"
      },
      "source": [
        "all_rec = np.ones((9, 251))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2tqBOi1lUKd"
      },
      "source": [
        "all_req = np.ones((9, 251))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u8MOvQV9mCnL",
        "outputId": "53cec77c-e719-4d32-f36f-a86739618806"
      },
      "source": [
        "all_f[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/55.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QKDKqxIVl2Nj",
        "outputId": "6bb723fa-d8b8-43e3-9db7-904df1b2a61d"
      },
      "source": [
        "all_f[0][9:len(all_f[0])-4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'55'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVgB7xcVlXeA"
      },
      "source": [
        "for i in range(len(all_f)):\n",
        "  all_req[i] = X_test[:, 2:][int(all_f[0][9:len(all_f[0])-4])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bta3Fs6WbHoW"
      },
      "source": [
        "for i in range(len(all_f)):\n",
        "  df2 = pd.read_table(all_f[i],  header=None, sep='\\s+').values\n",
        "  T_orig = df2[:, 1:]\n",
        "  all_rec[i] = [item for sublist in T_orig for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIGypfjuhXg5",
        "outputId": "92be7498-d69d-4d8d-c8d9-dc72e96c126e"
      },
      "source": [
        "len(all_rec[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F1l8yyigdlG"
      },
      "source": [
        "header = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FjbF0d2g-mA"
      },
      "source": [
        "for i in range(1400, 1651):\n",
        "  header = np.append(header, str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvFT9Myqjzxr",
        "outputId": "154ee069-3756-44dc-a7b6-ebd6c41fd949"
      },
      "source": [
        "all_rec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.98001, 0.97969, 0.97937, ..., 0.63352, 0.63444, 0.63526],\n",
              "       [0.80164, 0.80327, 0.8049 , ..., 0.90574, 0.90493, 0.90412],\n",
              "       [0.73316, 0.73487, 0.73657, ..., 0.95629, 0.95601, 0.95575],\n",
              "       ...,\n",
              "       [0.9843 , 0.98374, 0.98318, ..., 0.5491 , 0.54857, 0.54803],\n",
              "       [0.86567, 0.86462, 0.86356, ..., 0.59543, 0.59477, 0.59412],\n",
              "       [0.96533, 0.96481, 0.96429, ..., 0.6109 , 0.61021, 0.60952]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPjIDoVDjs6C",
        "outputId": "aa71a47a-f76a-423b-9119-ce93516e1d1f"
      },
      "source": [
        "header"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1400', '1401', '1402', '1403', '1404', '1405', '1406', '1407',\n",
              "       '1408', '1409', '1410', '1411', '1412', '1413', '1414', '1415',\n",
              "       '1416', '1417', '1418', '1419', '1420', '1421', '1422', '1423',\n",
              "       '1424', '1425', '1426', '1427', '1428', '1429', '1430', '1431',\n",
              "       '1432', '1433', '1434', '1435', '1436', '1437', '1438', '1439',\n",
              "       '1440', '1441', '1442', '1443', '1444', '1445', '1446', '1447',\n",
              "       '1448', '1449', '1450', '1451', '1452', '1453', '1454', '1455',\n",
              "       '1456', '1457', '1458', '1459', '1460', '1461', '1462', '1463',\n",
              "       '1464', '1465', '1466', '1467', '1468', '1469', '1470', '1471',\n",
              "       '1472', '1473', '1474', '1475', '1476', '1477', '1478', '1479',\n",
              "       '1480', '1481', '1482', '1483', '1484', '1485', '1486', '1487',\n",
              "       '1488', '1489', '1490', '1491', '1492', '1493', '1494', '1495',\n",
              "       '1496', '1497', '1498', '1499', '1500', '1501', '1502', '1503',\n",
              "       '1504', '1505', '1506', '1507', '1508', '1509', '1510', '1511',\n",
              "       '1512', '1513', '1514', '1515', '1516', '1517', '1518', '1519',\n",
              "       '1520', '1521', '1522', '1523', '1524', '1525', '1526', '1527',\n",
              "       '1528', '1529', '1530', '1531', '1532', '1533', '1534', '1535',\n",
              "       '1536', '1537', '1538', '1539', '1540', '1541', '1542', '1543',\n",
              "       '1544', '1545', '1546', '1547', '1548', '1549', '1550', '1551',\n",
              "       '1552', '1553', '1554', '1555', '1556', '1557', '1558', '1559',\n",
              "       '1560', '1561', '1562', '1563', '1564', '1565', '1566', '1567',\n",
              "       '1568', '1569', '1570', '1571', '1572', '1573', '1574', '1575',\n",
              "       '1576', '1577', '1578', '1579', '1580', '1581', '1582', '1583',\n",
              "       '1584', '1585', '1586', '1587', '1588', '1589', '1590', '1591',\n",
              "       '1592', '1593', '1594', '1595', '1596', '1597', '1598', '1599',\n",
              "       '1600', '1601', '1602', '1603', '1604', '1605', '1606', '1607',\n",
              "       '1608', '1609', '1610', '1611', '1612', '1613', '1614', '1615',\n",
              "       '1616', '1617', '1618', '1619', '1620', '1621', '1622', '1623',\n",
              "       '1624', '1625', '1626', '1627', '1628', '1629', '1630', '1631',\n",
              "       '1632', '1633', '1634', '1635', '1636', '1637', '1638', '1639',\n",
              "       '1640', '1641', '1642', '1643', '1644', '1645', '1646', '1647',\n",
              "       '1648', '1649', '1650'], dtype='<U32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H9ZIdwJa4l-"
      },
      "source": [
        "np.savetxt('/content/all_rec_dltr.csv', all_rec, delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t68kEIXOep7E"
      },
      "source": [
        "np.savetxt('/content/all_req_dltr1.csv', df_req, delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-on7P6vcmaum"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}